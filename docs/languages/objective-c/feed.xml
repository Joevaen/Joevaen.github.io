<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joevaen – 8.Pytorch to ONNX</title>
    <link>https://Joevaen.github.io/docs/languages/objective-c/</link>
    <description>Recent content in 8.Pytorch to ONNX on Joevaen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/docs/languages/objective-c/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: 怎样把模型从Pytorch转到ONNX</title>
      <link>https://Joevaen.github.io/docs/languages/objective-c/convert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/objective-c/convert/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: 怎样评估导出的模型</title>
      <link>https://Joevaen.github.io/docs/languages/objective-c/evaluate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/objective-c/evaluate/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: 支持导出为ONNX模型的列表</title>
      <link>https://Joevaen.github.io/docs/languages/objective-c/list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/objective-c/list/</guid>
      <description>
        
        
        &lt;p&gt;下表列出了能够导出为ONNX并且能在ONNX Runtime上运行的模型。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;模型&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;配置文件&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;动态形状&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;推理的batch&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;注意&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;FCOS&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/fcos/fcos_r50_caffe_fpn_gn-head_4x4_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;FSAF&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/fsaf/fsaf_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;RetinaNet&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/retinanet/retinanet_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;SSD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/ssd/ssd300_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;YOLOv3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/yolo/yolov3_d53_mstrain-608_273e_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Faster R-CNN&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Mask R-CNN&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;CornerNet&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/cornernet/cornernet_hourglass104_mstest_10x5_210e_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;N&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;no flip, no batch inference, tested with torch==1.7.0 and onnxruntime==1.5.1.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;MMCV的最小版本为 &lt;code&gt;1.3.5&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;所有的模型都是在 Pytorch==1.6.0 和 onnxruntime==1.5.1上进行测试的&lt;/em&gt;, 除了CornerNet。如果要了解Centernet的更多关于导出为ONNX的信息（包括&lt;code&gt;mmcv::cummax&lt;/code&gt;）, 参考这里mmcv的这个 &lt;a href=&#34;https://github.com/open-mmlab/mmcv/blob/master/docs/onnxruntime_op.md#known-issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Known Issues&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最近仅有单尺度评估被ONNX Runtime所支持，&lt;code&gt;mmcv::SoftNonMaxSuppression&lt;/code&gt;仅支持单个图像。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果部署的平台是TensorRT，在运行前请添加环境变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#366&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#033&#34;&gt;ONNX_BACKEND&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;MMCVTensorRT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果你想使用TensorRT中的&lt;code&gt;--dynamic-export&lt;/code&gt;来导出ONNX模型，请移除 &lt;code&gt;--simplify&lt;/code&gt; 参数，反之亦然。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: ONNX导出时的NMS参数</title>
      <link>https://Joevaen.github.io/docs/languages/objective-c/nms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/objective-c/nms/</guid>
      <description>
        
        
        &lt;p&gt;在导出ONNX模型的过程中，我们设置了一些NMS参数来控制输出的bounding box的数量。下面介绍了支持模型中的NMS参数。你能通过&lt;code&gt;--cfg-options&lt;/code&gt;来设置这些参数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;nms_pre&lt;/code&gt;: 使用NMS前的box的数量，默认为1000。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;deploy_nms_pre&lt;/code&gt;: 当导出为ONNX模型时，在NMS之前的box。默认设置为0。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;max_per_img&lt;/code&gt;: NMS之后保留的box的数量，默认为100.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;max_output_boxes_per_class&lt;/code&gt;: 每个类别的输出boxes进行NMS的最大数目，默认为200.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 提醒</title>
      <link>https://Joevaen.github.io/docs/languages/objective-c/reminder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/objective-c/reminder/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;当输入的模型有一些定制的操作，比如&lt;code&gt;ROIAlign&lt;/code&gt;，如果你想确认导出的模型，你需要用&lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnxruntime_op.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ONNXRuntime&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; from source 从源编译&lt;code&gt;mmcv&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mmcv.onnx.simplify&lt;/code&gt; 是基于 &lt;a href=&#34;https://github.com/daquexian/onnx-simplifier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnx-simplifier&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;的. 如果你想尝试的话，请参考 &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnx.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnx in &lt;code&gt;mmcv&lt;/code&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 和 &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnxruntime_op.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnxruntime op in &lt;code&gt;mmcv&lt;/code&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;如果你遇到以上列出模型中出现的任何问题，请创建issue，会很快收到答复。对于不在这个列表里面的模型，多半要靠你自己解决。&lt;/li&gt;
&lt;li&gt;因为现在处于试验阶段而且更新很快，请总是使用最新的&lt;code&gt;mmcv&lt;/code&gt;和&lt;code&gt;mmdetection&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
