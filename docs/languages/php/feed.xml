<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joevaen – 9.ONNX to TensorRT</title>
    <link>https://Joevaen.github.io/docs/languages/php/</link>
    <description>Recent content in 9.ONNX to TensorRT on Joevaen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/docs/languages/php/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: 怎样把模型从ONNX转到TensorRT</title>
      <link>https://Joevaen.github.io/docs/languages/php/convert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/php/convert/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: 怎样评估导出的模型</title>
      <link>https://Joevaen.github.io/docs/languages/php/evaluate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/php/evaluate/</guid>
      <description>
        
        
        &lt;p&gt;我们准备了一个工具 &lt;code&gt;tools/deplopyment/test.py&lt;/code&gt; 来评估 TensorRT 模型。&lt;/p&gt;
&lt;p&gt;请参考以下链接来获得更多信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;pytorch2onnx.md#how-to-evaluate-the-exported-models&#34;&gt;怎样评估导出模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;pytorch2onnx.md#results-and-models&#34;&gt;结果和模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 支持导出为TensorRT模型的列表</title>
      <link>https://Joevaen.github.io/docs/languages/php/list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/php/list/</guid>
      <description>
        
        
        &lt;p&gt;下面是支持转换为TensorRT的模型。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;模型&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;配置&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;支持动态形状&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;推理batch&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;注意&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;SSD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/ssd/ssd300_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;FSAF&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/fsaf/fsaf_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;FCOS&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/fcos/fcos_r50_caffe_fpn_4x4_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;YOLOv3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/yolo/yolov3_d53_mstrain-608_273e_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;RetinaNet&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/retinanet/retinanet_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Faster R-CNN&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Mask R-CNN&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Y&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;所有这些模型是在Pytorch==1.6.0, onnx==1.7.0 和 TensorRT-7.2.1.6.Ubuntu-16.04.x86_64-gnu.cuda-10.2.cudnn8.0的环境下测试的。&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 提醒</title>
      <link>https://Joevaen.github.io/docs/languages/php/reminder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/php/reminder/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;当输入的模型有一些定制的操作，比如&lt;code&gt;ROIAlign&lt;/code&gt;，如果你想确认导出的模型，你需要用&lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnxruntime_op.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ONNXRuntime&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; from source 从源编译&lt;code&gt;mmcv&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mmcv.onnx.simplify&lt;/code&gt; 是基于 &lt;a href=&#34;https://github.com/daquexian/onnx-simplifier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnx-simplifier&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;的. 如果你想尝试的话，请参考 &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnx.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnx in &lt;code&gt;mmcv&lt;/code&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 和 &lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/onnxruntime_op.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;onnxruntime op in &lt;code&gt;mmcv&lt;/code&gt;&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 。&lt;/li&gt;
&lt;li&gt;如果你遇到以上列出模型中出现的任何问题，请创建issue，会很快收到答复。对于不在这个列表里面的模型，多半要靠你自己解决。&lt;/li&gt;
&lt;li&gt;因为现在处于试验阶段而且更新很快，请总是使用最新的&lt;code&gt;mmcv&lt;/code&gt;和&lt;code&gt;mmdetection&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
