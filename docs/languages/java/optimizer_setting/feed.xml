<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gRPC – 自定义优化设置</title>
    <link>https://Joevaen.github.io/docs/languages/java/optimizer_setting/</link>
    <description>Recent content in 自定义优化设置 on gRPC</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/docs/languages/java/optimizer_setting/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: 自定义Pytorch支持的优化器</title>
      <link>https://Joevaen.github.io/docs/languages/java/optimizer_setting/optimizer_torch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/java/optimizer_setting/optimizer_torch/</guid>
      <description>
        
        
        &lt;p&gt;我们已经支持使用所有pytorch中的优化器，唯一的修改是改变了配置文件中的&lt;code&gt;optimizer&lt;/code&gt;字段。
比如：如果你想使用&lt;code&gt;ADAM&lt;/code&gt;（注意性能可能会下降很多），可以按照下面方式修改：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;optimizer &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Adam&amp;#39;&lt;/span&gt;, lr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.0003&lt;/span&gt;, weight_decay&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.0001&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To modify the learning rate of the model, the users only need to modify the &lt;code&gt;lr&lt;/code&gt; in the config of optimizer. The users can directly set arguments following the &lt;a href=&#34;https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;API doc&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; of PyTorch.
想要修改模型的学习率，只需要修改优化器配置文件中的&lt;code&gt;lr&lt;/code&gt;。使用者可以直接根据pytorch的&lt;a href=&#34;https://pytorch.org/docs/stable/optim.html?highlight=optim#module-torch.optim&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;API doc&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;设置参数。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 自定义自动化优化器</title>
      <link>https://Joevaen.github.io/docs/languages/java/optimizer_setting/self_implemented/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/java/optimizer_setting/self_implemented/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: 自定义优化器的构造函数</title>
      <link>https://Joevaen.github.io/docs/languages/java/optimizer_setting/optimizer_constructor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/java/optimizer_setting/optimizer_constructor/</guid>
      <description>
        
        
        &lt;p&gt;某些模型可能具有一些参数特定设置以进行优化，例如， Batchnorm层的权重衰减。 用户可以通过自定义优化器构造函数进行那些细粒度的参数调整。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmcv.utils&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; build_from_cfg

&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmcv.runner.optimizer&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; OPTIMIZER_BUILDERS, OPTIMIZERS
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmdet.utils&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; get_root_logger
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;.my_optimizer&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; MyOptimizer


&lt;span style=&#34;color:#99f&#34;&gt;@OPTIMIZER_BUILDERS.register_module&lt;/span&gt;()
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#0a8;font-weight:bold&#34;&gt;MyOptimizerConstructor&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;object&lt;/span&gt;):

    &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;def&lt;/span&gt; __init__(self, optimizer_cfg, paramwise_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;None):

    &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;def&lt;/span&gt; __call__(self, model):

        &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;return&lt;/span&gt; my_optimizer

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;默认的优化器的构造函数在 &lt;a href=&#34;https://github.com/open-mmlab/mmcv/blob/9ecd6b0d5ff9d2172c49a182eaa669e9f27bb8e7/mmcv/runner/optimizer/default_constructor.py#L11&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;, 可以作为其他优化器构造函数的模板。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 额外的设置</title>
      <link>https://Joevaen.github.io/docs/languages/java/optimizer_setting/add_set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/java/optimizer_setting/add_set/</guid>
      <description>
        
        
        &lt;p&gt;优化器未实现的技巧应通过优化器构造函数（例如，设置参数智能的学习率）或hooks来实现。 我们列出了一些可以稳定训练或加速训练的常见设置。欢迎大家来提出更多的问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;使用梯度渐变来稳定训练&lt;/strong&gt;:
有些模型需要梯度渐变以稳定训练过程。 一个例子如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;optimizer_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
    _delete_&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True, grad_clip&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(max_norm&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;35&lt;/span&gt;, norm_type&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;2&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果你的配置文件继承了基本的配置文件，也已经设置好了&lt;code&gt;optimizer_config&lt;/code&gt;，你可能需要&lt;code&gt;_delete_=True&lt;/code&gt;来覆写没必要的设置。查看&lt;a href=&#34;https://mmdetection.readthedocs.io/en/latest/config.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;config documenetation&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 得到更多细节。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;使用动量调度来加速模型收敛&lt;/strong&gt;:
我们支持使用动量调度来根据学习率修改模型的动量，这样能使模型收敛的更快。
动量调度通常会和学习率调度一起使用，比如下面这个3d检测的配置文件就通过这种方式加速模型收敛。
想知道更多的话，请查阅&lt;a href=&#34;https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/lr_updater.py#L327&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CyclicLrUpdater&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/momentum_updater.py#L130&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CyclicMomentumUpdater&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;lr_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
    policy&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;cyclic&amp;#39;&lt;/span&gt;,
    target_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1e-4&lt;/span&gt;),
    cyclic_times&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,
    step_ratio_up&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.4&lt;/span&gt;,
)
momentum_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
    policy&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;cyclic&amp;#39;&lt;/span&gt;,
    target_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;0.85&lt;/span&gt; &lt;span style=&#34;color:#555&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#f60&#34;&gt;0.95&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;),
    cyclic_times&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,
    step_ratio_up&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.4&lt;/span&gt;,
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
