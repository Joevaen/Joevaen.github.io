<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gRPC – 1.学习如何使用Configs</title>
    <link>https://Joevaen.github.io/docs/languages/cpp/</link>
    <description>Recent content in 1.学习如何使用Configs on gRPC</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/docs/languages/cpp/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: 通过脚本参数修改配置</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/quickstart/</guid>
      <description>
        
        
        &lt;p&gt;使用 &lt;code&gt;tools/train.py&lt;/code&gt; 或 &lt;code&gt;tools/test.py&lt;/code&gt; 提交作业时，您可以指定 &lt;code&gt;-cfg-options&lt;/code&gt; 修改配置。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;更新字典链的配置键。&lt;/p&gt;
&lt;p&gt;可以在原始配置的顺序之后指定配置选项。
比如, &lt;code&gt;--cfg-options model.backbone.norm_eval=False&lt;/code&gt; 可以改变 &lt;code&gt;train&lt;/code&gt; 模式中的BN模块配置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新配置列表中的键。&lt;/p&gt;
&lt;p&gt;某些Config字典在配置中作为列表组成。例如, 训练管道 &lt;code&gt;data.train.pipeline&lt;/code&gt; 通常是一个列表，形如：&lt;code&gt;[dict(type=&#39;LoadImageFromFile&#39;), ...]&lt;/code&gt;。 如果你想把管道中的 &lt;code&gt;&#39;LoadImageFromFile&#39;&lt;/code&gt; 改成 &lt;code&gt;&#39;LoadImageFromWebcam&#39;&lt;/code&gt;,你需要添加参数 &lt;code&gt;--cfg-options data.train.pipeline.0.type=LoadImageFromWebcam&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新列表/元组中的值。&lt;/p&gt;
&lt;p&gt;如果要更新的值是列表或元组。 例如, 配置文件通常设置为 &lt;code&gt;workflow=[(&#39;train&#39;, 1)]&lt;/code&gt;。 如果你想修改这个键, 你需要添加参数 &lt;code&gt;--cfg-options workflow=&amp;quot;[(train,1),(val,1)]&amp;quot;&lt;/code&gt;。 注意这个&lt;code&gt;&amp;quot;&lt;/code&gt; 不能忘记加, 加在列表/元组数据类型。引号内不能有空格。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 配置文件结构</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/basics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/basics/</guid>
      <description>
        
        
        &lt;p&gt;&lt;code&gt;config/_base_&lt;/code&gt;，dataSet，model，schedule，default_runtime有4种基本组件类型。 许多方法可以很容易地构造，其中一个是更快的R-CNN，mask R-CNN，Cascade R-CNN，RPN，SSD。 由&lt;code&gt;_base_&lt;/code&gt;组件组成的配置称为 &lt;em&gt;primitive&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;对于相同文件夹下的所有配置，建议只有&lt;strong&gt;一个&lt;/strong&gt; &lt;em&gt;primitive&lt;/em&gt; 配置。 所有其他配置都应该从 &lt;em&gt;primitive&lt;/em&gt;  配置继承。 以这种方式，最大继承级别为3。&lt;/p&gt;
&lt;p&gt;为了简单理解，我们建议贡献者继承现有方法。 例如，如果是在Faster R-CNN上进行修改，用户可以首先通过指定 &lt;code&gt;_base_ = ../faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&lt;/code&gt; 来继承基本的 Faster R-CNN 结构。然后修改配置文件中的必要字段。&lt;/p&gt;
&lt;p&gt;如果您正在构建与任何现有方法不共享结构的完全新方法，则可以在 &lt;code&gt;configs&lt;/code&gt; 下创建文件夹 &lt;code&gt;XXX_RCNN&lt;/code&gt;，&lt;/p&gt;
&lt;p&gt;有关详细文档，请参阅&lt;a href=&#34;https://mmcv.readthedocs.io/en/latest/utils.html#config&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MMCV&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 配置文件命名风格</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/async/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/async/</guid>
      <description>
        
        
        &lt;p&gt;我们按照以下方式命名配置文件。 建议使用者使用同样的风格。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{model}_[model setting]_{backbone}_{neck}_[norm setting]_[misc]_[gpu x batch_per_gpu]_{schedule}_{dataset}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;{xxx}&lt;/code&gt; 是必要的字段而 &lt;code&gt;[yyy]&lt;/code&gt; 是可以选择的字段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{model}&lt;/code&gt;: 例如 &lt;code&gt;faster_rcnn&lt;/code&gt;, &lt;code&gt;mask_rcnn&lt;/code&gt;这样的模型类型。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[model setting]&lt;/code&gt;: 指定一些模型的设置, 比如 &lt;code&gt;htc&lt;/code&gt; 的 &lt;code&gt;without_semantic&lt;/code&gt; , &lt;code&gt;reppoints&lt;/code&gt; 的  &lt;code&gt;moment&lt;/code&gt; 等等。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{backbone}&lt;/code&gt;: 网络骨架类型， 比如 &lt;code&gt;r50&lt;/code&gt; (ResNet-50), &lt;code&gt;x101&lt;/code&gt; (ResNeXt-101)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{neck}&lt;/code&gt;: neck类型， 比如 &lt;code&gt;fpn&lt;/code&gt;, &lt;code&gt;pafpn&lt;/code&gt;, &lt;code&gt;nasfpn&lt;/code&gt;, &lt;code&gt;c4&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[norm_setting]&lt;/code&gt;: &lt;code&gt;bn&lt;/code&gt; (Batch Normalization) 是默认使用的，除非指定其他选项, 比如： &lt;code&gt;gn&lt;/code&gt; (Group Normalization), &lt;code&gt;syncbn&lt;/code&gt; (Synchronized Batch Normalization)。
&lt;code&gt;gn-head&lt;/code&gt;/&lt;code&gt;gn-neck&lt;/code&gt; 表明&lt;code&gt;GN&lt;/code&gt;仅在 head/neck 应用, 而 &lt;code&gt;gn-all&lt;/code&gt; 意味着 GN 应用在整个模型上, 比如： backbone, neck, head。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[misc]&lt;/code&gt;: 模型中各种各样的设置和插件, 比如： &lt;code&gt;dconv&lt;/code&gt;, &lt;code&gt;gcb&lt;/code&gt;, &lt;code&gt;attention&lt;/code&gt;, &lt;code&gt;albu&lt;/code&gt;, &lt;code&gt;mstrain&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[gpu x batch_per_gpu]&lt;/code&gt;: GPU的数目和每个GPU的样本数, 默认使用&lt;code&gt;8x2&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{schedule}&lt;/code&gt;: 训练的日历, 选项分别有 &lt;code&gt;1x&lt;/code&gt;, &lt;code&gt;2x&lt;/code&gt;, &lt;code&gt;20e&lt;/code&gt;等等。
&lt;code&gt;1x&lt;/code&gt; 和 &lt;code&gt;2x&lt;/code&gt; 意味着 12 epochs 和 24 epochs。
&lt;code&gt;20e&lt;/code&gt; 应用在级联模型中, 表示 20 epochs。
对于 &lt;code&gt;1x&lt;/code&gt;/&lt;code&gt;2x&lt;/code&gt; 来说, 初始学习率会在8/16 epoch和11/22 epoch时衰减10倍，对于20e，在第16和第19 epoch衰减10倍。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{dataset}&lt;/code&gt;: 数据集，比如： &lt;code&gt;coco&lt;/code&gt;, &lt;code&gt;cityscapes&lt;/code&gt;, &lt;code&gt;voc_0712&lt;/code&gt;, &lt;code&gt;wider_face&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 丢弃这样的训练/测试配置方式：train_cfg/test_cfg</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/alts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/alts/</guid>
      <description>
        
        
        &lt;p&gt;新版本中， &lt;code&gt;train_cfg&lt;/code&gt; 和 &lt;code&gt;test_cfg&lt;/code&gt; 这样的配置文件被丢弃了, 请在模型配置文件中进行配置，原始的配置文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# deprecated&lt;/span&gt;
model &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
   &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=...&lt;/span&gt;,
   &lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;
)
train_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;)
test_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;修改后的配置文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# recommended&lt;/span&gt;
model &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
   &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=...&lt;/span&gt;,
   &lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;
   train_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;),
   test_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#555&#34;&gt;...&lt;/span&gt;),
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: 用Mask R-CNN进行举例说明</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/api/</guid>
      <description>
        
        
        &lt;p&gt;为了帮助用户在现代检测系统中具有完整配置和模块的基本概念，我们使用Reset50和FPN对Mask R-CNN配置进行简要评论。有关每个模块的更详细用法和相应的替代方案，请参阅API文档。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
    &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MaskRCNN&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 侦测器的名字&lt;/span&gt;
    pretrained&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;torchvision://resnet50&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 加载的ImageNet预训练骨架&lt;/span&gt;
    backbone&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 骨架配置文件&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;ResNet&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 骨架类型, 到 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/backbones/resnet.py#L288 了解更多细节。&lt;/span&gt;
        depth&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;50&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 骨架的深度, 对于ResNet来说，一般是50或101。&lt;/span&gt;
        num_stages&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;4&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 骨架的stage的数目。&lt;/span&gt;
        out_indices&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;3&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 每个stage输出的特征图的索引。&lt;/span&gt;
        frozen_stages&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 第一个stage的权重会被冻结。&lt;/span&gt;
        norm_cfg&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# normalization layers的配置文件。&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;BN&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# norm layer的类型, 通常是BN或者GN。&lt;/span&gt;
            requires_grad&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 在BN层中是否训练gamma和beta。&lt;/span&gt;
        norm_eval&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 是否冻结BN的统计数据。&lt;/span&gt;
        style&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;pytorch&amp;#39;&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# 骨架的类型, &amp;#39;pytorch&amp;#39; 意味折3x3卷积步长为2, &amp;#39;caffe&amp;#39; 意味着1x1卷积步长为2。&lt;/span&gt;
    neck&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;FPN&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The neck of detector is FPN. We also support &amp;#39;NASFPN&amp;#39;, &amp;#39;PAFPN&amp;#39;, etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/fpn.py#L10 for more details.&lt;/span&gt;
        in_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;512&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1024&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;2048&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The input channels, this is consistent with the output channels of backbone&lt;/span&gt;
        out_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The output channels of each level of the pyramid feature map&lt;/span&gt;
        num_outs&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;5&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of output scales&lt;/span&gt;
    rpn_head&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RPNHead&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The type of RPN head is &amp;#39;RPNHead&amp;#39;, we also support &amp;#39;GARPNHead&amp;#39;, etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/dense_heads/rpn_head.py#L12 for more details.&lt;/span&gt;
        in_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The input channels of each input feature map, this is consistent with the output channels of neck&lt;/span&gt;
        feat_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Feature channels of convolutional layers in the head.&lt;/span&gt;
        anchor_generator&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config of anchor generator&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;AnchorGenerator&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Most of methods use AnchorGenerator, SSD Detectors uses `SSDAnchorGenerator`. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/anchor/anchor_generator.py#L10 for more details&lt;/span&gt;
            scales&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;8&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Basic scale of the anchor, the area of the anchor in one position of a feature map will be scale * base_sizes&lt;/span&gt;
            ratios&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;2.0&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The ratio between height and width.&lt;/span&gt;
            strides&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;64&lt;/span&gt;]),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The strides of the anchor generator. This is consistent with the FPN feature strides. The strides will be taken as base_sizes if base_sizes is not set.&lt;/span&gt;
        bbox_coder&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of box coder to encode and decode the boxes during training and testing&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;DeltaXYWHBBoxCoder&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of box coder. &amp;#39;DeltaXYWHBBoxCoder&amp;#39; is applied for most of methods. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py#L9 for more details.&lt;/span&gt;
            target_means&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The target means used to encode and decode boxes&lt;/span&gt;
            target_stds&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;]),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The standard variance used to encode and decode boxes&lt;/span&gt;
        loss_cls&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of loss function for the classification branch&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CrossEntropyLoss&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of loss for classification branch, we also support FocalLoss etc.&lt;/span&gt;
            use_sigmoid&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# RPN usually perform two-class classification, so it usually uses sigmoid function.&lt;/span&gt;
            loss_weight&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Loss weight of the classification branch.&lt;/span&gt;
        loss_bbox&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of loss function for the regression branch.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;L1Loss&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of loss, we also support many IoU Losses and smooth L1-loss, etc. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/losses/smooth_l1_loss.py#L56 for implementation.&lt;/span&gt;
            loss_weight&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;)),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Loss weight of the regression branch.&lt;/span&gt;
    roi_head&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# RoIHead encapsulates the second stage of two-stage/cascade detectors.&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;StandardRoIHead&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of the RoI head. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/standard_roi_head.py#L10 for implementation.&lt;/span&gt;
        bbox_roi_extractor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# RoI feature extractor for bbox regression.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;SingleRoIExtractor&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of the RoI feature extractor, most of methods uses SingleRoIExtractor. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/roi_extractors/single_level.py#L10 for details.&lt;/span&gt;
            roi_layer&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of RoI Layer&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RoIAlign&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/ops/roi_align/roi_align.py#L79 for details.&lt;/span&gt;
                output_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;7&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The output size of feature maps.&lt;/span&gt;
                sampling_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Sampling ratio when extracting the RoI features. 0 means adaptive ratio.&lt;/span&gt;
            out_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# output channels of the extracted feature.&lt;/span&gt;
            featmap_strides&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;]),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Strides of multi-scale feature maps. It should be consistent to the architecture of the backbone.&lt;/span&gt;
        bbox_head&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of box head in the RoIHead.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Shared2FCBBoxHead&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of the bbox head, Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py#L177 for implementation details.&lt;/span&gt;
            in_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Input channels for bbox head. This is consistent with the out_channels in roi_extractor&lt;/span&gt;
            fc_out_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1024&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Output feature channels of FC layers.&lt;/span&gt;
            roi_feat_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;7&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Size of RoI features&lt;/span&gt;
            num_classes&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;80&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Number of classes for classification&lt;/span&gt;
            bbox_coder&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Box coder used in the second stage.&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;DeltaXYWHBBoxCoder&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of box coder. &amp;#39;DeltaXYWHBBoxCoder&amp;#39; is applied for most of methods.&lt;/span&gt;
                target_means&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.0&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Means used to encode and decode box&lt;/span&gt;
                target_stds&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.2&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;0.2&lt;/span&gt;]),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Standard variance for encoding and decoding. It is smaller since the boxes are more accurate. [0.1, 0.1, 0.2, 0.2] is a conventional setting.&lt;/span&gt;
            reg_class_agnostic&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether the regression is class agnostic.&lt;/span&gt;
            loss_cls&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of loss function for the classification branch&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CrossEntropyLoss&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of loss for classification branch, we also support FocalLoss etc.&lt;/span&gt;
                use_sigmoid&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to use sigmoid.&lt;/span&gt;
                loss_weight&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Loss weight of the classification branch.&lt;/span&gt;
            loss_bbox&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of loss function for the regression branch.&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;L1Loss&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of loss, we also support many IoU Losses and smooth L1-loss, etc.&lt;/span&gt;
                loss_weight&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;)),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Loss weight of the regression branch.&lt;/span&gt;
        mask_roi_extractor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# RoI feature extractor for bbox regression.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;SingleRoIExtractor&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of the RoI feature extractor, most of methods uses SingleRoIExtractor.&lt;/span&gt;
            roi_layer&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of RoI Layer that extracts features for instance segmentation&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RoIAlign&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported&lt;/span&gt;
                output_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;14&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The output size of feature maps.&lt;/span&gt;
                sampling_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Sampling ratio when extracting the RoI features.&lt;/span&gt;
            out_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Output channels of the extracted feature.&lt;/span&gt;
            featmap_strides&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;]),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Strides of multi-scale feature maps.&lt;/span&gt;
        mask_head&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Mask prediction head&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;FCNMaskHead&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of mask head, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py#L21 for implementation details.&lt;/span&gt;
            num_convs&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;4&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Number of convolutional layers in mask head.&lt;/span&gt;
            in_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Input channels, should be consistent with the output channels of mask roi extractor.&lt;/span&gt;
            conv_out_channels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Output channels of the convolutional layer.&lt;/span&gt;
            num_classes&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;80&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Number of class to be segmented.&lt;/span&gt;
            loss_mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of loss function for the mask branch.&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CrossEntropyLoss&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of loss used for segmentation&lt;/span&gt;
                use_mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to only train the mask in the correct class.&lt;/span&gt;
                loss_weight&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1.0&lt;/span&gt;))))  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Loss weight of mask branch.&lt;/span&gt;
    train_cfg &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of training hyperparameters for rpn and rcnn&lt;/span&gt;
        rpn&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Training config of rpn&lt;/span&gt;
            assigner&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of assigner&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MaxIoUAssigner&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of assigner, MaxIoUAssigner is used for many common detectors. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10 for more details.&lt;/span&gt;
                pos_iou_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.7&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoU &amp;gt;= threshold 0.7 will be taken as positive samples&lt;/span&gt;
                neg_iou_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.3&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoU &amp;lt; threshold 0.3 will be taken as negative samples&lt;/span&gt;
                min_pos_iou&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.3&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The minimal IoU threshold to take boxes as positive samples&lt;/span&gt;
                match_low_quality&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to match the boxes under low quality (see API doc for more details).&lt;/span&gt;
                ignore_iof_thr&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoF threshold for ignoring bboxes&lt;/span&gt;
            sampler&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of positive/negative sampler&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomSampler&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8 for implementation details.&lt;/span&gt;
                num&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;256&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Number of samples&lt;/span&gt;
                pos_fraction&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The ratio of positive samples in the total samples.&lt;/span&gt;
                neg_pos_ub&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The upper bound of negative samples based on the number of positive samples.&lt;/span&gt;
                add_gt_as_proposals&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether add GT as proposals after sampling.&lt;/span&gt;
            allowed_border&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The border allowed after padding for valid anchors.&lt;/span&gt;
            pos_weight&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The weight of positive samples during training.&lt;/span&gt;
            debug&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to set the debug mode&lt;/span&gt;
        rpn_proposal&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config to generate proposals during training&lt;/span&gt;
            nms_across_levels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to do NMS for boxes across levels. Only work in `GARPNHead`, naive rpn does not support do nms cross levels.&lt;/span&gt;
            nms_pre&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;2000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes before NMS&lt;/span&gt;
            nms_post&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes to be kept by NMS, Only work in `GARPNHead`.&lt;/span&gt;
            max_per_img&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes to be kept after NMS.&lt;/span&gt;
            nms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;( &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of nms&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;nms&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;#Type of nms&lt;/span&gt;
                iou_threshold&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.7&lt;/span&gt; &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# NMS threshold&lt;/span&gt;
                ),
            min_bbox_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The allowed minimal box size&lt;/span&gt;
        rcnn&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config for the roi heads.&lt;/span&gt;
            assigner&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of assigner for second stage, this is different for that in rpn&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MaxIoUAssigner&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of assigner, MaxIoUAssigner is used for all roi_heads for now. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10 for more details.&lt;/span&gt;
                pos_iou_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoU &amp;gt;= threshold 0.5 will be taken as positive samples&lt;/span&gt;
                neg_iou_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoU &amp;lt; threshold 0.5 will be taken as negative samples&lt;/span&gt;
                min_pos_iou&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The minimal IoU threshold to take boxes as positive samples&lt;/span&gt;
                match_low_quality&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to match the boxes under low quality (see API doc for more details).&lt;/span&gt;
                ignore_iof_thr&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# IoF threshold for ignoring bboxes&lt;/span&gt;
            sampler&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomSampler&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8 for implementation details.&lt;/span&gt;
                num&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;512&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Number of samples&lt;/span&gt;
                pos_fraction&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.25&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The ratio of positive samples in the total samples.&lt;/span&gt;
                neg_pos_ub&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The upper bound of negative samples based on the number of positive samples.&lt;/span&gt;
                add_gt_as_proposals&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True
            ),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether add GT as proposals after sampling.&lt;/span&gt;
            mask_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;28&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Size of mask&lt;/span&gt;
            pos_weight&lt;span style=&#34;color:#555&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The weight of positive samples during training.&lt;/span&gt;
            debug&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False))  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to set the debug mode&lt;/span&gt;
    test_cfg &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config for testing hyperparameters for rpn and rcnn&lt;/span&gt;
        rpn&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config to generate proposals during testing&lt;/span&gt;
            nms_across_levels&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to do NMS for boxes across levels. Only work in `GARPNHead`, naive rpn does not support do nms cross levels.&lt;/span&gt;
            nms_pre&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes before NMS&lt;/span&gt;
            nms_post&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes to be kept by NMS, Only work in `GARPNHead`.&lt;/span&gt;
            max_per_img&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1000&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of boxes to be kept after NMS.&lt;/span&gt;
            nms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;( &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of nms&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;nms&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;#Type of nms&lt;/span&gt;
                iou_threshold&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.7&lt;/span&gt; &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# NMS threshold&lt;/span&gt;
                ),
            min_bbox_size&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The allowed minimal box size&lt;/span&gt;
        rcnn&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config for the roi heads.&lt;/span&gt;
            score_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.05&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Threshold to filter out boxes&lt;/span&gt;
            nms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config of nms in the second stage&lt;/span&gt;
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;nms&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of nms&lt;/span&gt;
                iou_thr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# NMS threshold&lt;/span&gt;
            max_per_img&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;100&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Max number of detections of each image&lt;/span&gt;
            mask_thr_binary&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;))  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Threshold of mask prediction&lt;/span&gt;
dataset_type &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CocoDataset&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Dataset type, this will be used to define the dataset&lt;/span&gt;
data_root &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Root path of data&lt;/span&gt;
img_norm_cfg &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Image normalization config to normalize the input images&lt;/span&gt;
    mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Mean values used to pre-training the pre-trained backbone models&lt;/span&gt;
    std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Standard variance used to pre-training the pre-trained backbone models&lt;/span&gt;
    to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True
)  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The channel orders of image used to pre-training the pre-trained backbone models&lt;/span&gt;
train_pipeline &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; [  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Training pipeline&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadImageFromFile&amp;#39;&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# First pipeline to load images from file path&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadAnnotations&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Second pipeline to load annotations for current image&lt;/span&gt;
        with_bbox&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to use bounding box, True for detection&lt;/span&gt;
        with_mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to use instance mask, True for instance segmentation&lt;/span&gt;
        poly2mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to convert the polygon mask to instance mask, set False for acceleration and to save memory&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Resize&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Augmentation pipeline that resize the images and their annotations&lt;/span&gt;
        img_scale&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;1333&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;800&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The largest scale of image&lt;/span&gt;
        keep_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True
    ),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# whether to keep the ratio between height and width.&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomFlip&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Augmentation pipeline that flip the images and their annotations&lt;/span&gt;
        flip_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The ratio or probability to flip&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Normalize&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Augmentation pipeline that normalize the input images&lt;/span&gt;
        mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# These keys are the same of img_norm_cfg since the&lt;/span&gt;
        std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# keys of img_norm_cfg are used here as arguments&lt;/span&gt;
        to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Pad&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Padding config&lt;/span&gt;
        size_divisor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number the padded images should be divisible&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;DefaultFormatBundle&amp;#39;&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Default format bundle to gather data in the pipeline&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Collect&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Pipeline that decides which keys in the data should be passed to the detector&lt;/span&gt;
        keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_bboxes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_labels&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_masks&amp;#39;&lt;/span&gt;])
]
test_pipeline &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadImageFromFile&amp;#39;&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# First pipeline to load images from file path&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MultiScaleFlipAug&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# An encapsulation that encapsulates the testing augmentations&lt;/span&gt;
        img_scale&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;1333&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;800&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Decides the largest scale for testing, used for the Resize pipeline&lt;/span&gt;
        flip&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to flip images during testing&lt;/span&gt;
        transforms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Resize&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Use resize augmentation&lt;/span&gt;
                 keep_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Whether to keep the ratio between height and width, the img_scale set here will be suppressed by the img_scale set above.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomFlip&amp;#39;&lt;/span&gt;),  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Thought RandomFlip is added in pipeline, it is not used because flip=False&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Normalize&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Normalization config, the values are from img_norm_cfg&lt;/span&gt;
                mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],
                std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],
                to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Pad&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Padding config to pad images divisable by 32.&lt;/span&gt;
                size_divisor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;ImageToTensor&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# convert image to tensor&lt;/span&gt;
                keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;]),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Collect&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Collect pipeline that collect necessary keys for testing.&lt;/span&gt;
                keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;])
        ])
]
data &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
    samples_per_gpu&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;2&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Batch size of a single GPU&lt;/span&gt;
    workers_per_gpu&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;2&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Worker to pre-fetch data for each single GPU&lt;/span&gt;
    train&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Train dataset config&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CocoDataset&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of dataset, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py#L19 for details.&lt;/span&gt;
        ann_file&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/annotations/instances_train2017.json&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Path of annotation file&lt;/span&gt;
        img_prefix&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/train2017/&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Prefix of image path&lt;/span&gt;
        pipeline&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# pipeline, this is passed by the train_pipeline created before.&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadImageFromFile&amp;#39;&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadAnnotations&amp;#39;&lt;/span&gt;,
                with_bbox&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,
                with_mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True,
                poly2mask&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Resize&amp;#39;&lt;/span&gt;, img_scale&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;1333&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;800&lt;/span&gt;), keep_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomFlip&amp;#39;&lt;/span&gt;, flip_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.5&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Normalize&amp;#39;&lt;/span&gt;,
                mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],
                std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],
                to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Pad&amp;#39;&lt;/span&gt;, size_divisor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;DefaultFormatBundle&amp;#39;&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Collect&amp;#39;&lt;/span&gt;,
                keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_bboxes&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_labels&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;gt_masks&amp;#39;&lt;/span&gt;])
        ]),
    val&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Validation dataset config&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CocoDataset&amp;#39;&lt;/span&gt;,
        ann_file&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/annotations/instances_val2017.json&amp;#39;&lt;/span&gt;,
        img_prefix&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/val2017/&amp;#39;&lt;/span&gt;,
        pipeline&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Pipeline is passed by test_pipeline created before&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadImageFromFile&amp;#39;&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MultiScaleFlipAug&amp;#39;&lt;/span&gt;,
                img_scale&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;1333&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;800&lt;/span&gt;),
                flip&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,
                transforms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Resize&amp;#39;&lt;/span&gt;, keep_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomFlip&amp;#39;&lt;/span&gt;),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Normalize&amp;#39;&lt;/span&gt;,
                        mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],
                        std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],
                        to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Pad&amp;#39;&lt;/span&gt;, size_divisor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;ImageToTensor&amp;#39;&lt;/span&gt;, keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;]),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Collect&amp;#39;&lt;/span&gt;, keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;])
                ])
        ]),
    test&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Test dataset config, modify the ann_file for test-dev/test submission&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;CocoDataset&amp;#39;&lt;/span&gt;,
        ann_file&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/annotations/instances_val2017.json&amp;#39;&lt;/span&gt;,
        img_prefix&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;data/coco/val2017/&amp;#39;&lt;/span&gt;,
        pipeline&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Pipeline is passed by test_pipeline created before&lt;/span&gt;
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;LoadImageFromFile&amp;#39;&lt;/span&gt;),
            &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;MultiScaleFlipAug&amp;#39;&lt;/span&gt;,
                img_scale&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#f60&#34;&gt;1333&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;800&lt;/span&gt;),
                flip&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;False,
                transforms&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Resize&amp;#39;&lt;/span&gt;, keep_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;RandomFlip&amp;#39;&lt;/span&gt;),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(
                        &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Normalize&amp;#39;&lt;/span&gt;,
                        mean&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;123.675&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;116.28&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;103.53&lt;/span&gt;],
                        std&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;58.395&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.12&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;57.375&lt;/span&gt;],
                        to_rgb&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;True),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Pad&amp;#39;&lt;/span&gt;, size_divisor&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;32&lt;/span&gt;),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;ImageToTensor&amp;#39;&lt;/span&gt;, keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;]),
                    &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;Collect&amp;#39;&lt;/span&gt;, keys&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;])
                ])
        ],
        samples_per_gpu&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;2&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Batch size of a single GPU used in testing&lt;/span&gt;
        ))
evaluation &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The config to build the evaluation hook, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/evaluation/eval_hooks.py#L7 for more details.&lt;/span&gt;
    interval&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Evaluation interval&lt;/span&gt;
    metric&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;bbox&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;segm&amp;#39;&lt;/span&gt;])  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Metrics used during evaluation&lt;/span&gt;
optimizer &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config used to build optimizer, support all the optimizers in PyTorch whose arguments are also the same as those in PyTorch&lt;/span&gt;
    &lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;SGD&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Type of optimizers, refer to https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/optimizer/default_constructor.py#L13 for more details&lt;/span&gt;
    lr&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.02&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Learning rate of optimizers, see detail usages of the parameters in the documentaion of PyTorch&lt;/span&gt;
    momentum&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.9&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Momentum&lt;/span&gt;
    weight_decay&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;0.0001&lt;/span&gt;)  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Weight decay of SGD&lt;/span&gt;
optimizer_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config used to build the optimizer hook, refer to https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py#L8 for implementation details.&lt;/span&gt;
    grad_clip&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;None)  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Most of the methods do not use gradient clip&lt;/span&gt;
lr_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Learning rate scheduler config used to register LrUpdater hook&lt;/span&gt;
    policy&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;step&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The policy of scheduler, also support CosineAnnealing, Cyclic, etc. Refer to details of supported LrUpdater from https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9.&lt;/span&gt;
    warmup&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The warmup policy, also support `exp` and `constant`.&lt;/span&gt;
    warmup_iters&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;500&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The number of iterations for warmup&lt;/span&gt;
    warmup_ratio&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#f60&#34;&gt;0.001&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The ratio of the starting learning rate used for warmup&lt;/span&gt;
    step&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#f60&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;11&lt;/span&gt;])  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Steps to decay the learning rate&lt;/span&gt;
runner &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;EpochBasedRunner&amp;#39;&lt;/span&gt;, max_epochs&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;12&lt;/span&gt;) &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Runner that runs the workflow in total max_epochs&lt;/span&gt;
checkpoint_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Config to set the checkpoint hook, Refer to https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py for implementation.&lt;/span&gt;
    interval&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The save interval is 1&lt;/span&gt;
log_config &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# config to register logger hook&lt;/span&gt;
    interval&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;50&lt;/span&gt;,  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Interval to print the log&lt;/span&gt;
    hooks&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;[
        &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# dict(type=&amp;#39;TensorboardLoggerHook&amp;#39;)  # The Tensorboard logger is also supported&lt;/span&gt;
        &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(&lt;span style=&#34;color:#366&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;TextLoggerHook&amp;#39;&lt;/span&gt;)
    ])  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The logger used to record the training process.&lt;/span&gt;
dist_params &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;dict&lt;/span&gt;(backend&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;nccl&amp;#39;&lt;/span&gt;)  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Parameters to setup distributed training, the port can also be set.&lt;/span&gt;
log_level &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;INFO&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# The level of logging.&lt;/span&gt;
load_from &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; None  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# load models as a pre-trained model from a given path. This will not resume training.&lt;/span&gt;
resume_from &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; None  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Resume checkpoints from a given path, the training will be resumed from the epoch when the checkpoint&amp;#39;s is saved.&lt;/span&gt;
workflow &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; [(&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;)]  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Workflow for runner. [(&amp;#39;train&amp;#39;, 1)] means there is only one workflow and the workflow named &amp;#39;train&amp;#39; is executed once. The workflow trains the model by 12 epochs according to the total_epochs.&lt;/span&gt;
work_dir &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;work_dir&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Directory to save the model checkpoints and logs for the current experiments.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: 常见问题</title>
      <link>https://Joevaen.github.io/docs/languages/cpp/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/languages/cpp/faq/</guid>
      <description>
        
        
        
      </description>
    </item>
    
  </channel>
</rss>
