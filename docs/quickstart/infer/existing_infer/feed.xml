<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joevaen – 用现有模型进行推理</title>
    <link>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/</link>
    <description>Recent content in 用现有模型进行推理 on Joevaen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/docs/quickstart/infer/existing_infer/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: 推理的api</title>
      <link>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/api/</guid>
      <description>
        
        
        &lt;p&gt;MMDetection provide high-level Python APIs for inference on images. Here is an example of building the model and inference on given images or videos.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmdet.apis&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; init_detector, inference_detector
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmcv&lt;/span&gt;

&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# Specify the path to model config and checkpoint file&lt;/span&gt;
config_file &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&amp;#39;&lt;/span&gt;
checkpoint_file &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# build the model from a config file and a checkpoint file&lt;/span&gt;
model &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; init_detector(config_file, checkpoint_file, device&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;cuda:0&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# test a single image and show the results&lt;/span&gt;
img &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;test.jpg&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# or img = mmcv.imread(img), which will only load it once&lt;/span&gt;
result &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; inference_detector(model, img)
&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# visualize the results in a new window&lt;/span&gt;
model&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;show_result(img, result)
&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# or save the visualization results to image files&lt;/span&gt;
model&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;show_result(img, result, out_file&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;result.jpg&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# test a video and show the results&lt;/span&gt;
video &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; mmcv&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;VideoReader(&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;video.mp4&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;for&lt;/span&gt; frame &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;in&lt;/span&gt; video:
    result &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; inference_detector(model, frame)
    model&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;show_result(frame, result, wait_time&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f60&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A notebook demo can be found in &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/blob/master/demo/inference_demo.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;demo/inference_demo.ipynb&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note:  &lt;code&gt;inference_detector&lt;/code&gt; only supports single-image inference for now.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 异步接口</title>
      <link>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/interface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/interface/</guid>
      <description>
        
        
        &lt;p&gt;For Python 3.7+, MMDetection also supports async interfaces.
By utilizing CUDA streams, it allows not to block CPU on GPU bound inference code and enables better CPU/GPU utilization for single-threaded application. Inference can be done concurrently either between different input data samples or between different models of some inference pipeline.&lt;/p&gt;
&lt;p&gt;See &lt;code&gt;tests/async_benchmark.py&lt;/code&gt; to compare the speed of synchronous and asynchronous interfaces.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;asyncio&lt;/span&gt;
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;torch&lt;/span&gt;
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmdet.apis&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; init_detector, async_inference_detector
&lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#0cf;font-weight:bold&#34;&gt;mmdet.utils.contextmanagers&lt;/span&gt; &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;import&lt;/span&gt; concurrent

async &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#c0f&#34;&gt;main&lt;/span&gt;():
    config_file &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py&amp;#39;&lt;/span&gt;
    checkpoint_file &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth&amp;#39;&lt;/span&gt;
    device &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;cuda:0&amp;#39;&lt;/span&gt;
    model &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; init_detector(config_file, checkpoint&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;checkpoint_file, device&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;device)

    &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# queue is used for concurrent inference of multiple images&lt;/span&gt;
    streamqueue &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; asyncio&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;Queue()
    &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# queue size defines concurrency level&lt;/span&gt;
    streamqueue_size &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f60&#34;&gt;3&lt;/span&gt;

    &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#366&#34;&gt;range&lt;/span&gt;(streamqueue_size):
        streamqueue&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;put_nowait(torch&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;cuda&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;Stream(device&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;device))

    &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# test a single image and show the results&lt;/span&gt;
    img &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;test.jpg&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# or img = mmcv.imread(img), which will only load it once&lt;/span&gt;

    async &lt;span style=&#34;color:#069;font-weight:bold&#34;&gt;with&lt;/span&gt; concurrent(streamqueue):
        result &lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt; await async_inference_detector(model, img)

    &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# visualize the results in a new window&lt;/span&gt;
    model&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;show_result(img, result)
    &lt;span style=&#34;color:#09f;font-style:italic&#34;&gt;# or save the visualization results to image files&lt;/span&gt;
    model&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;show_result(img, result, out_file&lt;span style=&#34;color:#555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#c30&#34;&gt;&amp;#39;result.jpg&amp;#39;&lt;/span&gt;)


asyncio&lt;span style=&#34;color:#555&#34;&gt;.&lt;/span&gt;run(main())

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: 演示</title>
      <link>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/demo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/docs/quickstart/infer/existing_infer/demo/</guid>
      <description>
        
        
        &lt;p&gt;We also provide three demo scripts, implemented with high-level APIs and supporting functionality codes.
Source codes are available &lt;a href=&#34;https://github.com/open-mmlab/mmdetection/tree/master/demo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
