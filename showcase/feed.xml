<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joevaen – 论文译解</title>
    <link>https://Joevaen.github.io/showcase/</link>
    <description>Recent content in 论文译解 on Joevaen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="https://Joevaen.github.io/showcase/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Showcase: 前列腺近距离放射治疗中，检测粒子在CT中的3D位置和方向</title>
      <link>https://Joevaen.github.io/showcase/paper/paper1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper1/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;前列腺近距离放射治疗中，检测粒子在CT中的3D位置和方向&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2材料&#34;&gt;2.材料&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3方法&#34;&gt;3.方法&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#3a-使用连接对象分割进行粒子定位&#34;&gt;3.A 使用连接对象分割进行粒子定位&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#3b-font-colorred使用pca来进行方向估计font&#34;&gt;3.B &lt;font color=red&gt;使用PCA来进行方向估计&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#3c-使用聚类方法对union-seed进行分离&#34;&gt;3.C 使用聚类方法对&lt;code&gt;union-seed&lt;/code&gt;进行分离&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4结果&#34;&gt;4.结果&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#4a-实验设置&#34;&gt;4.A 实验设置&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#4b-体模实验&#34;&gt;4.B 体模实验&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#4c-病例实验&#34;&gt;4.C 病例实验&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5总结&#34;&gt;5.总结&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;p&gt;@[TOC](《Automatic 3D seed location and orientation in CT
images for prostate brachytherapy》)&lt;/p&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.&lt;font color=red&gt;&lt;strong&gt;Pre-MICCAI&lt;/strong&gt;&lt;/font&gt;是我为了进一步了解MICCAI某些相当有意义论文的发展历史而采取的一种追根溯源的方法，在这个系列中我会将这篇论文所提到的之前的论文进行一定的了解，便于更深层次的学习和了解整个算法要解决哪些之前的问题，同时借鉴前人的思想来丰富自己的知识库；&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示对原来的理解做的一些修改或补充&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示本文的重要关键字&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三、本文基于论文《&lt;strong&gt;A Deep Regression Model for Seed Localizationin Prostate Brachytherapy&lt;/strong&gt;》&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;在前列腺近距离治疗中，对每个植入的粒子的3D姿势信息的分析是剂量计算和质量评估的关键问题之一。 本文介绍了一种用于前列腺粒子的分离、定位和3D方向估计的自动图像处理解决方案。 该解决方案将对CT图像中的一组候选粒子的初始检测（使用阈值和连接成分方法）与使用主成分分析（PCA）的方向估计结合在一起。 这项工作的主要创意是能够根据先验强度和体积信息对检测到的物体进行分类，并使用改进的k均值方法将种子分组。 在体模和患者的CT图像上进行了实验，目的是在检测性能和计算时间方面将建议的解决方案与手动分割或其他先前的工作进行比较。&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;前列腺癌具有2006年至2010年全球每年每100,000名男性中152人的发病率，被认为是男性具有第二大发病率的癌症。 前列腺癌的诊断和治疗方法的改进变得越来越重要。 使用低剂量放射性粒子的低风险前列腺近距离放射疗法是一种处理局部前列腺癌的常见且高效的方法。 通过平行针将散落或搁浅的粒子插入前列腺。 在实践中，植入前列腺的粒子数量通常为40到100。手术的目的是定位种子，以在整个前列腺中获得适当的剂量覆盖，同时限制对邻近器官的风险。 理论上，粒子应与针插入方向对齐。然而，实际上，粒子植入取决于许多生物力学因素以及人类经验。 因此，尽管在放置针头和运送种子时进行了任何特殊的护理或努力，粒子仍可能掉出位置。 这也可能导致成排紧密排列的粒子。 我们将这样的重叠粒子命名为&lt;code&gt;union-seed&lt;/code&gt;（&lt;strong&gt;图1&lt;/strong&gt;）。 为了进行治疗质量评估，通常在手术后一个月进行PID，一旦前列腺的任何炎症反应消失，便会进行基于CT的剂量测定。 CT检查通常显示粒子在植入方向上未对齐，并且粒子可能会迁移。尽管美国医学物理学会建议根据实际粒子的位置和方向确定近距离放射治疗粒子的3D剂量分布，但大多数治疗计划软件仍在假设所有粒子均与CT的轴对齐这个前提。因此，粒子的最佳位置和方向（包括分离&lt;code&gt;union-seed&lt;/code&gt;的能力）是评估前列腺近距离放疗的主要挑战。
&lt;strong&gt;图1：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113152901217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113152901217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;因此粒子的定位已被广泛研究和发表。 例如，在[&lt;code&gt;《. Kuo et al., “Mri-based prostate brachytherapy seed localization,” ISBI, pp. 1397–1400, 2010》&lt;/code&gt;]中考虑使用高斯的拉普拉斯算子进行斑点检测来确定&lt;font color=red&gt;&lt;strong&gt;IRON图像&lt;/strong&gt;（利用共振水抑制进行反转-恢复）&lt;/font&gt;中的粒子位置，而没有明确提及粒子的方向。（&lt;font color=blue&gt;笔者人已经傻了，在之前的工作中我恰恰是使用了这样的算子检测手段，实现了粒子的检测，真没想到在这儿遇到了祖师爷。&lt;/font&gt;）Wei等人在[&lt;code&gt;《. Wei et al., “Automated localization of implanted seeds in 3d trus images used for prostate brachytherapy,” Medical Physics, vol. 33(7), pp. 2404–2417, 2006》&lt;/code&gt;]中从背景图和植入后的超声图像之间的减影图中分割出粒子，然后将PCA方法应用于方向检测。 还报道了粒子在X射线图像中的定位，例如在[&lt;code&gt;《 Lee et al.,“Prostate Brachytherapy Seed Localization with Gaussian Blurring and Camera Self-calibration”,MICCAI, pp. 636-643, 2008.》&lt;/code&gt;]中使用高斯模糊图像进行体积重建，取得了有意义的进展。 Chng等人在[《&lt;code&gt; Chng et al., “Prostate brachytherapy postimplant dosimetry: Seed orientation   and   the   impact   of   dosimetric   anisotropy   in   stranded implants,” Medical Physics, vol. 39, pp. 721–731, 2012.&lt;/code&gt;》]中估计了从切向量到粒子链的粒子切线的方向，该粒子链在植入CT后的每个粒子位置处确定。 大量论文都考虑了粒子的发散，其实际方向通常更接近计划的粒子。 但是，这些类型的粒子限制了临床医生规划剂量的能力。 而且，这些方法不能处理&lt;code&gt;union-seed&lt;/code&gt;。
我们已经开始在机构中开发植入手术后图像处理软件，强调较小的计算复杂性和粒子检测的高效率。 在这项研究中，我们利用CT图像中放射性粒子的高强度外观，寻求一种基于阈值化和关联成分分割的解决方案。除了精确定位粒子位置和方向外，我们还进行了对&lt;code&gt;union-seed&lt;/code&gt;的分割。 在此，将PCA方法用于方向估计，并改进了k均值分割方法。 本文的组织结构如下：在第二节中，介绍了此工作中使用的材料；在第三节中，我们描述了建议的解决方案；在第四节中报告了对来自体模和一名匿名患者的数据集的评估。 然后，我们将在第五节中讨论该方法的主要贡献和潜在扩展。&lt;/p&gt;
&lt;h2 id=&#34;2材料&#34;&gt;2.材料&lt;/h2&gt;
&lt;p&gt;格勒诺布尔大学医院的临床团队使用BEBIGIsoSeed®$I-125$种子。 种子由圆柱形陶瓷材料制成，并在中心充满了放射性碘125化合物和金标记，它们全部被激光密封的钛管包围。 种子的外部物理尺寸为$l = 4.5±0.2mm$长和$r = 0.4±0.02mm$外部半径。碘125同位素以35keV的最大能量发射光子，半衰期为59.46天。 该信息由制造商提供。
3DCT图像是使用GE Lightspeed RT16扫描仪获得的，默认X射线管参数为：120kVp，380-440mA.s。切片宽度为0.625mm，每个切片为16帧/秒。图像重建矩阵以512x512的DICOM 3.0格式归档，具有16位灰度级。&lt;/p&gt;
&lt;h2 id=&#34;3方法&#34;&gt;3.方法&lt;/h2&gt;
&lt;h3 id=&#34;3a-使用连接对象分割进行粒子定位&#34;&gt;3.A 使用连接对象分割进行粒子定位&lt;/h3&gt;
&lt;p&gt;初始步骤是使用分割方法检测候选粒子列表。已经提出了图像处理中的许多方法来分割图像中的单个对象，例如图像分割、分水岭转换和水平集。 在本文中，由于仅使用强度阈值 $t$ 很简单且计算效率高，因此考虑了&lt;strong&gt;连接组件标记方法&lt;/strong&gt;。 确实，我们首先根据 $t$ 对原始体积进行阈值分割，然后为每个连接的组件（26个像素为一个连接域）分配一个标签 $i$。与连接的组件相对应的所有体素都具有相同的标签，该标签对于其特定组件是唯一的。 将每个组件的位置确定为其质心 $c_i$。
在这项工作中，强度阈值 $t$ 的选择可以基于粒子的X射线吸收的图像特征和物理特征来启发式设置。 &lt;strong&gt;图2&lt;/strong&gt;显示了在患者的CT图像中检测到的连接组件的示例。 我们可以假设骨盆骨骼是非常大的组成部分，其体积比种子的实际体积大100倍（表示为$RV =r^2πl$）。 相反，噪声由微小的成分组成，其体积不到RV的三分之一。 骨盆的骨头和噪音被清除。 其他成分保留为候选粒子，由两种类型组成：&lt;code&gt;single-seed&lt;/code&gt;和&lt;code&gt;union-seed&lt;/code&gt;。&lt;code&gt;union-seed&lt;/code&gt;基于与&lt;code&gt;single-seed&lt;/code&gt;相比的体积（表示为Vsingle）进行分类。 实际上，&lt;code&gt;union-seed&lt;/code&gt;最多可以包含4或5个粒子。 在第一阶段，&lt;code&gt;union-seed&lt;/code&gt;不能分开。 实际上，&lt;code&gt;union-seed&lt;/code&gt;总是会导致位置和方向估计的潜在误差。 因此，我们在第III.C节中提出提出此方法的一个分离方案。
&lt;strong&gt;图2：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113152835168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113152835168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;3b-font-colorred使用pca来进行方向估计font&#34;&gt;3.B &lt;font color=red&gt;使用PCA来进行方向估计&lt;/font&gt;&lt;/h3&gt;
&lt;p&gt;考虑到每个组件中的 $n$ 个检测到的体素的集合，该&lt;strong&gt;3.B&lt;/strong&gt;阶段旨在估计组件的3D方向。 已经有人提出了许多方法，包括&lt;strong&gt;3D Hough平面变换&lt;/strong&gt;[&lt;code&gt;W. Qiu et al., “Needle segmentation using 3d hough transform in 3d trus   guided   prostate   transperineal therapy,”  Medical  Physics,  vol. 40,p. 042902, 2013&lt;/code&gt;]或&lt;strong&gt;最小包围边界框&lt;/strong&gt;[&lt;code&gt;. Lahanas et al., “Optimized bounding boxes for three-dimensional treatment   planning   in   brachytherapy,”   Medical   Physics,   vol.   27, pp.2333–2342, 2000&lt;/code&gt;]。 然而，由于这些方法的复杂性和图像伪影的高度影响，这些方法不适合在医学图像中识别。 在这项工作中，我们重点研究了一种3D方向估计的解决方案，该解决方案将通过研究PCA方法来改善这两个方面。 PCA方法是通过拒绝低方差特征来压缩和提取一组相关观测值的描述的最简单，最可靠的数学程序。 考虑到 $p$ 维特征向量（在我们的示例中为3维），PCA方法将把此数据投影到 $q$ 个主成分上。&lt;font color=red&gt; 第一主成分$v_1$ 是沿着具有点云协方差矩阵 $C$ 的最大特征值 $λ_1$投影的特征空间。 选择它作为对象的方向。 第二主成分 $v2$ 是在和第一主成分$v_1$的所有正交的方向中方差中最大的那个方向。&lt;/font&gt;&lt;/p&gt;
&lt;h3 id=&#34;3c-使用聚类方法对union-seed进行分离&#34;&gt;3.C 使用聚类方法对&lt;code&gt;union-seed&lt;/code&gt;进行分离&lt;/h3&gt;
&lt;p&gt;通过连接的组件标记检测到的每个&lt;code&gt;union-seed&lt;/code&gt;的体素集，我们研究一种使用k-均值聚类方法的无监督分类方法[&lt;code&gt;.   Han   et   al.,   Data   Mining:   Concepts   and   Techniques.   Morgan Kaufmann, 2011&lt;/code&gt;]。 通过将每个体素重新标记为属于具有最近均值的聚类，我们将这些成分分成k个粒子。 通过将分量体积$V$与$V_{single}$比较：$k = V / V_{single}$，将四舍五入到最接近的整数值，获得在联合种子中分组的种子数 $k$。我们首先随机选择 $k$ 个点作为初始簇质心。 然后，将每个体素分配给最近的质心。 我们重复此过程，直到所有质心不再变化为止。
K-means算法在许多分类应用中显示出其计算简便性。 但是，由于所得簇强烈依赖于初始质心的选择以及簇共享区域的大小和形状差异，因此k均值存在一些局限性。 在实践中，当分离平行粒子组时，这种经典的k均值方法存在最大的误差（请参见第四节）。因此，我们提出了一种改进方法&lt;code&gt;k-means-for-seeds&lt;/code&gt;，通过利用PCA提供的信息来选择k-means算法的初始聚类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们首先使用PCA方法估计&lt;code&gt;union-seed&lt;/code&gt;的两个主要方向 ${v1，v2}$；&lt;/li&gt;
&lt;li&gt;然后，$（k-1）$平行平面由&lt;code&gt;union-seed&lt;/code&gt;的主方向 $v1$ 和它们之间的距离 $d =λ_2/ k$定义（见&lt;strong&gt;图3&lt;/strong&gt;），其中 $λ_2$ 是&lt;code&gt;union-seed&lt;/code&gt;的协方差矩阵 $C$ 的第二个特征值。 这些平行平面将&lt;code&gt;union-seed&lt;/code&gt;的空间划分为 $k$ 个分区。 最后，我们将k-means聚类算法与初始聚类中心一起应用，初始聚类中心是这 $k$ 个分区的质心。
&lt;strong&gt;图3：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113161011915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113161011915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

在这项工作中，我们对具有不同初始簇质心的经典k-means方法和k-means-FS方法进行了实验。 从质心方向信息中为&lt;code&gt;union-seed&lt;/code&gt;中检测到的每个单个粒子重建对应于粒子模型的圆柱体。然后，针对每种解决方案计算这些圆柱体形式和&lt;code&gt;union-seed&lt;/code&gt;共有的体素数量之和。 总和最大的解决方案被选为最佳解决方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4结果&#34;&gt;4.结果&lt;/h2&gt;
&lt;h3 id=&#34;4a-实验设置&#34;&gt;4.A 实验设置&lt;/h3&gt;
&lt;p&gt;所建议方法的验证是使用放射性碘125粒子的CT图像进行植入的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1）特殊制作的体模；&lt;/li&gt;
&lt;li&gt;2）来自格勒诺布尔大学医院提供的真实患者的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;手动将11个粒子放置在一个平板模型的表面上（尺寸9x9x0.5cm^3^）。 将成对的粒子以从垂直到平行的不同方向相互接触，其主要目的是评估分离各种类型的&lt;code&gt;uinon-seed&lt;/code&gt;的能力。粒子在体模中的参考位置基于手动检测（&lt;strong&gt;图4&lt;/strong&gt;）。 患者数据由前列腺近距离放射治疗期间植入的72颗粒子组成。 在第二个实验中考虑的CT扫描仪图像是在粒子植入后一个月拍摄的（图1）。使用临床治疗计划软件手动重建粒子在前列腺中的参考位置。
&lt;strong&gt;图4：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113165108770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113165108770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

所提出的解决方案的实现是基于我们的开源框架CamiTK（使用带有VTK和ITK库的C++）在3.4 GHz Intel Core i7-2600 CPU上构建的。有关DICOM图像的更多信息，请参见&lt;strong&gt;表1&lt;/strong&gt;。 CT图像中每种材料的体素强度（HU）为：体模材料[0,400]，患者软组织[0,400]，患者骨骼[0,1350]和粒子[500，max]。
为了将粒子的参考位置和方向与其检测到的位置和方向进行比较，我们使用了它们的质心    $c1，c2$ 与它们的方向矢量 $v1，v2$（&lt;strong&gt;等式1&lt;/strong&gt;）的点积之间的欧几里得距离，$||v_i||$ 是向量$v_i$的大小，距离 $Δd$ 的单位是mm，$Δθ$ 的单位是度:
$$\Delta{d}=\sqrt{\sum_{i=1}^3(c_{1i}-c_{2_i})^2},\Delta{\theta}=a\cos(\frac{v_1\cdot{v_2}}{{|v_1|}{|v_2|}})\tag{1}$$&lt;/p&gt;
&lt;h3 id=&#34;4b-体模实验&#34;&gt;4.B 体模实验&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;表2&lt;/strong&gt;显示了使用强度阈值t = 1400时检测到的粒子相对于参考位置的方向差 $Δθ$ 和距离 $Δd$ 的详细信息。使用$Δθ= 0.23^o$和$Δd= 0.02mm$的11号&lt;code&gt;single-seed&lt;/code&gt;获得了最佳检测结果。 相反，定向估计最困难的情况是平行&lt;code&gt;union-seed&lt;/code&gt;，即粒子几乎以相同的方向对齐（在这里是5号和6号粒子）。 距离误差最大的是&lt;code&gt;T形&lt;/code&gt;，即其中一个粒子与另一粒子刚好正交（1号和2号种子）。
&lt;strong&gt;表2：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/2021011317141841.png&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;2021011317141841&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-2021011317141841&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-2021011317141841&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/2021011317141841.png&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;strong&gt;表3&lt;/strong&gt;还体现了3种不同阈值选择的方向差$Δθ$和距离差$Δd$：[500,1400,7431]。 总体而言，我们针对20种以上的 $t$ 进行了该实验。 平均距离为0.13±0.07mm，而Chng方法为0.3mm。 平均取向为$1.32^o±0.9$，而Chng方法为$2^o$。 计算时间为3.15s±0.3，而Chng的方法为9s，同时他的手动确定参考数据需要30分钟以上。 由于体模和计算机系统不同，因此必须仔细解释这些比较。 另请注意，Chng的方法未考虑&lt;code&gt;union-seed&lt;/code&gt;分离。&lt;/p&gt;
&lt;h3 id=&#34;4c-病例实验&#34;&gt;4.C 病例实验&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;表3&lt;/strong&gt;和&lt;strong&gt;图5&lt;/strong&gt;显示了在实际前列腺近距离放射治疗的情况下所提出的粒子定位方法的结果。 72颗粒子全部被检测到。 最佳结果是在 $t = 1400$ 时获得的，其中没有错误检测，并且方向差与离参考值的距离最小。 在不同强度阈值 $t$ 的20次运行中，平均计算时间为10.1s。 与用于确定参考数据的手动检测相比，这是一种快速的解决方案。 从这些实验结果中，我们建议在[1300,1700]的间隔内选择强度阈值。
图5：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113172302427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113172302427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;5总结&#34;&gt;5.总结&lt;/h2&gt;
&lt;p&gt;在这项研究中，我们提出了一种精确，可靠和快速的方法，用于在CT图像中估计近距离治疗粒子的位置和方向。 它还可以自动可靠地分离&lt;code&gt;union-seed&lt;/code&gt;。 这些结果为改善剂量计算准确性和质量评估提供了潜力。 这种精确度对剂量的影响尚待证明，针对这一目标的研究已经针对一系列患者展开，它将单独出版。未来的工作将扩展到最佳强度阈值的自动选择和针对其他前列腺图像模式（例如超声）的粒子定位的可靠解决方案。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: 从植入粒子后的CT图像自动定位植入的粒子</title>
      <link>https://Joevaen.github.io/showcase/paper/paper2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper2/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;从植入粒子后的CT图像自动定位植入的粒子&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-方法和材料&#34;&gt;2. 方法和材料&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-算法描述&#34;&gt;2.1 算法描述&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-基于强度的ct阈值分割&#34;&gt;2.2 基于强度的CT阈值分割&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#23-几何区域分割&#34;&gt;2.3 几何区域分割&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#24-几何区域连通&#34;&gt;2.4 几何区域连通&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#25-确定种子位置和方向&#34;&gt;2.5 确定种子位置和方向&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3结果&#34;&gt;3.结果&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-最佳阈值确定&#34;&gt;3.1 最佳阈值确定&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-使用体模进行算法测试&#34;&gt;3.2 使用体模进行算法测试&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-使用实际的植入后ct图像进行算法测试&#34;&gt;3.3 使用实际的植入后CT图像进行算法测试&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#34-算法可移植性测试&#34;&gt;3.4 算法可移植性测试&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#35-植入后剂量&#34;&gt;3.5 植入后剂量&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4讨论&#34;&gt;4.讨论&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-算法的可移植性&#34;&gt;4.1 算法的可移植性&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-ct层厚上的选择建议&#34;&gt;4.2 CT层厚上的选择建议&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#总结&#34;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.&lt;font color=red&gt;&lt;strong&gt;Pre-MICCAI&lt;/strong&gt;&lt;/font&gt;是我为了进一步了解MICCAI某些相当有意义论文的发展历史而采取的一种追根溯源的方法，在这个系列中我会将这篇论文所提到的之前的论文进行一定的了解，便于更深层次的学习和了解整个算法要解决哪些之前的问题，同时借鉴前人的思想来丰富自己的知识库；&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示对原来的理解做的一些修改或补充&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示本文的重要关键字&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt; es》)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三、本文基于论文**《A Deep Regression Model for Seed Localizationin Prostate Brachytherapy》**&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;本文介绍了一种从一系列植入后CT图像中自动定位植入种子的方法。对接受前列腺近距离放射治疗的患者进行了植入后CT研究。 在每个CT切片中使用二进制阈值对明亮的区域进行分割，并收集这些区域的几何信息。 通过在每个切片中进行基于几何的过滤，将较大的区域（可能包含两个相连的种子）分成较小的区域。 使用基于几何学的连接搜索算法对每个区域切片进行纵向切片，分析沿纵向的区域连通性，从而将连通区域组合为一个对象。 将每个对象的加权质心作为这些位置。 该方法在含种子的前列腺幻象上进行了良好的测试，并通过患者的CT研究进行了统计分析。统计分析表明，该方法可以实现99％以上的检测率，并且定位准确，速度快。 对于在CT上定位植入的种子，它是可靠且方便的，可用于辅助前列腺近距离放射治疗的植入后剂量测定。&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;经直肠超声（TRUS）引导的永久性近距离放射治疗植入物已被越来越多地用作前列腺癌的治疗选择，其中$I^{125}$或者$Pd^{103}$放射性种子被永久植入前列腺中。 始终使用最佳的预计划来指导粒子植入过程，旨在将规定的剂量覆盖范围提供给前列腺和备用尿道和直肠。 但是，由于植入过程中的一些技术问题，例如前列腺运动和浮肿，针头放置和粒子下沉，实际的种子位置将与预先计划的位置不同。 因此，植入后剂量测定是验证实际剂量覆盖范围和评估植入物质量的重要步骤。
在最近的一份报告中，美国近距离放射治疗协会（ABS）建议对所有接受永久性前列腺近距离放射治疗的患者进行植入后剂量测定，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（a）记录前列腺和正常邻近组织在植入物的整个生命周期内的实际剂量;&lt;/li&gt;
&lt;li&gt;（b）通过使用补充的外部束照射或其他粒子植入来纠正由于前列腺剂量不足引起的可能的治疗失败;&lt;/li&gt;
&lt;li&gt;（c）帮助刚刚开始进行永久性粒子植入的医师评估和修改其植入技术，并帮助经验丰富的医师完善和完善该程序；&lt;/li&gt;
&lt;li&gt;（d）用于将来的结果分析，例如比较各个机构的治疗结果，并用作预期的多机构临床试验的质量保证工具（质控）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过定位粒子位置，已采用几种方法确定植入后剂量。 这些包括使用两到三张胶片，使用计算机断层摄影（CT）图像以及使用MRI图像。 目前，基于可用性，成本以及对前列腺以及粒子成像的能力，ABS推荐使用基于CT的剂量测定法。
大多数基于CT的粒子定位方法会首先确定连续2D切片上的种子位置。 由于种子通常会暴露在多个相邻的切片上（取决于成像厚度），因此此过程往往会比患者体内的种子数量识别出更多的种子位置。 因此，使用迭代过程将初始位置的数量减少到种子的确切数量。 Brinkmann和Kline（1998）和Liet等人（2001）分别报告了自动种子定位的方法。 他们的方法基于数​​据聚类技术，该技术通过对CT图像中分离的斑点进行分组来确定种子位置。 由于这些方法仅取决于亮点的大小，因此检测结果将极大地依赖于CT研究的设置参数和阈值。随着CT切片厚度的增加，每个种子的像素数变得更加取决于粒子轴向平面的相对方向；另一个重要因素是，由于粒子丢失（例如，通过外部迁移或排出种子），在成像时前列腺中的粒子数量可能不等于植入的数量。 这两个因素会使使用这些方法识别单个粒子变得困难，尤其是当轴向分辨率降低时。
在本文中，我们描述了一种基于几何的识别方法，该方法可自动确定粒子中心的三维（3D）坐标并将其位置记录在植入种子后前列腺的CT研究中的患者解剖结构中。 这种方法并不是强制性找到预期的植入种子数量，因此，可以解释粒子丢失的影响。 分割的粒子位置可以被转移到治疗计划中以计算剂量分布。 在足够高的切片分辨率下（例如1.5毫米或1毫米切片厚度），该算法可以提取粒子的3D方向进行各向异性计算，从而比点源方法更精确地进行剂量测定。 已对包含粒子的前列腺体模以及来自患者的CT进行了测试。&lt;/p&gt;
&lt;h2 id=&#34;2-方法和材料&#34;&gt;2. 方法和材料&lt;/h2&gt;
&lt;h3 id=&#34;21-算法描述&#34;&gt;2.1 算法描述&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;图一：&lt;/strong&gt;

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113093458307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113093458307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图1&lt;/strong&gt;显示了该算法的流程图，该算法以C++程序实现。 CT图像以DICOM 3.0格式导入到程序中。 经过&lt;strong&gt;二进制阈值&lt;/strong&gt;处理后，程序会在每个CT切片中的明亮区域上收集相关的几何信息（例如大小，位置）。 初始的基于几何的过滤算法将大区域（可能包含连接的粒子）分割为单个较小的区域。 每个区域的描述（例如位置，大小，质心，长轴和短轴）都输出到多维矩阵中。 下面的基于几何的连接搜索算法逐一搜索从顶部切片到底部切片的每个区域，并根据几个标准确定连续切片上的连接区域是否属于一个粒子体积，每个最终连接体积均被视为一个粒子且加权质心被计算为种子位置。 如果粒子由两个或多个区域组成，则可以确定粒子方向。根据CT图像的像素间距和得到的粒子位置，将坐标从像素单位转换为厘米单位，以进行随后的剂量计算。 该算法包括三个关键步骤：图像分割，基于几何的初始过滤和基于几何的连接搜索。 我们将在本节的其余部分讨论这些步骤。&lt;/p&gt;
&lt;h3 id=&#34;22-基于强度的ct阈值分割&#34;&gt;2.2 基于强度的CT阈值分割&lt;/h3&gt;
&lt;p&gt;本研究中使用的CT图像具有512×512像素，像素值介于0和4095之间，0为黑色，而4095为白色。 尽管像素值不在以0表示水而-1000表示空气的Hounsfield单位（HU）中，但是可以将它们视为与Hounsfield单位的线性偏移。
在我们的研究中，为了选择用于分割每个CT图像中放射性粒子的最佳值，我们首先对38个CT图像集进行了统计分析。 对于每种设置，首先选择一个感兴趣的区域（ROI）以覆盖前列腺区域（在我们的程序中，可以通过将鼠标拖到CT图像上来快速定义矩形ROI），然后使用低阈值（1500）进行分割 从背景组织中剔除出较高价值的像素。 然后根据像素连接性将这些像素聚类到一些分离的对象。 对于每个对象，记录其最大值和大小。 放射性粒子具有较高的最大值和较小的尺寸，而骨骼和钙化物具有较低的最大值和较大的尺寸（如&lt;strong&gt;图2&lt;/strong&gt;所示）。 在通过CT图像观察确认骨骼和钙化的检测之后，记录每种情况下的钙化物数目，钙化物的最大像素值和骨骼的最大像素值。 本文描述的自动算法中使用的阈值大于从该统计研究中获得的骨骼和钙化物的最大值。（&lt;font color=blue&gt;也就是说，仅仅统计38个CT的骨骼和钙化物来确定手动分割的阈值，在这个阈值之上过滤掉钙化物，怎么感觉这么草率呢？&lt;/font&gt;）
&lt;strong&gt;图2：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113095135545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113095135545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;23-几何区域分割&#34;&gt;2.3 几何区域分割&lt;/h3&gt;
&lt;p&gt;上一步在每个CT切片中创建了许多分段区域。 这一步将设置一个截断尺寸，以区分单个种子与CT平面内的重叠种子对。 截断尺寸通过以下方法自动确定：
在阈值化之后，每个分割的区域具有大小，即，大于阈值的像素数。 由于大多数区域仅包含一个种子，因此它们的大小相似。几个区域的大小可能几乎翻倍，因为它们包含两个相连的种子区域。 将整个CT图像集中所有分割区域的大小收集为数据数组，并进行统计分析。 &lt;font color=red&gt;将平均值加此数据数组标准差的三倍设置为截断大小&lt;/font&gt;。 大于此大小的区域被视为两个相连的粒子区域，因此从阵列中删除。 重新计算了新阵列的截断大小，并且再次消除了大于该大小的区域。 重复此过程，直到没有任何区域的大小大于当前的截断尺寸为止，该截断尺寸因此被设置为最终截断尺寸。
对于比截断尺寸大的区域，基于几何的分割算法（&lt;strong&gt;图3&lt;/strong&gt;）被分成了两部分。 首先，通过在区域边界中搜索最大距离来找到区域的长轴。 然后计算该区域的质心，并将质心投影到长轴上，将长轴分为两部分。 计算这两个部分的各个质心，并将它们投影到长轴上作为起点和终点。 沿着长轴，从起点到终点搜索，找到了垂直距离最短的位置。 该位置用作分割点，从该分割点创建了两个子区域。
&lt;strong&gt;图3：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113100748121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113100748121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;24-几何区域连通&#34;&gt;2.4 几何区域连通&lt;/h3&gt;
&lt;p&gt;在此步骤中，如果满足多个规则，则将可能属于一个粒子体积的多个连续切片中的粒子区域连接起来。 该算法从头到尾连续搜索每个区域，并将每个区域分配为&lt;code&gt;起始&lt;/code&gt;粒子区域或&lt;code&gt;后续&lt;/code&gt;粒子区域。 第一个CT切片中的所有区域都被视为&lt;code&gt;起始&lt;/code&gt;粒子区域。 对于每个后续切片中的每个区域，该算法首先检查它是否连接到上一个切片中的任何粒子区域。 计算了从该粒子区域到先前切片中所有粒子区域的横向距离。 然后选择距离最小的种子区域。如果这两个粒子区域具有连接的体素，则将应用&lt;code&gt;最大粒子体积&lt;/code&gt;标准。
&lt;code&gt;最大粒子体积&lt;/code&gt;标准意味着，如果添加此粒子区域使粒子量的总大小超过&lt;code&gt;最大粒子体积&lt;/code&gt;，则该粒子区域将被分配为新的&lt;code&gt;起始&lt;/code&gt;种子区域； 否则，它是&lt;code&gt;后续&lt;/code&gt;粒子区域。 根据所植入粒子的数量 $N$ 自适应地确定&lt;code&gt;最大粒子体积&lt;/code&gt;，具体实现方法如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，确定&lt;code&gt;平均粒子体积&lt;/code&gt;：为所有种子区域的总大小除以 $N$ ；&lt;/li&gt;
&lt;li&gt;然后，两倍的&lt;code&gt;平均粒子体积&lt;/code&gt;作为初始的&lt;code&gt;最大粒子体积&lt;/code&gt; ,总共的待侦测粒子数目也会被确定。 因为&lt;code&gt;平均粒子体积&lt;/code&gt;足够大，大到可以连接物理上分离的粒子，因此检测到的粒子总数$N1$小于预期的粒子数$N$。这些检测到的粒子的体积按降序计算和排序。 设$M ＝ N-N1$。 选择第 $M$ 个粒子体积作为最终的&lt;code&gt;最大粒子体积&lt;/code&gt;，然后将再次执行连接算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果&lt;code&gt;后续&lt;/code&gt;粒子区域位于&lt;code&gt;起始&lt;/code&gt;粒子区域的第三（或更多）切片上，则&lt;code&gt;直线规则&lt;/code&gt;也将适用。 这意味着，如果该区域的质心在粒子区域的直线上，它将连接到粒子上； 否则，它将被分配为新的&lt;code&gt;起始&lt;/code&gt;种子区域。&lt;/p&gt;
&lt;h3 id=&#34;25-确定种子位置和方向&#34;&gt;2.5 确定种子位置和方向&lt;/h3&gt;
&lt;p&gt;最后一步是确定每个粒子的3D位置和方向（如果仅在一个切片上出现了，则无法确定方向）。 对于显示在两个或更多CT切片上的粒子，使用面积加权方法确定3D坐标，方法如下：
$$
x=\frac{\sum^N_{i=1}x_iA_i}{\sum^N_{i=1}A_i},
y=\frac{\sum^N_{i=1}y_iA_i}{\sum^N_{i=1}A_i},
z=\frac{\sum^N_{i=1}z_iA_i}{\sum^N_{i=1}A_i}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N$是所有包含粒子的切片数目；&lt;/li&gt;
&lt;li&gt;$(x_i,y_i,z_i)$是第$i$个切片上粒子的坐标；&lt;/li&gt;
&lt;li&gt;$A_i$是第$i$个切片上的粒子的面积；&lt;/li&gt;
&lt;li&gt;$(x,y,z)$是结果：面积加权坐标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;粒子的方向通过计算$(x,y,z)$得到的$\alpha$和$\beta$来表示：
$$
\alpha=\frac{x_N-x_1}{(N-1)\Delta},
\beta=\frac{y_N-y_1}{(N-1)\Delta}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Delta$是CT的厚度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3结果&#34;&gt;3.结果&lt;/h2&gt;
&lt;h3 id=&#34;31-最佳阈值确定&#34;&gt;3.1 最佳阈值确定&lt;/h3&gt;
&lt;p&gt;在我们研究的38个前列腺患者CT中，在19个病例上发现了41处钙化物，这些钙化物的最大HU值在1232到2338之间，骨骼的最大HU值在1870到2322之间。这表明，2338可能是最好的过滤掉钙化物和骨骼的阈值。但是考虑到算法向其他数据的迁移，我们将阈值设置为2400。&lt;/p&gt;
&lt;h3 id=&#34;32-使用体模进行算法测试&#34;&gt;3.2 使用体模进行算法测试&lt;/h3&gt;
&lt;p&gt;在植入了56个假粒子的前列腺体模上测试了这种自动粒子定位方法。 体模的尺寸为5.0×4.5×4.0 cm^3^（长×宽×高），直径为1cm的尿道嵌入模型中。 假粒子的直径为0.8毫米，长度为4.5毫米。模型的ACT切片如&lt;strong&gt;图4&lt;/strong&gt;（a）所示。 这项研究评估了该算法在种子定位中的准确性及其分离位置紧密的种子的能力。更近似的模仿实际植入物，在不同角度引入某些针头，以验证算法能够以随机方向准确定位种子。 使一些粒子彼此接触以形成多个粒子的交叉。 在使用1.5毫米厚度的连续切片获取的CT数据集上测试了自动方法。 正交膜定位技术是由一名观察员执行的。 观察者获悉图像中包含的种子总数，将种子坐标与自动化方法的结果进行比较，最大，最小和平均差异分别为2.72 mm，0.17 mm和1.63 mm。 据报道，约11％的种子位置超过2 mm。 识别出的种子的3D坐标被投影到CT扫描之前获取的AP和侧面侦察视图上。 &lt;strong&gt;图4&lt;/strong&gt;（b）和（c）显示了CT检测结果与实际X射线侦察图像之间的匹配：
&lt;strong&gt;图四：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113114748586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113114748586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;33-使用实际的植入后ct图像进行算法测试&#34;&gt;3.3 使用实际的植入后CT图像进行算法测试&lt;/h3&gt;
&lt;p&gt;使用来自两名患者的影像学研究，使用CT和正交膜技术通过自动方法确定了粒子坐标。 对植入了86125粒子的患者1进行了1毫米和3毫米厚度的连续CT图像扫描。 &lt;strong&gt;图5&lt;/strong&gt;显示了该患者CT检测到的粒子位置与X射线胶片之间的比较。 植入了69103$Pd$粒子的患者2仅在3毫米厚的CT图像中进行了扫描。 在CT扫描的同一天为每位患者获取AP和横向正交胶片。 将所得的粒子坐标与相应3D位置之间的最大，最小和平均差异的自动方法的结果进行比较（&lt;strong&gt;表1&lt;/strong&gt;）。 对于CT厚度为1 mm的患者1，所有种子均被识别，并且85个种子具有3D方向（其中78％记录在三个相邻的切片上）。剩余的一颗种子仅记录在一个切片上，因此无法确定其方向。
&lt;strong&gt;图5：&lt;/strong&gt;(a)是将CT检测的结果和X光进行覆盖的AP显示；(b)是侧面显示


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113115132923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113115132923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;strong&gt;表一：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113115535772.png&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20210113115535772&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20210113115535772&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20210113115535772&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113115535772.png&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;34-算法可移植性测试&#34;&gt;3.4 算法可移植性测试&lt;/h3&gt;
&lt;p&gt;为了测试该算法在不同临床情况下的可移植性，使用四种不同类型的种子（$^{103}Pd$ TheraSeed，$^{103}Pd$ PdGold，$^{125}I$ 6711和$^{125} I$ IoGold），三种不同的CT切片厚度（1 mm，3 mm和5 mm）和两种不同的FOV（ 16厘米和36厘米）。 所有测试用例均获得满意的结果。 该算法针对不同情况自动确定不同的参数。 例如，TheraSeed，PdGold和IoGold种子的截断尺寸通常在16 cm FOV下为27–32像素，对于3 mm切片厚度在36 cm FOV下为7-11像素，对于16 cm FOV为17–18像素。 切片厚度为5 mm，而对于3 mm切片厚度，碘6711种子的截断尺寸在16 cm FOV下为45–58像素，在36 cm FOV下为9–13像素。 &lt;strong&gt;表2&lt;/strong&gt;列出了20个测试案例的种子类型，CT切片厚度，FOV，算法确定的参数以及植入和检测到的粒子数量。（&lt;font color=blue&gt;由此也可以看出一个问题，对于不同性质的数据，算法内部的参数都需要人工调整，这里的问题在于，论文没有进行横向的对比，没有在控制住其他变量只改变病例的情况下做测试。&lt;/font&gt;）
&lt;strong&gt;表二：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113134534660.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113134534660.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

使用Pentium 4 2.4 GHz计算机的平均处理速度为1秒。 与手动操作相比，这节省了大量时间。&lt;/p&gt;
&lt;h3 id=&#34;35-植入后剂量&#34;&gt;3.5 植入后剂量&lt;/h3&gt;
&lt;p&gt;我们将这种自动粒子定位算法应用于近距离放疗后的28个病例。 这些包括18个$^{103}Pd$ 植入物和101个$^{25}I$植入物。 所有病例都以3毫米的切片厚度扫描。 根据每个CT图像序列的前列腺边界的手动轮廓线，计算每个患者的植入后体积和剂量体积直方图（DVH）。&lt;strong&gt;表3&lt;/strong&gt;列出了研究结果。 在该表中，植入前的体积是从超声研究中获得的。 经验丰富的观察员对每个病例​​进行目视检查，以确认粒子的正确性。 最后一行给出统计总结，包括植入粒子总数（2634）和已鉴定种子（2610），&lt;strong&gt;平均鉴定率&lt;/strong&gt;99.1±1.0％（平均值±标准差），&lt;strong&gt;平均体积增加&lt;/strong&gt;1.25±0.26（平均值±标准差） ）和&lt;strong&gt;平均D90 / Rx剂量&lt;/strong&gt;1.08±0.18（平均值±标准偏差）。 在此，D90是前列腺体积的90％所接受的剂量，Rx剂量是前列腺的规定剂量。 &lt;strong&gt;D90 / Rx剂量&lt;/strong&gt;之比是反映植入后剂量测定中植入质量的重要因素，这是美国医学物理学会（AAPM）第64号任务组的建议。$^{125 }I$的D90 / Rx剂量（1.23）高于$^{103}Pd$（1.00）。 这可能是由于$^{103}Pd$病例的体积增加较高（1.33比1.10）和$^{103}Pd$来源的剂量衰减更快。
一名经验丰富的观察员根据人工粒子定位对2例（$I-125$病例编号为10，$Pd-103$病例编号为18）进行了植入后剂量测定.D90的值分别为201和94。 这两种情况下的粒子自动定位结果均在1％的范围内。这表明，自动粒子定位方法与植入后剂量计算的专家手动定位相当。 粒子定位差异（与正交X射线胶片定位技术相比，平均差异为3 mm）没有转化为明显的剂量学差异。
表三：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210113140309424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210113140309424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;4讨论&#34;&gt;4.讨论&lt;/h2&gt;
&lt;h3 id=&#34;41-算法的可移植性&#34;&gt;4.1 算法的可移植性&lt;/h3&gt;
&lt;p&gt;该算法应该相对容易在其他诊所中实施，因为它与粒子的类型和CT扫描参数无关。
在本研究中，通过实验确定了用于将粒子区域分割出前列腺组织，钙化和耻骨弓骨的阈值。 在本研究中，发现2400的像素值足够高，可以消除那些属于所有测试用例的钙化和骨骼像素。 搜索属于非粒子区域的最大像素值的方法是该程序的一项独立功能，因此可以很容易地在其他诊所中实施以找到其最佳阈值。
该算法中使用的两个关键参数是来自CT，而不是来自外部输入。 分割双粒子区域的截断面积被计算为平均值加上单粒子区域大小分布的标准偏差的三倍。 测试结果表明，这是一个合理的选择，并使算法与粒子类型和FOV无关。 确定体素数量的&lt;code&gt;最大粒子体积&lt;/code&gt;是基于知识的自适应过程，因为最初植入的粒子数是前提条件。 由于此输入可能不是CT上存在的确切种子数，因此不会强制算法匹配此输入数，因此本地化粒子的最终数可能会有小的差异。 该参数的自动确定使该算法与粒子类型，FOV和CT切片厚度无关。&lt;/p&gt;
&lt;h3 id=&#34;42-ct层厚上的选择建议&#34;&gt;4.2 CT层厚上的选择建议&lt;/h3&gt;
&lt;p&gt;在该算法中，较小的CT切片厚度（1毫米）将提高粒子定位的准确性，因为将加权的质心位置计算为这些质心。 &lt;strong&gt;表1&lt;/strong&gt;体现了使用1mm CT切片厚度比使用3mmCT导致更高的精度。此外，在较小的CT切片厚度中，更多的种子将具有取向信息，因为粒子将出现在两个或更多个切片上。 研究发现，使用1毫米CT切片时，可以3D方向计算98％以上的粒子，而使用3毫米CT切片时可以减少到67％的种子，但是在常规情况下使用1毫米CT可能会被禁止（由于成本和时间的临床实践）。
另一方面，使用1 mm和3 mm CT（平均差0.2 mm）的结果之间的一致性表明，当不需要粒子方向信息时，使用3 mm CT是一个很好的折衷方案。 布林克曼还研究了5毫米CT切片，发现在1毫米和5毫米CT中匹配坐标之间的距离大于2.0毫米。 我们的研究表明3 mm CT是常规临床实践中的合理选择。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文从植入后的CT图像中描述了一种自动粒子定位算法，该算法与先前发布的方法之间的主要区别在于该算法依赖于3D粒子分布上的几何和强度信息，因此在处理粒子重叠和计算方向方面可能更准确。 对于那些仍处于选定阈值连接状态的粒子区域，该算法使用粒子大小标准来拆分连接的粒子区域，而不是像以前的方法那样将组合对象的质心坐标分配给每个连接的粒子区域。
该算法已使用20个病例进行了测试，其中有四种不同种子类型、三种不同CT切片厚度和两种不同FOV的病例。结果对于所有情况都是令人满意的，因此表明该算法与这些变量无关。 在Pentium III 600 MHz处理器计算机上，典型CT序列的处理速度为4 s，在Pentium 4 2.4GHz处理器计算机上为1s。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: 前列腺近距离放射治疗中粒子定位的深度回归模型</title>
      <link>https://Joevaen.github.io/showcase/paper/paper3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper3/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;前列腺近距离放射治疗中粒子定位的深度回归模型&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2方法论&#34;&gt;2.方法论&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-深度回归模型&#34;&gt;2.1 深度回归模型&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-实现&#34;&gt;2.2 实现&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-实验&#34;&gt;3. 实验&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-总结&#34;&gt;4. 总结&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;p&gt;@[TOC](《A Deep Regression Model for Seed Localizationin Prostate Brachytherapy》)&lt;/p&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.当前粒子植入手术面对着术中及术后植入粒子剂量核验的问题，本人现在已经完成一部分这样的工作，能够比较有效的将粒子在空间中进行聚类，结果较为理想但在面对多个粒子伪影重叠的情况下，仍然有较大的误差存在。刚好找到这篇极具研究价值的论文，希望能理解其精髓思想，尽快复现其内部知识；&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示对原来的理解做的一些修改或补充&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示本文的重要关键字&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;植入后剂量测定（PID）是前列腺粒子放射治疗的重要步骤，利用CT对前列腺进行成像，并使放射性粒子的位置和剂量分布与实际前列腺直接相关。 但是，由于严重的金属伪影和当多个粒子聚集在一起时出现的高度重叠的外观，因此在CT图像中识别这些种子是一项非常艰巨的任务。 在本文中，我们提出了一种基于3D深层卷积网络的自动高效算法，用于识别CT图像中的植入粒子。我们的方法将粒子定位任务建模为监督回归问题，该问题将输入的CT图像投影到概率图上，其中每个元素代表输入体素属于属于对应粒子的概率。 这种深度回归模型显着抑制了图像伪影，使后处理变得更加容易和可控。该方法在大型临床数据库中得到了验证，该数据库包含100名患者的7820个粒子，其中使用了70名患者的5534个粒子进行了模型训练和 验证。 我们的方法正确地检测了30位测试患者中的2150颗种子，共2286颗（94.1％），与广泛使用的商用种子搜索软件（VariSeed，Varian，Palo Alto，CA）相比，提高了16％。&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;2019年，据估计有174,650例新病例和31,620例死亡，前列腺癌仍然是美国男性中最常见的诊断出的癌症类型。粒子植入物近距离放射治疗涉及将放射性源（粒子）永久植入前列腺内，是中低危前列腺癌的标准选择。尽管在计划和粒子输送方面进行了各种改进，但是由于各种因素（例如针头位置变化，前列腺变形，粒子输送变化和粒子迁移），实际的辐射剂量分布可能会偏离计划。 因此，建议采用植入后剂量测定法（PID）以确保植入质量并建立放射剂量与临床结果之间的关系。PID通常在植入后第30天执行，该操作利用CT对植入区域成像，从中勾勒出前列腺和周围高危器官（OAR）的轮廓，并确定粒子位置。
植入粒子的准确定位对于量化向这些器官的剂量分布至关重要。 但是，鉴于植入了大量粒子，手动识别这些粒子非常耗时，通常每位患者需要10至20分钟才能识别60至100颗种子。 因此，对种子定位的精确和自动匹配的方法有很大的需求。 如&lt;strong&gt;图1&lt;/strong&gt;所示，尽管射线在CT图像上显示出很高的对比度，但由于以下两个独特的特征，自动粒子定位在实际工作中是一项艰巨的任务。大大增加了粒子鉴定的复杂性。 其次，由于粒子传输位置的变化和粒子的迁移，一些植入的粒子彼此非常靠近以形成种子簇。 这种高度重叠的外观使得很难在CT图像上识别单个种子。
已经开发了几种自动方法来在CT图像中定位种子，例如&lt;strong&gt;基于几何的识别方法&lt;/strong&gt;【&lt;em&gt;Liu,  H.,  et  al.:  Automatic  localization  of  implanted  seeds  from  post-implant  CTimages. Phys Med Biol 48(9), 1191 - 1203 (2003)&lt;/em&gt;】和&lt;strong&gt;霍夫变换&lt;/strong&gt;【&lt;em&gt;Holupka,  E.  J.,  et  al.:  An  automatic  seed  finer  for  brachytherapy  CT  postplansbased on the Hough transform. Med Phys. 31(9), 2672-2679 (2004)&lt;/em&gt;】。最近，Nguyen等人提出了一种&lt;strong&gt;级联方法&lt;/strong&gt;【&lt;em&gt;Nguyen, H. G., et al.: Automatic 3D seed location and orientation detection in CTimage for prostate brachytherapy. In: IEEE ISBI 2014, pp. 1320-1323. (2014)&lt;/em&gt;】，该方法涉及阈值和关联成分分析作为种子候选物的初始检测，然后是一种改进的k均值方法，用于基于先验强度和体积信息来分离种子组。 张等人【&lt;em&gt;Zhang, G., et al.: Automatic seed picking for brachytherapy postimplant validationwith 3D CT images. Int J CARS. 12, 1985 - 1993 (2017)&lt;/em&gt;】&lt;strong&gt;采用灰度检测和改进的凹点匹配&lt;/strong&gt;，以在基于灰度直方图的阈值化之后分离触摸种子。 所有这些方法都使用需要特殊领域知识的手工制作的功能。 同时，通常引入复杂的预处理和后处理步骤以促进种子定位过程。 结果，这些方法的评估主要是在体模或少量临床病例的情况下进行的。
&lt;strong&gt;图一：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210112114909204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210112114909204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最近，深卷积神经网络（CNN）在医学图像分析中变得很流行，并且在各种医学图像计算任务（例如肺结节检测，组织学图像中的腺体实例分割，肝和肿瘤分割，皮肤病变分割和分类）。 由于直接从原始图像数据中学习分层特征的能力，CNN通常会产生更好的泛化性能，尤其是在对大型数据集进行评估时。
受到深度学习研究的最新进展的启发，我们提出了基于深度CNN的新型框架，以在3D CT图像中自动定位植入的粒子。 我们在本文中的贡献是三方面的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，我们将种子定位建模为回归问题，并利用深层CNN的判别力引入全自动解决方案。 据我们所知，这是使用深度神经网络解决这一艰巨任务的首次尝试。&lt;/li&gt;
&lt;li&gt;其次，我们没有直接预测3D空间中的种子坐标，而是设计了种子位置的概率图来解决人工识别的不确定性，从而提高了模型预测的鲁棒性。&lt;/li&gt;
&lt;li&gt;最后，我们在大型临床数据库中对100名患者的7820颗粒子进行了评估，并与商业粒子搜索软件（VariSeed，Varian，Palo Alto，CA）进行了比较。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2方法论&#34;&gt;2.方法论&lt;/h2&gt;
&lt;h3 id=&#34;21-深度回归模型&#34;&gt;2.1 深度回归模型&lt;/h3&gt;
&lt;p&gt;如&lt;strong&gt;图一&lt;/strong&gt;所示，红色的点作为粒子的标签，每一个点对应一个原始粒子。但是，考虑到粒子有一定的形状（直径0.8mm，长度4.5mm），只要是在粒子上的点，都应该是正确的注释。结果就是，就种子而言的标签位置而言，可能和真实情况有很大的变化，如果直接将确切的注释位置用作学习目标，则这将带来不必要的挑战并易于过度拟合。与之不同的是，我们将离散的点标签转换成连续的概率图（$x\in{R^3}$），从而将粒子的定位问题强制转换成监督回归问题，通过这样的方式，来学习3D CT图像 $I(x)$ 和 概率图$P(x)$ 之间的一种映射关系。$\hat{P}$是推理出的概率图，$w$是学习到的权重：
$$\hat{P}(x,w) = F(I(x),w)$$
对于每一个3D图像$I_i(x)$都有它对应的三维点集$C_I = {C_1,&amp;hellip;,C_{N(i)}}$作为其注释，$N(i)$是标注的总共的点数目，我们将GT概率图定义为给予所提供点的一种核强度估计：
$$\forall{x} \in{I_i, P_i(x)}=\sum_{C\in{C_i}}N(x;C,\Sigma),
\Sigma= \left[
\begin{matrix}
{\sigma_x^2} &amp;amp; 0 &amp;amp; 0 \&lt;br&gt;
0 &amp;amp; {\sigma_y^2}&amp;amp; 0 \&lt;br&gt;
0 &amp;amp; 0 &amp;amp; {\sigma_z^2}
\end{matrix}
\right] \tag{1}$$
对这些参数做些解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x$: 代表$I_i$的某个体素的坐标；&lt;/li&gt;
&lt;li&gt;$N(x；C,\Sigma)$：在 $x$ 这个体素位置的归一化高斯核；&lt;/li&gt;
&lt;li&gt;$C$：均值，也就是标签；&lt;/li&gt;
&lt;li&gt;$\Sigma$：方差，对角矩阵；&lt;/li&gt;
&lt;li&gt;$\sigma_x,\sigma_y,\sigma_z$：考虑到粒子的大小形状和CT图像本身的影响，在研究中设置：$\sigma_x=\sigma_y=1mm, \sigma_z=2mm$。
**图二（a）**显示了从图一认为标签点中创建概率图，**图二（b）**是对应的深度回归模型推理出来的概率图。
&lt;strong&gt;图二：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210112165630530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210112165630530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

我们训练一个深度回归且对称的编解码网络（&lt;strong&gt;DRN&lt;/strong&gt;）来将输入的CT图像映射为概率图，就像图三显示的这样：
&lt;strong&gt;图三&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210112170020605.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210112170020605.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

我们在编码器阶段使用卷积层和最大池化层来聚合图像信息，在解码器阶段使用转置卷积来恢复原始的图像信息。每层卷积之后是BN层和ReLU层来促进反向传播。同时使用跳跃链接来聚合高低级像素的图像信息。通过明确地组合低级和高级功能，DRN从本地和全局上下文信息中受益，以重建粒子位置的更精确概率图。 考虑到目标概率图是非负的，我们在最后的卷积层中使用 &lt;em&gt;softplus&lt;/em&gt; 作为激活函数以确保DRN的正输出，其函数和ReLU十分相近：
$$softplus(x)=\frac{1}{\beta}\cdot(log(1+exp^{\beta\cdot{x}}))$$
在我们的研究中，将$\beta$设置为1，卷积核大小为3，步长为1，但是转置卷积因为要进行上采样，所以卷积核大小核步长都设置为2。为了保证卷积过程中相同的维度，使用0填充，所有的操作都是在3D的空间上操作的。
训练DRN的目的是为了使得预测值和真是标签之间的损失越来越小，由于大部分的体素都属于背景，DRN倾向于更多地关注学习背景，而不是高斯型粒子标签。为了解释这种前后景的不平衡，我们使用加权的MSE作为损失函数，权重为目标概率图$P(x)$：
$$L(w)=\frac{1}{N}\cdot{\sum^{N}_{n=1}[P(x_n)(P(x_n)-\hat{P}(x_n,w))]}\tag{3}$$
$N$ 是一个mini batch中训练的体素总数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-实现&#34;&gt;2.2 实现&lt;/h3&gt;
&lt;p&gt;我们的DRN是使用Pytorch（v.0.4）实现的。 使用Adam随机优化方法（batchsize为4），训练DRN从头开始进行了500次迭代。初始学习率设置为0.003，并且当验证损失停止减少时使用学习率衰减和早期停止策略。 为了减少过度拟合，我们随机地向左/向右，上/下和前/后方向翻转以进行数据增强。 我们使用七折交叉验证来评估模型在训练数据集上的性能，其中还通过&lt;font color=red&gt;网格搜索实验&lt;/font&gt;确定了一些超参数。 所有实验均在装有四个Nvidia GTX 1080 TIGPU的工作站上进行。
对于预处理，我们仅将所有CT扫描的体素值截断到[-80,175] HU范围内，以消除无关的图像信息。将CT图像各向同性重采样为0.5 mm，ROI的体积为 从整个CT图像中提取以前列腺为中心的128×128×96（VOI）作为DRN的输入。 在推理过程中，按照与训练数据准备相同的步骤对新的CT图像进行预处理，然后将训练后的DRN应用于VOI以生成3D概率图。 我们使用&lt;font color=red&gt;3D分水岭分割算法&lt;/font&gt;将概率图转换为最终粒子位置。&lt;/p&gt;
&lt;h2 id=&#34;3-实验&#34;&gt;3. 实验&lt;/h2&gt;
&lt;p&gt;我们在机构中收集了2008年至2019年接受种子植入近距离放射治疗的100名前列腺癌患者的数据库。 植入的粒子（钯103）的数量从48到156不等。随机选择了70例具有5534粒子的患者进行模型训练和验证，而剩下的30例具有2286种子的患者被保留用于独立测试。 植入后30天对每位患者进行ACT扫描，面内分辨率为0.6×0.6至1.4×1.4 mm，切片厚度为2.5至3.0 mm。
通过半自动程序获得GT，其中VariSeed 种子查找器算法首先用于搜索CT图像中前列腺区域附近的植入种子。 由于此自动程序通常会导致一些错误的粒子放置，因此需要用户干预才能根据CT图像中的粒子位置校正这些错误。 放射肿瘤学家最终批准了种子的定位以及重建的辐射剂量分布。
&lt;strong&gt;图4&lt;/strong&gt;分别以轴向，矢状冠状面图显示了CT图像中PID研究的两个示例，其中在患者（a）中植入了77颗种子，在（b）中植入了143颗种子。 还显示了概率图的相应DRN预测。 清楚地表明，金属伪影和粒子重叠外观被显着抑制，这使得粒子定位更加容易。 右边的图显示了GT的3D分布以及DRN识别的粒子。 总体而言，DRN花了大约60秒钟恢复30位测试患者的植入种子数量。 中值对距离为0.70毫米[25％-75％：0.36-1.28毫米]。
&lt;strong&gt;图四：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210112175111440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210112175111440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;strong&gt;表1&lt;/strong&gt;详细列出了DRN和VariSeed查找器粒子检测之间的比较，其中第一行和第四行列出了植入种子的数量。 对于大量植入的种子（从48颗到143颗），DRN几乎在每位患者上都大大超过了VariSeed。总体而言，DRN在30位测试患者的2286颗种子中正确地识别出2150颗种子（94.1％），达到了16％ 与VariSeed相比有所改善（81.0％）。
&lt;strong&gt;表一：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210112175516288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210112175516288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;4-总结&#34;&gt;4. 总结&lt;/h2&gt;
&lt;p&gt;在本文中，我们在基于CT的植入后剂量学研究中对接受前列腺近距离放射治疗的患者进行深度学习在识别放射性粒子任务中的应用开创了先河。 尽管在CT图像中进行粒子定位存在挑战，但与大型临床数据库上广泛使用的商业软件相比，提出的深度回归模型实现了更高的检测准确性。 而且，我们的模型被发现非常有效，一个新的测试用例平均要花2秒的时间。 我们的方法无需在每个种子上手动绘制3D边界框或蒙版，而仅需要将点注释作为地面实况进行模型训练，从而大大简化了数据标记过程。 这种弱监督的学习框架可以轻松地推广到其他对象检测任务，&lt;font color=red&gt;例如2D / 3D实时成像中的监护标记跟踪以及高剂量率（HDR）近距离放射治疗中的源/导管定位&lt;/font&gt;。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: BiO-Net：学习用于编码器-解码器结构的递归双向连接</title>
      <link>https://Joevaen.github.io/showcase/paper/paper4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper4/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;BiO-Net：学习用于编码器-解码器结构的递归双向连接&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#11-u-net-variantsu-net的变体总结&#34;&gt;1.1 U-Net Variants（U-Net的变体总结）&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#12-recurrent-convolutional-networks递归神经网络&#34;&gt;1.2 Recurrent Convolutional Networks（递归神经网络）&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2方法&#34;&gt;2.方法&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-递归双向跳跃连接&#34;&gt;2.1 递归双向跳跃连接&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-bio-net结构&#34;&gt;2.2 BiO-Net结构&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3实验&#34;&gt;3.实验&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-语义分割&#34;&gt;3.1 语义分割&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-超像素分割&#34;&gt;3.2 超像素分割&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#总结&#34;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.论文地址在&lt;a href=&#34;https://arxiv.org/abs/2007.00243&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示本文的重要关键信息&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示此处的一些个人思考&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=purple&gt;紫色表示我的更新内容&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三.&lt;strong&gt;&lt;font color=red&gt;目的&lt;/font&gt;&lt;/strong&gt;：研究该改进算法的实验结果，理解该算法的思想，尝试去改进算法。&lt;/li&gt;
&lt;li&gt;四.&lt;font color=red&gt;&lt;strong&gt;意义&lt;/strong&gt;&lt;/font&gt;：
*&lt;/li&gt;
&lt;li&gt;五.&lt;font color=red&gt;&lt;strong&gt;思考&lt;/strong&gt;&lt;/font&gt;：
*&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;        U-Net已成为用于现代计算机视觉任务（例如语义分段，超分辨率，图像降噪和修复）的基于深度学习的最新技术之一。 U-Net的先前扩展主要集中在修改其现有构建基块或开发新的功能模块以提高性能。 结果，这些变体通常会导致模型复杂性的增加。 为了解决此类U-Net变体中的此问题，在本文中，我们提出了一种新颖的双向O型网络（BiO-Net），该网络以循环方式重用构建基块，而无需引入任何其他参数。 我们提出的双向跳跃连接可以直接应用于任何编码器/解码器结构中，以进一步增强其在各种任务领域中的功能。我们在各种医学图像分析任务上评估了我们的方法，结果表明，我们的BiO-Net大大优于vanillaU -Net以及其他最新方法。代码地址在&lt;a href=&#34;https://github.com/tiangexiang/BiO-Net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;。
关键词：语义分割、双向连接、递归神经网络&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;        基于深度学习的方法最近在辅助医学图像分析中占了上风，例如整个图像分类，脑病灶分割和医学图像合成。 U-Net作为最流行的基于深度学习的模型之一，已经在众多医学图像计算研究中证明了其令人印象深刻的表现能力。 U-Net引入了跳跃连接，可以跨多个语义尺度聚合特征表示，并有助于防止信息丢失。&lt;/p&gt;
&lt;h3 id=&#34;11-u-net-variantsu-net的变体总结&#34;&gt;1.1 U-Net Variants（U-Net的变体总结）&lt;/h3&gt;
&lt;p&gt;        最近的工作提出用不同的模块设计和网络构建来扩展U-Net结构，从而说明其在各种可视化分析任务中的潜力。 V-Net在较高尺寸的体素上应用U-Net并保持其内部结构。 W-Net修改了U-Net，以通过自动编码器样式模型连接两个U-Net来解决无监督的分割问题。与U-Net相比，M-Net将不同比例的输入特征附加到不同的级别，因此可以通过一系列下采样和上采样层来捕获多级视觉细节。 最近，U-Net ++采用嵌套和密集跳过连接来更有效地表示细粒度的对象细节。 此外，注意力U-Net使用额外的分支来将注意力机制自适应地应用于跳过和解码特征的融合。 但是，这些建议可能涉及其他构建块，这导致更多的网络参数，从而增加了GPU内存。 与上述变体不同，我们的BiO-Net通过一种新颖的功能重用机制提高了U-Net的性能，该机制在编码器和解码器之间建立双向连接，以递归方式进行推理。&lt;/p&gt;
&lt;h3 id=&#34;12-recurrent-convolutional-networks递归神经网络&#34;&gt;1.2 Recurrent Convolutional Networks（递归神经网络）&lt;/h3&gt;
&lt;p&gt;        使用递归卷积迭代优化在不同时间提取的特征已被证明对于许多计算机视觉问题是可行且有效的。郭等人建议重用ResNet中的残差块，以便充分利用可用参数，并显着减小模型大小。 这种机制也有利于U-Net的发展。结果，王等人提出R-U-Net，可以递归连接UNet的编解码对来加强语义分割对信息的表达能力，尽管他也引入了一些额外的学习模块，但也只是作为一个折中的方法引入。BiO-Net与R-U-Net的反向跳跃连接是不同的，因为后者的解码器的特征被多次反复使用，目的是为了随着当前步骤保存的梯度聚合更多的过渡信息。R2U-Net采用了类似的方法，但是是仅在每个细化级别上都递归最后一个构建块。与这些不同的是，我们的方法是在现有的编码器和解码器之间学习递归连接，而不是递归同一水平的block，因为这样并不能利用解码器的精细化特征。
        所以，最终我们提出了BiONet，一个带有双向O型推理轨迹的递归UNet。改网络将解码器的特征通过反向跳跃连接传送给编码器，通过这种方式不断在编解码器之间进行递归。与之前的一些算法相比，我们的方法更好的实现了特征的细化，因为我们的网络出发了多个编解码机制。我们将我们的BiO-Net应用于在核分割任务和EM膜分割任务上的语义分割，并且我们的结果表明，所提出的BiO-Net优于其他U-Net变体，包括同样使用递归的其他方法和许多SOTA方法。超分辨率任务还证明了我们将BiO-Net应用于不同场景的重要性。&lt;/p&gt;
&lt;h2 id=&#34;2方法&#34;&gt;2.方法&lt;/h2&gt;
&lt;p&gt;        就像&lt;strong&gt;图一&lt;/strong&gt;展示的这样，BiONet采用与UNet相同的网络结构，没有添加任何额外的功能模块，只使用了成对的双向连接。它在展开过程中没有引入额外的可训练参数，从而实现了更好的性能。 此外，我们的方法不限于U-Net，还可以集成到其他编码器/解码器体系结构中以执行各种视觉分析任务。
&lt;strong&gt;图一&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108101457735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108101457735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;21-递归双向跳跃连接&#34;&gt;2.1 递归双向跳跃连接&lt;/h3&gt;
&lt;p&gt;BiO-Net模型的主要独特之处在于引入了递归双向跳跃连接，这有助于编码器处理解码器中的语义特征，也有助于解码器处理编码器的信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;前向跳跃连接(Forward Skip Connections)&lt;/strong&gt;：
连接同一个水平线上编码器和解码器&lt;strong&gt;前向跳跃连接&lt;/strong&gt;可以保存low-level的图像特征 $f_{enc}$ 和他们的梯度信息。因此第 $l$ 个解码块就能将从底下传上来的信息$\hat{x_{in}}$和从对应编码块的$f_{enc}$ 进行融合，然后经过解码器 $DEC$ 再变成 $f_{dec}$ ，然后进一步通过上采样 $UP$ 。这个过程如下公式表示：
$$f_{dec}=DEC([f_{enc}, \hat{x_{in}}])\tag1$$
连接的方式采用点乘$[\cdot]$。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反向跳跃连接(Backward Skip Connections)&lt;/strong&gt;：
在我们设计的独特模块&lt;strong&gt;反向跳跃连接&lt;/strong&gt;的帮助下，我们能够将解码器部分的特征信息再传回编码器中，与编码器的特征信息聚合。与之前的前向跳跃方法类似，我们以同样方式来进行反向操作，公式表达如下：
$$f_{enc}=ENC([f_{dec}, x_{in}])\tag2$$
下采样块$DOWN$使得编码器可以获得更深层的图像特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;回归推理(Recursive Inferences)&lt;/strong&gt;：
上面的两种跳跃链接方式使得我们的网络形成了一个$O$型的推理路径。注意，这种路径可以循环多次来快速得到表现的收益，更重要的是，这样的方法不会产生任何额外的参数。所以，我们的方法公式表达如下，$i$是推理的迭代次数：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108152243522.png&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20210108152243522&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20210108152243522&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20210108152243522&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108152243522.png&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

与一般的UNet相比，我们的BiONet把编码器和解码器的特征都考虑了进去，同时从之前一次递归过程中拿到更精细的信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-bio-net结构&#34;&gt;2.2 BiO-Net结构&lt;/h3&gt;
&lt;p&gt;在网络结构中，我们使用平面卷积、BN层、ReLU层。没有BN层会被重复使用。输入图像首先会经过三个卷积块来提取向下阶段的特征。注意第一个level上是没有&lt;strong&gt;backward skip connection&lt;/strong&gt;的，因此第一个stage上的block中的参数在递归时不会重复使用。提取到的特征被送入到编码块中从而使用池化操作进行下采样。在编码阶段完成后，会进入一个中间stage来进一步提取编码器的信息，之后就会被送入解码器阶段，通过每个解码块中转置卷积来恢复编码器信息。之后解码器恢复的信息再次传入到编码器，执行循环。同样的，解码器的最后一个block也不循环使用。
为了方便起见，我们定义了以下几个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$t$:总共的循环次数；&lt;/li&gt;
&lt;li&gt;$×n$:代表所有隐藏的输出通道号的扩展倍数；&lt;/li&gt;
&lt;li&gt;$w$:代表从最底下一层数的第几个深度使用&lt;strong&gt;backward skip connections&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;$TNT$:代表会将前几次 迭代的解码恢复后的特征进行叠加，组合成最终的block；&lt;/li&gt;
&lt;li&gt;$l$:代表的是最大的编码深度。
从&lt;strong&gt;图2&lt;/strong&gt;可以看到对应的例子：
&lt;strong&gt;图2&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108155523847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108155523847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3实验&#34;&gt;3.实验&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据集&lt;/strong&gt;
我们的方法是在三个常见的数字病理图像分析任务上进行评估的：总共四个不同的数据集上的核分割，EM膜分割和图像超分辨率。 选择了两个可公开获得的数据集，即MoNuSeg和TNBC，以评估我们的核语义分割方法。 MoNuSeg数据集包含30个图像训练集和14个图像测试集，并从多个器官的不同整体幻灯片图像中采样了大小为1000x1000的图像。 我们从每个图像的4个角提取512x512大小的patch，将数据集放大4倍。 TNBC由50个大小为512x512的组织病理学图像组成，没有任何特定的测试集。 这两个数据集都包含针对核语义分割问题的像素级注释。 我们评估的第二个任务是EM膜分割，从中收集小鼠的梨状皮质EM数据集，其中包含四叠EM图像，切片图像尺寸分别为255x255、512x512、512x512和256x256。 图像超分辨率是我们评估方法的最后一项任务，该数据集是由MICCAI15 CBTC收集的完整幻灯片图像构成的。 我们在40倍放大倍率下采样了2900个大小为512x512的patch，分别针对训练和测试集以9：1的比例进行了分割。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;改进细节&lt;/strong&gt;
我们使用初始学习率为0.01、衰减率为0.00003的Adam优化器，语义分割任务中使用的交叉熵损失，在超像素任务中使用的是均方差损失。数据增强采用了（-15,15）度的随机旋转、xy两个方向上范围在（-5%, 5%）的随机平移、随机裁剪、范围在（0,0.2）的随机扩大、水平和竖直的翻转。训练和推理的Batchsize都设置为2。默认实在编码器深度为4、同时在网络的每一个stage上都进行&lt;strong&gt;backward skip connectio&lt;/strong&gt;，一张1080Ti上进行的测试，最好的$t$应该为3。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;31-语义分割&#34;&gt;3.1 语义分割&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核分割：&lt;/strong&gt;
在此任务中，我们的方法与baselineU-Net和其他最新技术进行了比较。仅在MoNuSeg训练集上训练模型，并在MoNuSeg测试集和TNBC数据集上进行评估。 评估了（DICE）和（IoU）。 如&lt;strong&gt;表1&lt;/strong&gt;所示，我们的结果优于MoNuSeg测试集上的其他结果。 我们在TNBC数据集上的结果也大大高于其他数据集，这证明了强大的泛化能力。 此外，与U-Net的其他扩展相比，我们的BiO-Net具有更高的内存效率。 图3显示了我们的方法与循环对应的R2U-Net的定性比较。可以看出，随着推理时间的增加，我们的模型对核的分割更加准确。在我们的实验中，BiO-Net推断出两个预测的批次 当t = 1，t = 2和t = 3时分别在35、52和70ms中。 将我们的方法结合到另一个编码器-解码器体系结构LinkNet中的进一步评估，也显示在表中。 我们的BiO-LinkNet明智地添加了跳过的功能，因此，它们共享的参数数量与普通LinkNet相同。
&lt;strong&gt;表1：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108161234472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108161234472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;strong&gt;表2&lt;/strong&gt;通过改变&lt;strong&gt;图2&lt;/strong&gt;中定义的设置演示了我们的烧蚀研究。 结果表明，通过提出的双向跳跃连接通过编码器和解码器进行递归，通常可以提高网络性能。 集成来自所有推理重复的解码特征，可以在两个数据集中产生最新的性能。 此外，我们发现当网络中的参数不足时，增加推理重复率几乎没有改善，甚至使结果更糟。 有趣的是，当构建编码深度较浅的BiO-Net时，我们的模型在两个数据集上的表现要好于编码深度较深的模型。
&lt;strong&gt;表2：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108161451188.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108161451188.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EM膜分割：&lt;/strong&gt;
我们通过对Mouse Piriform Cortex EM图像进行分段来进一步评估我们的方法，其中在stack1和stack2上训练模型，并在stack4和stack3上进行验证。 结果由Rand F-score评估。 如&lt;strong&gt;表3&lt;/strong&gt;所示，我们的方法通过提出的双向O形跳过连接展示了更好的细分结果。
&lt;strong&gt;图3:&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108161706585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108161706585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

&lt;strong&gt;表3：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108161954114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108161954114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-超像素分割&#34;&gt;3.2 超像素分割&lt;/h3&gt;
&lt;p&gt;在超分辨率任务中，将低分辨率（下采样）图像用作输入，以将网络朝其原始的高分辨率标签训练，这可以通过重新恢复丢失的细节并生成高分辨率的组织病理学图像来帮助医学成像分析。 我们采用了两种最先进的方法FSRCNN和SRResNet与我们的BiO-Net进行比较。 整个测试集中的定性结果以及峰值信噪比（PSNR）得分如&lt;strong&gt;图4&lt;/strong&gt;所示。可以看出，我们的方法在安全范围内优于最新方法，这证明了该方法的有效性。 在不同的视觉任务上应用我们的BiO-Net的可行性。
&lt;strong&gt;图4：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210108162207164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210108162207164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在本文中，我们介绍了一种新颖的U-Net循环变体，称为BiO-Net。 BiO-Net是U-Net的紧凑替代品，具有更好的性能和无额外训练的参数，它利用成对的前向和后向跳过连接来构成编码器和解码器之间的复杂关系。 可以对模型进行递归，以在训练和推理过程中重用参数。语义分割和超分辨率任务的大量实验表明了我们提出的模型的有效性，该模型在不引入辅助参数的情况下优于U-Net及其扩展方法。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: U^2 Net借助嵌套U型结构深入研究显着物体</title>
      <link>https://Joevaen.github.io/showcase/paper/paper5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper5/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;U^2 Net借助嵌套U型结构深入研究显着物体&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2之前的相关工作&#34;&gt;2.之前的相关工作&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-多级的深度特征整合&#34;&gt;2.1 多级的深度特征整合&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-多尺度特征提取&#34;&gt;2.2 多尺度特征提取&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3我们提出的方法&#34;&gt;3.我们提出的方法&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-残差u型块&#34;&gt;3.1 残差U型块&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-usup2sup-net的结构&#34;&gt;3.2 U&lt;sup&gt;2&lt;/sup&gt;-Net的结构&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-监督策略&#34;&gt;3.3 监督策略&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4实验结果&#34;&gt;4.实验结果&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-数据集&#34;&gt;4.1 数据集&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-评估方法&#34;&gt;4.2 评估方法&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#43-实现细节&#34;&gt;4.3 实现细节&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#44-ablation-study消融研究&#34;&gt;4.4 Ablation Study（消融研究）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#441-基本块上的消融研究&#34;&gt;4.4.1 基本块上的消融研究&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#442-结构上的消融研究&#34;&gt;4.4.2 结构上的消融研究&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#443-骨干网络上的消融研究&#34;&gt;4.4.3 骨干网络上的消融研究&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#45-与sota进行对比&#34;&gt;4.5 与SOTA进行对比&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#451-定量比较&#34;&gt;4.5.1 定量比较&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#451-定性比较&#34;&gt;4.5.1 定性比较&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5总结&#34;&gt;5.总结&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.学习该算法的目的：替换针道的FLD算法和粒子检测的算子，以及测试其在器官分割上的性能；&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示对原来的理解做的一些修改或补充&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示本文的重要关键字&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=purple&gt;紫色表示后续更新的内容&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三.这篇论文最近一度登上github热榜，我都以为自己产生了幻觉，很期待它到底能发挥什么功效，其实就全文来看，想法和思路是很好理解的，阅读起来甚至没有什么难度。所以重在如何使用，以及如何用代码实现这样一个网络。所以请关注我之后的应用的文章，我会尽可能地体现代码实现网络的细节。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;        在这篇文章中，我们为&lt;strong&gt;突出物体检测&lt;/strong&gt;（SOD）设计了一种深度网络结构——U^2^-net。这个网络的结构是两层嵌套的U型结构。这样的设计具备一下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.借助我们建议的ReSidual U块（RSU）中不同大小的感受野的混合，它能够从不同的尺度捕获更多的上下文信息。&lt;/li&gt;
&lt;li&gt;2.由于在这些RSU块中使用了池化操作，因此它在不显着增加计算成本的情况下增加了整个体系结构的深度。这种架构使我们无需使用图像分类任务中的主干就可以从头开始训练深度网络。我们公开了所建议架构的两个模型：U2-Net（GTX 1080Ti GPU上为176.3 MB，30 FPS）和U2-Net†（4.7 MB，40 FPS），以促进在不同环境中的使用。 两种模型在六个SOD数据集上均实现了较好的效果。这里有&lt;a href=&#34;https://github.com/NathanUA/U-2-Net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;开源代码&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;        &lt;strong&gt;显着物体检测&lt;/strong&gt;（SOD）旨在分割图像中最具视觉吸引力的物体。 它在视觉跟踪和图像分割等许多领域得到了广泛使用。 近年来，随着深度卷积神经网络（CNN）的发展，尤其是全卷积网络（FCN）在图像分割中的兴起，显着目标检测得到了显着改善。 那么接下来面对的是什么挑战呢？
        大多数SOD网络的设计都有一个共同的模式，也就是说，它们专注于充分利用现有主干网提取的深度特征，例如Alexnet，VGG，ResNet，ResNeXt，DenseNet等。但是，这些主干都是为图像分类而设计的。他们提取代表语义含义的特征，而不是代表局部性和全局对比信息，然而后者对于显着性检测至关重要。前者首先要在ImageNet上进行预训练，然而当目标数据和ImageNet的数据分布不匹配时，就会出现数据效率低下的问题。
        这就引出了我们的第一个问题：&lt;strong&gt;我们是否可以设计一个新的SOD网络，该网络可以从头开始进行培训，并且与基于现有预训练骨干的网络相比，具有可比或更好的性能？&lt;/strong&gt;
        SOD的网络体系结构还有很多问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，它们通常过于复杂。 部分原因是由于将附加的功能聚合模块添加到现有主干中，以从这些主干中提取多级显着性功能。&lt;/li&gt;
&lt;li&gt;其次，现有的骨干网通常通过牺牲高分辨率的特征图来实现更深的架构。 为了使用负担得起的内存和计算成本来运行这些深度模型，功能图将按比例缩小以在早期降低分辨率。例如，在ResNet和DenseNet的早期层，使用了步幅为2的卷积，然后是步幅为2的maxpooling，以将特征图的大小减小到输入图的四分之一。 然而，除了深度架构外，高分辨率在分割中也起着重要作用。我们需要解决分辨率不断降低的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        因此，我们的后续问题是：我们可以以较低的内存和计算成本在保持高分辨率的特征图的同时更深入吗？
        我们的主要贡献是一个新颖且简单的网络体系结构，称为U^2^ Net，它解决了上述两个问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一，U^2^ Net是两层嵌套的U型结构，专为SOD设计，而无需使用来自图像分类的任何预训练主干。 可以从头开始对其进行训练，以实现具有竞争力的性能。&lt;/li&gt;
&lt;li&gt;第二，新颖的架构允许网络更深入，获得更高的分辨率，而不会显着增加存储和计算成本。 这是通过嵌套的U型结构实现的：在底层，我们设计了一种新颖的ReSidual U块（RSU），它能够提取级内多尺度特征而不会降低特征图的分辨率； 在顶层，有一个类似于U-Net的结构，其中每个阶段都由RSU块填充。 两级配置导致嵌套的U型结构（&lt;strong&gt;图5&lt;/strong&gt;）。 我们的U2-Net（176.3 MB）在六个公共数据集上与最先进的（SOTA）方法相比具有竞争优势，并在以下条件下实时运行（30 FPS，输入大小为320×320×3） 1080TiGPU。 为了便于在计算和内存受限的环境中使用我们的设计，我们提供了U2-Net的一个小版本，称为U2-Net†（4.7 MB）。 U2-Net†以40 FPS的速度获得了与大多数SOTA模型（&lt;strong&gt;图1&lt;/strong&gt;）的竞争结果。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图5&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/202012141056315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/202012141056315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图1&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214105738836.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214105738836.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2之前的相关工作&#34;&gt;2.之前的相关工作&lt;/h2&gt;
&lt;p&gt;        近年来，已经提出了许多深层的显着物体检测网络。 与基于手工特征（如前地面一致性，高光谱信息，超像素相似度，直方图等）的传统方法相比，深显着物体检测网络显示出更具竞争力的性能。&lt;/p&gt;
&lt;h3 id=&#34;21-多级的深度特征整合&#34;&gt;2.1 多级的深度特征整合&lt;/h3&gt;
&lt;p&gt;        最近的工作表明，来自多个深层的特征能够产生更好的结果。 正是因为如此，针对SOD许多用于集成和聚合多层深度特征的策略和方法被开发。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Li等人的 &lt;strong&gt;MDF&lt;/strong&gt; 提出将目标像素周围的图像块馈送到网络，然后获得用于描述此像素显着性的特征向量。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;Amulet&lt;/strong&gt; 通过将多级特征聚合为不同的分辨率来预测显着性图。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;UCF&lt;/strong&gt; 提出通过引入重新设计的dropout和混合升序插补模块来减少反卷积算子的棋盘伪影。&lt;/li&gt;
&lt;li&gt;Luo等人设计具有4×5网格结构的显着性检测网络 &lt;strong&gt;NLDF +&lt;/strong&gt; ，其中较深的功能与较浅的功能逐渐集成在一起。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;LFR&lt;/strong&gt; 通过使用同级架构从原始输入图像及其反射图像中提取特征来预测显着性图。&lt;/li&gt;
&lt;li&gt;Hou等人的 &lt;strong&gt;DSS+&lt;/strong&gt; 建议通过引入从深层到浅层的短连接来集成多级功能。&lt;/li&gt;
&lt;li&gt;Chen等人的 &lt;strong&gt;RAS&lt;/strong&gt; 通过将骨干网的侧面输出显着性作为特征关注指南来迭代和预测显着性图。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;BMPM&lt;/strong&gt; 提出通过受控的双向传递策略来整合深层和深层的特征。&lt;/li&gt;
&lt;li&gt;Deng等人的 &lt;strong&gt;R^3^Net+&lt;/strong&gt; 交替结合浅层和深层的功能，以完善预测的显着性图。&lt;/li&gt;
&lt;li&gt;Hu等人的 &lt;strong&gt;RADF+&lt;/strong&gt; 建议通过循环聚合多层深度特征来检测目标对象。&lt;/li&gt;
&lt;li&gt;Wu等人的 &lt;strong&gt;MLMS&lt;/strong&gt; 通过开发一种新型的互学习模块来更好地利用边界和区域的相关性，从而提高了显着性检测的准确性。&lt;/li&gt;
&lt;li&gt;Wu等人提出使用级联局部解码器 &lt;strong&gt;CPD&lt;/strong&gt; 框架进行快速准确的显着目标检测。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        这类深度方法利用了骨干网络提取的多级深度特征，与传统方法相比，大大提高了显着目标检测的水平。&lt;/p&gt;
&lt;h3 id=&#34;22-多尺度特征提取&#34;&gt;2.2 多尺度特征提取&lt;/h3&gt;
&lt;p&gt;        如前所述，显着性检测需要本地和全局信息。 3×3的卷积核非常适合在每个图层上提取局部特征。 但是，仅通过增大滤波器的大小就难以提取全局信息，因为这将急剧增加参数的数量和计算成本。
        有许多工作关注着如何获取全局信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wang等人的 &lt;strong&gt;SRM&lt;/strong&gt; 利用金字塔池模块适应以捕获全局上下文，并提出了一种用于显着图重新细化的多阶段细化机制。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;PAGRN&lt;/strong&gt; 开发了一个空间和逐通道注意模块来获取每一层的全局信息，并提出了一种渐进式注意引导机制来完善显着图。&lt;/li&gt;
&lt;li&gt;Wang等人的 &lt;strong&gt;DGRL&lt;/strong&gt; 开发了一个类似Inception的连续加权模块来全局定位显着对象，然后使用边界优化模块来局部优化显着性图。&lt;/li&gt;
&lt;li&gt;Liu等人的 &lt;strong&gt;PiCANet&lt;/strong&gt; 反复捕获局部和全局像素方面的上下文关注，并通过将其与U-Net体系结构合并来预测显着性图。&lt;/li&gt;
&lt;li&gt;Zhang等人的 &lt;strong&gt;CapSal&lt;/strong&gt; 设计了一个本地和全局感知模块，以从骨干网络提取的特征中提取本地和全局信息。&lt;/li&gt;
&lt;li&gt;Zeng等人的 &lt;strong&gt;MSWS&lt;/strong&gt; 设计一个注意模块，以预测前景对象在图像区域上的空间分布，同时汇总其特征。&lt;/li&gt;
&lt;li&gt;Feng等人的 &lt;strong&gt;AFNet&lt;/strong&gt; 开发了一个全局感知模块和专心的反馈模块，以更好地探索突出对象的结构。&lt;/li&gt;
&lt;li&gt;Qin等人的 &lt;strong&gt;BASNet&lt;/strong&gt; 提出了一种预测细化模型，该模型通过依次堆叠两个不同配置的U-Nets和混合损失来进行边界感知的显着物体检测。&lt;/li&gt;
&lt;li&gt;Liu等人的 &lt;strong&gt;PoolNet&lt;/strong&gt; 通过引入用于提取全局定位特征的全局指导模块和从金字塔池模块改编而来的用于融合全局和精细级特征的多尺度特征聚合模块，开发了用于显着目标检测的编码器-解码器体系结构。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        在这些方法中，提出了许多启发性模块，以从现有骨架中提取的多层次深度特征中提取多尺度特征。 这些新颖的模块引入了多样化的接受领域和更丰富的多尺度上下文特征，从而显着提高了显着物体检测模型的性能。&lt;/p&gt;
&lt;p&gt;        综上所述，一方面，&lt;strong&gt;多层深度特征集成&lt;/strong&gt;主要集中在开发更好的多层特征聚合策略上。 另一方面，&lt;strong&gt;多尺度特征提取类别&lt;/strong&gt;中的方法针对设计新模块以从骨干网络获得的特征中提取局部和全局信息。 如我们所见，几乎所有上述方法都试图更好地利用现有图像分类主干生成的特征图。 我们没有开发和添加更复杂的模块和策略来使用这些主干的功能，而是提出了一种新颖而简单的体系结构，该体系结构会逐步逐步提取多尺度特征，用于显着目标检测。&lt;/p&gt;
&lt;h2 id=&#34;3我们提出的方法&#34;&gt;3.我们提出的方法&lt;/h2&gt;
&lt;p&gt;        首先我们介绍残差U型块的设计，然后描述利用这个U型块进行设计的嵌套结构，网络监督策略和训练损失将会在这部分的最后进行解释。&lt;/p&gt;
&lt;h3 id=&#34;31-残差u型块&#34;&gt;3.1 残差U型块&lt;/h3&gt;
&lt;p&gt;        对于显著物体检测来说，局部和全局信息都是非常重要的。在当前许多的CNN设计中，所有的卷积核都是1x1或者3x3，用来提取特征信息，这是非常受欢迎的因为这样所需要消耗的内存小而且效率高。&lt;strong&gt;图2&lt;/strong&gt;（a）-（c）展示了典型的现有的具有小接收场的卷积块。浅层的输出特征图仅包含局部特征，因为1×1或3×3卷积核的接受场太小，无法捕获全局信息。为了在浅层高分辨率特征图中获得更多的全局信息，最直接的想法是扩大接收范围。&lt;strong&gt;图2&lt;/strong&gt;（d）显示了一个类似块的起始块，它试图通过使用扩大的卷积来扩大接收场来提取局部和非局部特征。 但是，以原始分辨率在输入特征图上（尤其是在早期阶段）进行多次卷积需要太多的计算和内存资源。为了降低计算成本，PoolNet 调整了金字塔池模块（PPM）的并行配置，金字塔模块在降采样特征图上使用了较小的卷积核，而不是在原始尺寸特征图上使用了卷积。 但是通过直接上采样和级联（或相加）来融合不同比例尺的特征可能会导致高分辨率特征的退化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图2&lt;/strong&gt;：这张图下面的举例写反了，读者要注意一下


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214140135673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214140135673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        受U-Net的启发[34]，我们提出了一种新颖的ReSidualU块RSU，以捕获阶段内多尺度特征。 RSU-L（$C_{in}，M，C_{out}$）的结构如图2（e）所示，其中$L$是编码器中的层数，$C_{in}，C_{out}$表示输入和输出通道，$M$表示RSU内部层中的通道数。 因此，我们的RSU主要由三个部分组成：&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(i)&lt;/strong&gt;&lt;/em&gt;  输入卷积层，将输入特征映射$x（H×W×C_{in}）$转换为通道为$C_{out}$的中间映射$F_1（x）$。 这是用于局部特征提取的简单卷积层。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(ii)&lt;/strong&gt;&lt;/em&gt; 高度为 $L$ 的类似U-Net的对称编码器/解码器结构，以中间特征图$F_1（x）$作为输入，并学习提取和编码多尺度上下文信息$U（F_1（x））$。$U$表示类似U-Net的结构，如&lt;strong&gt;图2&lt;/strong&gt;（e）。 较大的值导致更深的残留U块（RSU），更多的合并操作，较大的接受域范围以及更丰富的局部和全局特征。配置此参数可以从具有任意空间分辨率的输入特征图中提取多尺度特征。 从渐进下采样的特征图中提取多尺度特征，并通过逐步上采样，级联和卷积将其编码为高分辨率特征图。 该过程减轻了由大规模直接上采样引起的精细细节的损失。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(iii)&lt;/strong&gt;&lt;/em&gt; 残差连接，通过将总和融合为局部特征和多尺度特征：$F_1（x）+ U（F_1（x））$
        为了更好的说明我们设计的意图，我们将原始残差结构和RSU进行了对比，如&lt;strong&gt;图3&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图3&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214144211540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214144211540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        一般残差块的结构可以概括为$H(x) =F_2(F_1(x))+x$，其中$H(x)$表示我们期望得到的特征$x$的映射、$F_1, F_2$代表的是权重层，在这里是卷积操作。RSU与一般残差块的不同点在于：RSU用U形替代了单方向形，同时用权重层（$H_{RSU}(x) =U(F_1(x))+F_1(x)$）转换的局部特征替换原始特征。这种设计更改使网络能够直接从每个残差块中提取多种尺度的特征。 更值得注意的是，由于大多数操作都在降采样特征图上进行，因此由于U型结构而导致的计算开销很小。 这在**图4**中进行了说明，其中我们在**图4**中显示了RSU与其他特征提取模块之间的计算成本比较。  密集块（DSE），起始块（INC）和RSU的FLOP随内部通道M的数量呈二次方增长。 但是RSU在二次项上的系数要小得多，从而提高了效率。 与普通卷积（PLN）和残差块（RES）块（均为线性w.r.t.M）相比，其计算开销并不大。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图4&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214144117116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214144117116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-usup2sup-net的结构&#34;&gt;3.2 U&lt;sup&gt;2&lt;/sup&gt;-Net的结构&lt;/h3&gt;
&lt;p&gt;        一段时间以来，已经探索了为不同任务堆叠多个类似U-Net的结构。 ，例如 堆叠的hourgalssnetwork，DocUNet，CU-Net进行姿势估计等。这些方法通常按顺序堆叠类似U-Net的结构以构建级联模型，可以概括为“（U× n-Net）”，其中重复的U-Net模块数。 问题在于计算和主题成本会以n倍放大。
        在本文中，我们提出了一种不同的Un-Net堆叠U结构用于显着目标检测的表示方法。我们的结构是嵌套的U结构而不是级联堆叠。 从理论上讲，可以将指数设置为任意正整数，以实现单层或多层嵌套U型结构。 但是嵌套层次太多的体系结构太复杂而无法在实际应用中实现和使用。
        在这里，我们设置n=2来构建U&lt;sup&gt;2&lt;/sup&gt;-Net。 我们的U&lt;sup&gt;2&lt;/sup&gt;-Net是一个两层嵌套的U型结构，如&lt;strong&gt;图5&lt;/strong&gt;所示。它的最外边是一个大的U型结构，由11个阶段组成。 每个阶段都由配置良好的残余U块（RSU）（底部U型结构）填充。 因此，嵌套U结构可更加有效地提取阶段内多尺度特征并聚合阶段间多尺度特征。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图五&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214145137551.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214145137551.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        正如&lt;strong&gt;图5&lt;/strong&gt;所示，U&lt;sup&gt;2&lt;/sup&gt;-Net主要包括三个部分：(1) 六个编码器；(2)五个解码器；(3)连接编码器信息和解码器信息的一个混合模块：&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(i)&lt;/strong&gt;&lt;/em&gt; 在编码器En1，E​​n2，En3和En4中，我们分别使用了RSU-7，RSU-6，RSU-5和RSU-4。 如前所述，“ 7”，“ 6”，“ 5”和“ 4”表示RSU块的高度（$L$）。$L$通常根据输入要素图的空间分辨率进行配置。 对于高度和宽度较大的要素地图，我们使用更大的 $L$ 捕获更多大规模信息。 En5和​​En6中特征图的分辨率相对较低，这些特征图的进一步下采样导致有用上下文的丢失。因此，在En5和En6中，我们使用的是RSU-4F，其中“ F”表示RSU的扩版本，其中我们用扩张卷积代替了合并和上采样运算（&lt;strong&gt;图5&lt;/strong&gt;）。这意味着RSU-4F的所有中间特征图都具有与其输入特征图相同的分辨率。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(ii)&lt;/strong&gt;&lt;/em&gt; 在解码器阶段，在En6时编解码结构相同。在De5，我们使用类似于En5的RSU-4F的扩张卷积版本。每一级解码器都将来自其上一级的上采样特征映射和来自其对称编码器级的特征映射的串联作为输入，参见&lt;strong&gt;图5&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;(iii)&lt;/strong&gt;&lt;/em&gt; 最后一部分是显著性图融合模块，用于生成显著性概率图。
与HED类似，我们的U^2^-Net首先从En6，De5，De4，De3，De2和De1通过3x3卷积核和sigmoid函数生成六个side输出显着性概率图：$S^{（6）}&lt;em&gt;{side}，S^{（5）}&lt;/em&gt;{side}，S^{（4）}&lt;em&gt;{side}，S^{（3）}&lt;/em&gt;{side}，S^{（2）}&lt;em&gt;{side}，S^{（1）}&lt;/em&gt;{side}$。 然后，它将side输出显着性图的逻辑回归（在Sigmoid函数之前的卷积输出）上采样到输入图像大小，并将它们与级联运算融合，随后是1×1卷积层和sigmoid函数以生成最终显着性概率图$S_{fuse}$（请参见**图5**的右下角）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        总而言之，我们的U^2^-Net的设计允许具有丰富的多尺度功能的深度体系结构以及相对较低的计算和内存成本。 此外，由于我们的U^2^-Net架构仅建立在我们的RSU上，而未使用任何经过图像分类的预训练主干，因此它灵活且易于适应不同的工作环境，而性能损失不大。 在本文中，我们通过使用不同的卷积核编号配置来提供U2-Net的两种实例：正常版本的U^2^-Net（176.3 MB）和相对较小的版本的U^2^-Net†（4.7 MB）。 &lt;strong&gt;表1&lt;/strong&gt;的最后两行显示了详细的配置。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表1：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201214163548615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201214163548615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;33-监督策略&#34;&gt;3.3 监督策略&lt;/h3&gt;
&lt;p&gt;        在培训过程中，我们使用类似于HED的深度监督策略。 在HED和DSS中已经证明了其有效性。 我们的训练损失定义为：
$$\mathcal L = \sum_{m=1}^Mw_{side}^{(m)}l_{side}^{(m)}+w_{fuse}l_{fuse}$$
        以图5为例，$l_{side}^{(m)}$是$S^{(m)}_{side}$的损失，而$l_{fuse}$是$S_{fuse}$的损失；$w_{side}^{(m)}$和$w_{fuse}$是每个损失项的权重。对于每一个项$l$，我们使用BCE来计算损失：
$$l = -\sum_{(r,c)}^{(H,W)}[P_{G(r,c)}logP_{S(r,c)}+(1-P_{G(r,c)}log(1-P_{S(r,c)}))]$$
        在这里，$(r,c)$是像素点的坐标，$(H,W)$是图像的高宽，$P_{G(r,c)}$表示像素的真实值，$P_{S(r,c)}$表示像素的预测值，训练的目的是尽可能的使得总损失$\mathcal L$最小。在测试过程中，我们选择融合输出$l_{fuse}$作为最终的显着性图。&lt;/p&gt;
&lt;h2 id=&#34;4实验结果&#34;&gt;4.实验结果&lt;/h2&gt;
&lt;h3 id=&#34;41-数据集&#34;&gt;4.1 数据集&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;训练数据&lt;/strong&gt;：我们在DUTS-TR上训练我们的网络，DUTS-TR是DUTS数据集的一部分。DUTS-TR总共包含10553张图像。 目前，它是最大的，最常用的用于显着目标检测的训练数据集，我们通过水平翻转来扩充该数据集，共获取21106个训练图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估数据&lt;/strong&gt;：六个常用的基准数据集用于评估我们的方法，包括：DUT-OMRON，DUTS-TE，HKU-IS，ECSSD，PASCAL-S，SOD。 DUT-OMRON包含5168个图像，其中大多数包含一个或两个结构复杂的前景对象。 DUTS数据集包括两部分：DUTS-TR和DUTS-TE。 如上所述，我们使用DUTS-TR进行培训。 因此，选择包含5019张图像的DUTS-TE作为我们的评估数据集之一.HKU-IS包含4447张具有多个前地面物体的图像.ECSSD包含1000张结构复杂的图像，其中许多包含大型前景物体.PASCAL-Scontains 850 具有复杂前景对象和杂乱背景的图像。SOD仅包含300个图像。 但这是非常具有挑战性的。 因为它最初是为图像分割而设计的，所以许多图像对比度较低或包含与图像边界重叠的复杂前景对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;42-评估方法&#34;&gt;4.2 评估方法&lt;/h3&gt;
&lt;p&gt;        深度显著目标检测的方法输出通常是概率图，其与输入图像具有相同的空间分辨率。 预测显著性图的每个像素的值都在0到1（或[0，255]）的范围内。gt通常是二进制掩码，其中每个像素为0或1（或0和255），其中0表示 背景像素和1表示前景显着对象像素。
        为了全面评估那些相对于gt的概率图的质量，使用以下六种度量：（1）精度回归（PR）曲线，（2）最大F度量（$maxF_β$），（3） 绝对误差（MAE），（4）加权F度量（$F^w_β$），（5）结构度量（$S_m$），以及（6）约束的松弛F测度（$relaxF^b_β$）:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PR曲线&lt;/strong&gt;：由很多对的精度-回归值组成的曲线，给定一个预测的显着性概率图，可通过将其阈值化的二进制掩码与gt进行比较来计算其精度和召回分数。 数据集的精度和召回率是通过对这些显着性图的精度和召回率取平均值来计算的。 通过将阈值从0调到1，我们可以获得数据集的一组平均精确-回归率对。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最大F度量（$maxF_β$）&lt;/strong&gt;：$F_β$用来全面评估精确率和召回率：
$$F_β=\frac{(1+β^2)\times{Precision}\times{Recall}}{β^2\times{Precision}+Recall}$$
类似于之前的工作，我么将$β^2$设置为0.3，从而得到每个数据集的最大值$maxF_β$。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MAE&lt;/strong&gt;：MAE是平均绝对误差，它表示预测的显著性图与gt之间的平均每像素差。它是这样定义的：
$$MAE=\frac{1}{H\times{W}}\sum_{r=1}^H\sum_{c=1}^W|P(r,c)-G(r,c)|$$
$P、G$是分别是像素预测值和gt，$(H,W)、（r,c）$是宽高和像素点的坐标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;加权F度量（$F^w_β$）&lt;/strong&gt;：它被用作$maxF_β$的补充措施，以克服由&lt;font color=red&gt;&lt;strong&gt;“内插缺陷，依赖缺陷和等重要性缺陷”&lt;/strong&gt;&lt;/font&gt;引起的可能的不公平比较。 定义为:
$$F^w_β=(1+β^2)\frac{{Precision^w}\cdot{Recall^w}}{β^2\cdot{Precision^w}+Recall^w}$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结构度量（$S_m$）&lt;/strong&gt;：$S-measure（S_m）$用于评估预测的非二进制显著图和gt的结构相似性。$S_m$被定义为区域感知$S_r$和对象感知$S_o$结构相似度的加权和：
$$S=(1-α)S_r+αS_o$$
$α$通常被设置为0.5。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;&lt;strong&gt;约束的松弛F测度（$relaxF^b_β$）&lt;/strong&gt;&lt;/font&gt;&lt;/strong&gt;：用于定量评估预测显著性图的边界质量。给定一个显着性概率图$P∈[0,1]$，通过简单阈值运算（阈值设置为0.5）获得其二进制掩码$P_{bw}$。 然后，进行$XOR（P_{bw}，P_{erd}）$操作以获得其一个像素宽的边界，其中$P_{erd}$表示$P_{bw}$的腐蚀二进制掩码。 以相同的方式获得gt的边界。 松弛边界$F-measure$ $relaxF^b_β$的计算类似于方程式:
$$F_β=\frac{(1+β^2)\times{Precision}\times{Recall}}{β^2\times{Precision}+Recall}$$ 区别在于方程中使用的$relaxPrecision^b$和$relaxRecall^b$不同于$Precision$和$Recall$。 松弛边界精度（$relaxPrecision^b$）的定义是从gt的边界像素中拿出$p$个，求这些像素的预测的边界分数。 松散边界召回（$relaxRecall^b$）定义是从预测的边界像素中拿出$p$个，求这些像素的gt的边界分数。 公式即为：
$$F_β=\frac{(1+β^2)\times{relaxPrecision^b}\times{relaxRecall^b}}{β^2\times{relaxPrecision^b}+relaxRecall^b}$$
在先前的工作中，松弛参数$ρ$被设置为3。 在给定数据集的情况下，本文报告了所有预测的显著性图的平均$relaxF^b_β$。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;43-实现细节&#34;&gt;4.3 实现细节&lt;/h3&gt;
&lt;p&gt;        在训练的过程中，每张图片会被resize成$320\times320$，同时随机旋转然后再裁剪成$288\times288$。我们不再使用任何的骨干网络，因此，我们从头开始训练我们的网络，所有的卷积层都由Xavier初始化。损失的权重$w^{(m)}&lt;em&gt;{side}$和$w&lt;/em&gt;{fuse}$都设置为1。使用Adam优化器，其超参数lr=1e-3，betas=(0.9, 0.999)，eps=1e-8，weight_decay=0。我们在不使用验证集的情况下训练网络直到损失收敛。大约在60万的iteration（batchsize为12）后，损失收敛，总共用时120个小时。在测试时，输入图片被resize为$320\times320$然后输入网络从而获得显著性图，预测后的显著性图为$320\times320$然后会重新resize成原始大小。两次resize都用的线性插值。网络使用的是pytorch0.4.0，训练和测试都在8核、16线程的PC上（AMD Ryzen 1800x3.5 GHz CPU (32GB RAM) 和 GTX 1080ti GPU (11GBmemory）。我们已经将代码开源。&lt;/p&gt;
&lt;h3 id=&#34;44-ablation-study消融研究&#34;&gt;4.4 Ablation Study（消融研究）&lt;/h3&gt;
&lt;p&gt;        为了验证我们的U^2^-Net的有效性，我们在以下三个方面进行了消融研究:&lt;strong&gt;i)基本块&lt;/strong&gt;、&lt;strong&gt;ii)结构&lt;/strong&gt;和&lt;strong&gt;iii)骨干&lt;/strong&gt;。所有的消融研究都遵循相同的实现设置。&lt;/p&gt;
&lt;h4 id=&#34;441-基本块上的消融研究&#34;&gt;4.4.1 基本块上的消融研究&lt;/h4&gt;
&lt;p&gt;        在块消融时，目标是验证我们新设计的RSU的有效性。具体来说，我们固定了我们的U^2^-Net的外部编解码器结构，并用RSU块之外的其他常用块(包括普通卷积块(PLN)、类剩余块(RSE)、类密集块(DSE)、类切波块(INC)和金字塔池模块(PPM))替换了它，如&lt;strong&gt;图2&lt;/strong&gt; (a)-(d)所示。详细的配置见&lt;strong&gt;表1&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图2&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215104009710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215104009710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表一&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215104036474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215104036474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        &lt;strong&gt;表2&lt;/strong&gt;给出了烧蚀研究的定量结果。我们可以看到，基准U-Net的性能最差，而PLN U-Net、RES U-Net、DES U-Net、INCU-Net和PPM U-Net的性能优于基准U-Net。因为它们要么是较深的，要么是具有提取多尺度特征的能力。然而，他们的表现仍然不如我们的全尺寸的U2-Net和小版本的U2-Net†。特别是，在DUT-OMRON和ECSSD数据集上，我们的全尺寸的U^2^-net提升了$maxF_β$大约有3.3%和1.8%，与第二好的模型(在块消融研究中)相比，降低了$MAE$超过12.9%和21.4%。此外，我们的U^2^-net和U^2^-Net†在DUT-OMRON数据集相对于基线U-Net，增加了$maxF_β$ 9.8%和8.8%，减少了 $MAE$ 34.1%和27.0%，这是显著的改善。在ECSSD数据集上，虽然我们的U^2^-Net和U^2^-Net†的$maxF_β$改进(5.5%，4.7%)相对于基线U-Net略低于DUT-OMRON, $MAE$ 的改进更大(50.0%，38.0%)。因此，我们认为我们新设计的RSU在该突出目标检测任务中比其他的块更好。此外，我们的基于残余RSU的U^2^-Net架构没有显著的时间成本增加。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表2&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215104217547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215104217547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;442-结构上的消融研究&#34;&gt;4.4.2 结构上的消融研究&lt;/h4&gt;
&lt;p&gt;        正如我们上面提到的，以前的方法通常使用cascaded的方式来堆叠多个类似的结构，以构建更具表达性的模型。该思想的一个直观的特点是，多个相似结构能够在减少过拟合的同时逐步改进结果。StackedHourglassNet和CU-Net是这类模型中的两个代表性模型。因此，我们采用了StackedHourglassNet和CU-Net来比较级联架构和嵌套架构之间的性能。如&lt;strong&gt;表2&lt;/strong&gt;所示，我们的全尺寸模型U^2^-Net和小尺寸模型U^2^-Net†均优于这两种级联模型。值得注意的是，StackedHourglassNet和CU-Net都采用了改进的类u网模块作为它们的堆叠子模型。为了进一步证明我们的嵌套架构的有效性，我们还举例说明了一个基于朴素u块(NIV)的U^2^-Net的表现，而不是我们新提出的RSU。我们可以看到，NIV U^2^-Net仍然取得了比这两个级联模型更好的性能。此外，嵌套架构比级联架构更快。综上所述，我们的内嵌架构在精度和速度方面都比传统的内嵌架构取得了更好的性能。&lt;/p&gt;
&lt;h4 id=&#34;443-骨干网络上的消融研究&#34;&gt;4.4.3 骨干网络上的消融研究&lt;/h4&gt;
&lt;p&gt;        不同于以往突出的目标检测模块(如vgg、ResNet等)使用骨干作为编码器，我们新提出的U^2^-Net架构是无骨干的。为了验证自由骨干网的设计，我们进行了研究，用不同的骨干网:VGG16和ResNet50替换我们的全sizeU2-Net的编码器部分。实际上，我们对主干(VGG-16和ResNet-50)进行了调整，在它们的最后一个convolutionalstage之后增加了一个额外的stage，以实现与我们最初的U^2^-Net架构设计相同的接受域。如&lt;strong&gt;表2&lt;/strong&gt;所示，使用骨干和RSU作为解码器的模型取得了比以前的实验更好的性能，并且与我们的小型U^2^-Net相比具有更好的性能。然而，他们仍然低于我们的全尺寸的U^2^-Net。因此，我们认为在SOD任务中，我们的无骨架设计比基于骨架的设计更有竞争力。&lt;/p&gt;
&lt;h3 id=&#34;45-与sota进行对比&#34;&gt;4.5 与SOTA进行对比&lt;/h3&gt;
&lt;p&gt;        我们比较了我们的模型(全尺寸的U^2^-Net, 176.3 MB和小尺寸的U^2^-Net†，4.7 MB)与20种SOTA的方法，包括基于AlexNet的模型：MDF;10个基于vgg模型：UCF,Amulet,NLDF,DSS,RAS,PAGRN,BMPM,PiCANet,MLMS,AFNet;一个基于DenseNet的模型：MSWS;一个基于ResNeXt的模型：R3Net;和7个基于ResNet的模型：CapSal、SRM DGRL, Pi-CANetR, CPD, PoolNet BASNet。为了公平比较，我们主要使用了作者提供的SOD结果。对于某些方法的某些数据集上缺失的结果，我们在建议的环境设置上用训练过的模型运行它们发布的代码。&lt;/p&gt;
&lt;h4 id=&#34;451-定量比较&#34;&gt;4.5.1 定量比较&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图6&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215110534922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215110534922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215110546798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215110546798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215110618550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215110618550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        &lt;strong&gt;图6&lt;/strong&gt;展示了我们的模型(U2-Net, 176.3 MB和U2-Net†，4.7 MB)的PR曲线以及对这六个数据集的典型的最新方法。这些曲线与&lt;strong&gt;表3&lt;/strong&gt;和&lt;strong&gt;表4&lt;/strong&gt;一致，&lt;strong&gt;表3&lt;/strong&gt;和&lt;strong&gt;表4&lt;/strong&gt;展示了我们的U^2^-Net在DUT-OMRON、HKU-IS和ECSSD上的最新性能，以及在其他数据集上的竞争性性能。&lt;strong&gt;表3&lt;/strong&gt;和&lt;strong&gt;表4&lt;/strong&gt;比较了我们提出的方法的五个(六个包括模型大小)评价指标和模型大小。正如我们所看到的，我们的U^2^-Net在数据集DUT-OMRON、HKU-IS和ecssd上几乎在所有五个评估指标上都达到了最好的性能。在DUTS-TE数据集上，我们的U^2^-Net实现了第二好的总体性能，略低于PoolNet。在PASCAL-S上，我们的U^2^-Net的性能略逊于AFNet、CPD和PoolNet。值得注意的是，在边界质量评价指标$relaxF^b_β$方法方面，U^2^-net达到了第二好的性能。在SOD上，PoolNet的性能最好，而在总体性能方面，我们的U^2^-Net是第二好的。
        我们的U^2^-Net†只有4.7 MB，这是目前在突出目标检测领域最小的模型。与其他模型相比，少得多的参数，它仍然取得惊人的竞争性能。虽然它的性能不如我们的全尺寸的U^2^-Net，但它的小尺寸将有助于它在许多计算和内存受限的环境中的应用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;表3&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215111255133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215111255133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表4&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215111316213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215111316213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;451-定性比较&#34;&gt;4.5.1 定性比较&lt;/h4&gt;
&lt;p&gt;        为了直观地理解我们的模型的前景表现，我们在&lt;strong&gt;图7&lt;/strong&gt;中说明了我们的模型的样本结果和其他几个最先进的方法。正如我们所看到的，我们的U^2^-Net和U^2^-Net†能够处理不同类型的目标，并产生准确的显著的目标检测结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图7&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201215111438588.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201215111438588.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        &lt;strong&gt;图7&lt;/strong&gt;的第1行和第2行显示了大小对象的结果。正如我们可以观察到的，我们的U^2^-Net和U^2^-Net†能够产生大、小物体上的精确结果。其他模型要么容易错过小目标，要么产生精度不高的大目标。第3行显示了目标触摸图像边界的结果。我们的U^2^-Net正确地划分了所有区域。尽管U^2^-Net†错误地节的底部右眼，它仍然比其他模型好得多。第4行展示了模型在分割由大的和薄的结构组成的目标时的性能。正如我们所看到的，除了AFNet之外，大多数其他模型都能很好地提取出大的区域，但却缺少明智的薄结构。在第5行中，一棵树的背景是相对干净的蓝天， 它看起来很简单，但它实际上是十分具有挑战性的，因为目标数目的复杂形状。正如我们所看到的，我们的模型可以很好地分割树干和树枝，而其他的模型在分割复杂的树枝区域时失败了。与第五行相比，第六行的长椅更加复杂，这是因为其中空的结构。我们的U^2^-Net产生了接近完美的结果。虽然在U^2^-Net†的预测图的右下角是不完善的，但它在这一目标上的总体表现比其他模型要好得多。此外，与PoolNet、CPD、PiCANetR和AFNet等模型相比，我们的模型结果更加均匀，灰色区域更少。第7行显示，我们的模型可以产生比gt更精细的结果。标记这些小孔在第7幅图像费时费力，所以在标注过程中，这些重复的精细结构往往被忽略。从这些不完美的标签推断正确的结果是具有挑战性的。但我们的模型在分割这些精细结构方面显示出了良好的能力，这要归功于精心设计的架构，可以提取和集成高分辨率的局部信息和低分辨率的全局信息。第8行和第9行显示了我们的模型在处理背景杂乱和前景外观复杂的目标时的强大能力。第10行显示了我们的模型能够在捕获检测到的目标细节的同时分割多个目标(参见每个帆船的两个分支的间隙区域)。总之，我们的全尺寸模型和小尺寸模型都能够处理各种各样的sc -narios，并产生高精度的显著目标检测结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5总结&#34;&gt;5.总结&lt;/h2&gt;
&lt;p&gt;        在本文中，我们提出了一种新的深度网络:U^2^-Net，用于显著目标检测。我们的U^2^-Net的主要架构是一个两层嵌套的u结构。嵌套的u型结构与我们新设计的RSU块，使网络从浅层和深层捕获更丰富的局部和全局信息。与那些建立在现有骨干上的SOD模型相比，我们的U^2^-Net完全建立在所提议的RSU上，这使得它可以根据目标环境的约束从开始训练并配置成不同的模型大小。在本文中，我们提供了一个全尺寸的U^2^-Net (176.3 MB, 30 FPS)和一个较小尺寸的U^2^-Net†(4.7 MB, 40 FPS)。在6个公共突出目标检测数据集的实验结果表明，相对于其他20个最先进的方法在定性和定量措施，两种模型取得了非常有竞争力的性能。
虽然我们的模型取得了与其他最先进的方法竞争的结果，但更快和更小的模型需要计算和内存有限的设备，如移动电话，机器人等。在不久的将来，我们将研究不同的技术和架构来进一步提高速度和减小模型的尺寸。此外，需要更大的多样化显著目标数据集来训练更精确和鲁棒的模型。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: CT中伪影的识别和规避</title>
      <link>https://Joevaen.github.io/showcase/paper/paper6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper6/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;CT中伪影的识别和规避&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#物理伪影&#34;&gt;物理伪影&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#一beam-hardening线质硬化&#34;&gt;一、Beam Hardening（线质硬化）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i线质硬化的原理&#34;&gt;I.线质硬化的原理&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii线质硬化的表现&#34;&gt;II.线质硬化的表现&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral杯子伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;杯子伪影&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral密集对象之间的暗带或条纹font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;密集对象之间的暗带或条纹&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#iii解决线质硬化的内置功能&#34;&gt;III.解决线质硬化的内置功能&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#iv避免线质硬化的操作方法&#34;&gt;IV.避免线质硬化的操作方法&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#二partial-volume部分体积效应&#34;&gt;二、Partial Volume（部分体积效应）&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#三photon-starvation光子饥饿效应&#34;&gt;三、Photon Starvation（光子饥饿效应）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i-光子饥饿原理&#34;&gt;I. 光子饥饿原理&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii-光子饥饿解决方案&#34;&gt;II. 光子饥饿解决方案&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoralautomatic-tube-current-modulation自动管电流调制font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;Automatic Tube Current Modulation（自动管电流调制）:&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoraladaptive-filtration自适应过滤font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;Adaptive Filtration（自适应过滤）:&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#四undersampling欠采样&#34;&gt;四、Undersampling（欠采样）&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#病例伪影&#34;&gt;病例伪影&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#一metallic-materials金属材料&#34;&gt;一、Metallic Materials（金属材料）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i金属伪影原因&#34;&gt;I.金属伪影原因&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii解决方案&#34;&gt;II.解决方案&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral在操作上避免金属伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;在操作上避免金属伪影:&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral软件上修正伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;软件上修正伪影:&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#二patient-motion移动伪影&#34;&gt;二、Patient Motion（移动伪影）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i移动伪影原因&#34;&gt;I.移动伪影原因&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii移动伪影解决方案&#34;&gt;II.移动伪影解决方案&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral操作上避免移动伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;操作上避免移动伪影&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral内置功能可最大程度地减少运动伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;内置功能可最大程度地减少运动伪影&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#三incomplete-projections不完整的投影&#34;&gt;三、Incomplete Projections（不完整的投影）&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#扫描仪伪影&#34;&gt;扫描仪伪影&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#一ring-artifacts环状伪影&#34;&gt;一、Ring Artifacts（环状伪影）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i环装伪影原因&#34;&gt;I.环装伪影原因&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii环状伪影解决方案&#34;&gt;II.环状伪影解决方案&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#二helical-and-multisection-ct-artifacts螺旋多段状伪影&#34;&gt;二、Helical and Multisection CT Artifacts（螺旋、多段状伪影）&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#i轴向平面中的螺旋伪影单节扫描&#34;&gt;I.轴向平面中的螺旋伪影：单节扫描&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#ii多段扫描中的螺旋伪影&#34;&gt;II.多段扫描中的螺旋伪影&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#iii锥束效应&#34;&gt;III.锥束效应&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#iv多平面和三维重塑&#34;&gt;IV.多平面和三维重塑&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral阶梯状伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;阶梯状伪影&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#font-colorcoral斑马伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;斑马伪影&lt;/strong&gt;&lt;/font&gt;&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.之前的工作持续了很长一段，所以博客的更新进度比较慢，关于分割的很多问题也没有花更多的精力，毕竟不是求学阶段，所以还是工作的结果更重要。主要解决对于粒子手术中针道的检测问题，产生的一些小的问题花费了巨额的时间来进行修正和调整。有意思的是，在这么长时间的问题解决过程中，我发现在医学图像领域解决问题的方法往往是自然场景图像解决方案的一种延伸。在我的构想中，如果针道在ct的图像中显示是一条直线，那么利用现有3d点云中检测直线的方法实现在ct中的利用是否可行，那么我就可以去除复杂的2d线性检测后的后处理过程，在空间直接找到针道，我认为该方案具有革命性的意义。&lt;/li&gt;
&lt;li&gt;二.那么问题来了，CT中的针道在图像上的显影可并不是一条直线，假如我使用了插值算法，那么伪影的存在，会使得这条针道的表现成为类似于一个片状的存在。为了解决这个问题，我决定一步步地解决这个伪影的问题，&lt;strong&gt;&lt;font color=red&gt;急功近利的利用解决的方案不是一个工程师应该做的事，寻求为什么，才是真正的意义所在，尤其是当我只是一个菜鸟的时候。&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;三.对于这篇论文而言，我会尽量结合一些事实做更多的阐述，可能会变得啰嗦，但是也是为了方便更多的和我一样的新手阅读。&lt;strong&gt;&lt;font color=red&gt;这是一篇2004年的论文&lt;/font&gt;&lt;/strong&gt;，但我认为就基础而言，这篇论文仍然有讨论的价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;        伪影会严重影响CT的质量，甚至有些时候会让诊断无法进行下去。为了优化图像质量，理解伪影为何会发生以及如何避免或者抑制就变得十分必要。CT伪影产生的原因有很多：
        1.基于物理原因的伪影是因为在CT图像在物理采集的过程中产生的；
        2.基于病例原因的伪影是病人因为移动或者病人体内的金属造成的；
        3.基于扫描器的伪影是扫描器的功能上的瑕疵导致的；
        4.螺旋状和多段式的伪影是在图像的重建过程中产生的；
        现代CT扫描仪中包含的设计功能可最大程度地减少某些伪影，并且某些部分可以通过扫描仪软件进行部分校正。然而，在许多情况下，避免CT伪影的最重要因素是精心安排患者位置和选择最佳扫描参数。（&lt;strong&gt;&lt;font color=green&gt;但实际情况下，很多扫描是不注重这些位置选择和参数设置的，至少在我所跟踪的临床手术中，选择参数这种情况很少发生，而医生对于软件的使用也是相当有局限性的，或者说，能不用的他们都不会用&lt;/font&gt;&lt;/strong&gt;）&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;        在CT中，“伪影”这个术语是用来形容重构图像的CT数值和物体的真实衰减系数之间的各项系统差异。CT相比传统的射线图像是一定更容易收到伪影的影响的，因为CT图像是上百万个相互独立的探测结果中的某种东西合并而成的。
        伪影产生的类型有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（a） 条纹状伪影：通常是单项测量不一致导致；&lt;/li&gt;
&lt;li&gt;（b） 阴影状伪影：由于一组通道或视图逐渐偏离真实度量；&lt;/li&gt;
&lt;li&gt;（c） 环状伪影：由于单个探测器的校准错误；&lt;/li&gt;
&lt;li&gt;（d）变形伪影：螺旋形重建导致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        伪影产生的原因有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（a） 物理原因：CT数据采集中的物理过程导致；&lt;/li&gt;
&lt;li&gt;（b） 病例原因：病人的移动或者体内的金属造成；&lt;/li&gt;
&lt;li&gt;（c） 扫描原因：扫面器的功能缺陷；&lt;/li&gt;
&lt;li&gt;（d）螺旋和多段伪影：图像重构过程中产生。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        这篇文章对于这几种伪影进行以下几点的阐述：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（a）阐述他们产生的机制；&lt;/li&gt;
&lt;li&gt;（b）阐述CT厂商们抑制他们的方法；&lt;/li&gt;
&lt;li&gt;（c）避免伪影的技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;物理伪影&#34;&gt;物理伪影&lt;/h2&gt;
&lt;h3 id=&#34;一beam-hardening线质硬化&#34;&gt;一、Beam Hardening（线质硬化）&lt;/h3&gt;
&lt;h4 id=&#34;i线质硬化的原理&#34;&gt;I.线质硬化的原理&lt;/h4&gt;
&lt;p&gt;        一束x光线是由带有一序列能量的光子组成的。随着这些光子穿过物体，光束会具备更大的穿透力或者说&amp;quot;harder&amp;quot;的现象，这是因为低能量光子会比高能量的光子更迅速的被吸收（如图1：x光线经过不同深度的水后的能量谱，能量随着水深而增加）。这样的情况会产生两种伪影：所谓的&lt;font color=Coral&gt;&lt;strong&gt;cupping伪影&lt;/strong&gt;&lt;/font&gt;和图像中&lt;font color=Coral&gt;&lt;strong&gt;密集对象之间的暗带或条纹&lt;/strong&gt;&lt;/font&gt;的出现。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109144519879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109144519879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;ii线质硬化的表现&#34;&gt;II.线质硬化的表现&lt;/h4&gt;
&lt;h5 id=&#34;font-colorcoral杯子伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;杯子伪影&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        当x射线经过一个规则圆柱体时，穿过圆柱的中间部分的能量要比穿过边缘部分的能量要大，因为它穿过了更多的物质。随着光束越来越硬，衰减的速率也越来越低，因此光束到达检测器时的强度比未硬化时要强。因此，最终的衰减曲线不同于在没有光束硬化的情况下获得的理想曲线（如图2：理想化的穿过圆柱体的衰减曲线和硬化后的光束穿过圆柱体的衰减曲线）


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109154611919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109154611919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        这就是穿过圆柱体后产生的CT的数值形成的类似于杯子的形状（图3：经过校准器修正和未修正之后的）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109155056526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109155056526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoral密集对象之间的暗带或条纹font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;密集对象之间的暗带或条纹&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        在非常异质的横截面中，图像中的两个密集对象之间可能会出现暗带或条纹。它们发生的原因是，当光束通过相邻两个物体中的一个物体时，它的硬度比通过两个物体时要小。这种伪影既可以出现在身体的骨区，也可以出现在造影剂的扫描中。图4的胸部CT就显示出，造影剂造成的条纹性伪影可能就会导致会被误认为是临近解剖结构性疾病。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109160240761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109160240761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;iii解决线质硬化的内置功能&#34;&gt;III.解决线质硬化的内置功能&lt;/h4&gt;
&lt;p&gt;        以下是厂商们解决伪影问题的方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;font color=Coral&gt;&lt;strong&gt;过滤器：&lt;/strong&gt;&lt;/font&gt;在x光线穿过人体之前，加上一块平整的衰减材料，通常是金属做的，这样可以事先过滤掉能量较低的部分。然后再另外加一块器件（领结过滤器）来增强那些穿过人体更薄的部分的边缘光束的能量。&lt;/li&gt;
&lt;li&gt;&lt;font color=Coral&gt;&lt;strong&gt;校准修正：&lt;/strong&gt;&lt;/font&gt;制造商使用各种尺寸的幻像对他们的扫描仪进行校准，针对患者不同部位的光束硬化效果定制各种特定的补偿，探测器上添加上这种补偿。由于临床的解剖学结构一定不会和一个理想的圆柱体一样，所以临床上尽管经过了这个校正的手段，但可能还是会有轻微的杯状伪影和帽状伪影，而过度校正会使得中心的CT值会升高。&lt;/li&gt;
&lt;li&gt;&lt;font color=Coral&gt;&lt;strong&gt;光束硬化修正软件：&lt;/strong&gt;&lt;/font&gt;当重建骨区域的图像时，可以应用迭代校正算法。这有助于最大程度地减少脑部扫描中骨骼-软组织界面的模糊（图5：经过骨头修正和没经过骨头修正的），并减少非均质横截面中暗带的出现（图6）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109174440565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109174440565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109174634835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109174634835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;iv避免线质硬化的操作方法&#34;&gt;IV.避免线质硬化的操作方法&lt;/h4&gt;
&lt;p&gt;        有时可以通过患者定位或倾斜机架来避免扫描骨区域。 重要的是选择合适的扫描视野，以确保扫描仪使用正确的校准和光束硬化校正数据，以及在某些系统上使用合适的领结过滤器。&lt;/p&gt;
&lt;h3 id=&#34;二partial-volume部分体积效应&#34;&gt;二、Partial Volume（部分体积效应）&lt;/h3&gt;
&lt;p&gt;        部分体积效应可通过多种方式导致图像伪影。 这些伪影是与部分体积平均分开的独立问题，部分体积平均产生的CT值代表体素内材料的平均衰减。（&lt;font color=green&gt;&lt;strong&gt;CT图像上各个像素的数值代表相应单位组织全体的平均CT值，它不能如实反映该单位内各种组织本身的CT值。&lt;/strong&gt;&lt;/font&gt;）
        一种产生的伪影类型是：当x射线的光束路径上，突然有一个凸起的稠密物体时，就会产生伪影现象。&lt;strong&gt;图7&lt;/strong&gt;展现了这种伪影产生的原因：这里对这个光线进行了一些夸张，方便看到结果。当光束从右往左时，因为绿色物体没有在光束内，所以右边的探测器接受不到这个物体的信息；但当光束从左往右时，绿色物体出现在光束范围内，所以探测器是“看得见”这个物体的。两个视图之间的不一致会导致阴影伪影出现在图像中，也就是&lt;strong&gt;图8a&lt;/strong&gt;.


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109182250492.png#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20201109182250492#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20201109182250492#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20201109182250492#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109182250492.png#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109182834364.png#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20201109182834364#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20201109182834364#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20201109182834364#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109182834364.png#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        &lt;font color=red&gt;&lt;strong&gt;避免这种伪影的最好的方法是使用一个薄片的&lt;code&gt;acquisition section width&lt;/code&gt;。&lt;/strong&gt;&lt;/font&gt;当人体结构在z轴方向上快速移动照射时这样做是非常有必要的。为了限制图片的噪声，用这些薄的&lt;code&gt;section&lt;/code&gt;来组成更厚的&lt;code&gt;section&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;三photon-starvation光子饥饿效应&#34;&gt;三、Photon Starvation（光子饥饿效应）&lt;/h3&gt;
&lt;h4 id=&#34;i-光子饥饿原理&#34;&gt;I. 光子饥饿原理&lt;/h4&gt;
&lt;p&gt;        一个潜在的产生纹状伪影的原因是光子饥饿效应，尤其是在肩膀这种高衰减区域，如图9：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109184535585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109184535585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        当x射线光束水平传播时，衰减最大，到达探测器的光子出现不足现象。结果是在这些传播通道的角度上会产生非常大的噪声投影。 重建过程会极大地放大噪声，从而导致图像中出现水平条纹。
        如果在扫描期间增加管电流，则将克服光子饥饿的问题，但是当光束穿过无衰减部分时，患者将受到不必要的剂量。 因此，制造商已经开发出使光子饥饿最小化的技术。&lt;/p&gt;
&lt;h4 id=&#34;ii-光子饥饿解决方案&#34;&gt;II. 光子饥饿解决方案&lt;/h4&gt;
&lt;h5 id=&#34;font-colorcoralautomatic-tube-current-modulation自动管电流调制font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;Automatic Tube Current Modulation（自动管电流调制）:&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        在某些扫描仪型号上，管电流在每次旋转过程中会自动改变，这是一个称为&lt;code&gt;毫安调制&lt;/code&gt;的过程，这使足够的光子可以穿过患者的最宽部分而不会对狭窄部分产生不必要的剂量（图10）


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109190243871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109190243871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoraladaptive-filtration自适应过滤font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;Adaptive Filtration（自适应过滤）:&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        一些制造商使用一种自适应过滤器来减少光子饥饿图像中的条纹。 该软件校正可在重建图像之前平滑高衰减区域中的衰减曲线（图11：投影数据可能出现在水平X射线束穿过肩部的情况下。 图以原始形式（a）和自适应过滤（b）显示数据。）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109190946768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109190946768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        目前正在开发一种多维自适应过滤技术，以用于多部分扫描仪。 对于超过选定衰减阈值的一小部分投影数据，在相邻的面内探测器之间（图12a）和连续的投影角度之间（图12b）进行平滑处理，&lt;font color=red&gt;&lt;strong&gt;而在螺旋重建中使用的z滤光片则扩大了宽幅范围， 衰减投影角，以允许更多的光子有助于重建（图12c）&lt;/strong&gt;&lt;/font&gt;。 图13展示了减少条纹的程度，同时通过技术（2）保持了空间分辨率。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109193422925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109193422925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/202011091937087.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/202011091937087.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;四undersampling欠采样&#34;&gt;四、Undersampling（欠采样）&lt;/h3&gt;
&lt;p&gt;        用于重建一个CT图像的投影数量是图像质量的决定因素之一。 投影之间的间隔（欠采样）过大会导致计算机对与锐利边缘和小物体有关的信息进行配准错误。 这导致了一种称为&lt;code&gt;视图混叠&lt;/code&gt;的效果，其中细小条纹似乎从密集结构的边缘放射而出（图14）。 出现在结构附近的条纹更有可能是由投影内的欠采样引起的，这被称为&lt;code&gt;射线混叠&lt;/code&gt;。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109194259618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109194259618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        混叠可能不会对图像的诊断质量造成太大的影响，因为均匀间隔的线通常不会模仿任何解剖结构。 但是，在精细细节的解析很重要的地方，欠采样需要尽量避免。 通过获取每个旋转可能的最大投影数量，可以最大程度地减少视图混淆。 在某些扫描仪上，这只能通过使用较低的旋转速度来实现，而在其他扫描仪上，投影的数量与旋转速度无关。 可以通过使用专业的高分辨率技术（例如，四分之一探测器移位或飞行焦点）来减少&lt;code&gt;射线混叠&lt;/code&gt;，制造商采用这种技术来增加投影内的样本数量。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;病例伪影&#34;&gt;病例伪影&lt;/h2&gt;
&lt;h3 id=&#34;一metallic-materials金属材料&#34;&gt;一、Metallic Materials（金属材料）&lt;/h3&gt;
&lt;h4 id=&#34;i金属伪影原因&#34;&gt;I.金属伪影原因&lt;/h4&gt;
&lt;p&gt;        扫描场中金属物体的存在会导致严重的条纹痕迹。 发生这些现象是因为金属的密度超出了计算机可以处理的正常范围，从而导致衰减曲线不完整。 当扫描非常稠密的物体时，由于光束硬化，部分体积和混叠而产生的其他伪像可能会使问题更加复杂。&lt;/p&gt;
&lt;h4 id=&#34;ii解决方案&#34;&gt;II.解决方案&lt;/h4&gt;
&lt;h5 id=&#34;font-colorcoral在操作上避免金属伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;在操作上避免金属伪影:&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        病人在检查前经常会被告知取下金属物质。对于不可移动的物品，例如牙科填充物，修复设备和手术夹子，有时可以使用龙门成角法将金属插件从附近的解剖结构扫描中排除。 当无法在不包括金属物体的情况下扫描所需的解剖结构时，不断增加的技术（特别是千伏电压）可能有助于穿透某些物体，并且使用薄截面将减少由于部分体积伪影而造成的影响。&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoral软件上修正伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;软件上修正伪影:&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        可以通过特殊的软件校正大大减少由超范围引起的条纹。制造商使用各种插值技术来替代衰减曲线中的超范围值。 一种这样的技术的有效性如图15所示。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109195633702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109195633702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;        金属伪影减少软件的有用性有时受到限制，因为尽管去除了与金属植入物相距较远的条纹，但金属组织界面周围的细节仍然被伪影影响，这里通常是诊断的主要领域。 扫描金属物体时也应使用线质硬化校正软件，以最大程度地减少由于线质硬化而产生的其他伪影。&lt;/p&gt;
&lt;h3 id=&#34;二patient-motion移动伪影&#34;&gt;二、Patient Motion（移动伪影）&lt;/h3&gt;
&lt;h4 id=&#34;i移动伪影原因&#34;&gt;I.移动伪影原因&lt;/h4&gt;
&lt;p&gt;        患者的运动可能会导致重合失调伪影，通常在重建图像中表现为阴影或条纹（图16）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109200204271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109200204271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;        可以采取一些步骤来阻止自发运动，但是在图15中，使用金属脊柱植入物，未经任何矫正（a）和减少金属伪影（b）重建的患者的CT图像扫描中可能是不可避免的。 但是，某些扫描仪具有特殊功能，旨在最大程度地减少由此产生的伪像。&lt;/p&gt;
&lt;h4 id=&#34;ii移动伪影解决方案&#34;&gt;II.移动伪影解决方案&lt;/h4&gt;
&lt;h5 id=&#34;font-colorcoral操作上避免移动伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;操作上避免移动伪影&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        使用定位辅助器足以防止大多数患者自愿活动。但是，在某些情况下（例如，儿科患者），可能需要通过镇静手段来固定患者。 尽可能短的扫描时间有助于在易于移动的区域进行扫描时最大程度地减少伪影。 如果患者能够在扫描期间屏住呼吸，则呼吸运动可以降到最低。
        图像对运动伪影的敏感性取决于运动的方向。 因此，优选的是，管的开始和结束位置与运动的主要方向对齐，例如，在进行胸部扫描的患者的垂直上方或下方。 与头扫描模式相反，指定身体扫描模式可以在重建过程中自动合并一些运动伪影减少功能。&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoral内置功能可最大程度地减少运动伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;内置功能可最大程度地减少运动伪影&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        制造商通过使用过扫描和欠扫描模式，软件校正和心脏门控来最大程度地减少运动伪影。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.&lt;strong&gt;过扫描和欠扫描模式&lt;/strong&gt;：检测器读数的最大差异发生在朝向360°扫描开始和结束的视图之间。 某些扫描仪型号使用过扫描模式进行轴向人体扫描，从而在标准360°旋转中增加了10％左右。 对重复的投影进行平均可以帮助降低运动伪影的严重性。 使用部分扫描模式还可以减少运动伪像，但这可能以分辨率较差为代价。&lt;/li&gt;
&lt;li&gt;2.&lt;strong&gt;软件校正&lt;/strong&gt;：大多数扫描仪在人体扫描模式下使用时，会自动在开始和结束视图上应用减少的权重，以抑制它们对最终图像的影响。但是，这可能会在最终图像的垂直方向上产生更多噪点 ，这取决于患者的形状。 在某些扫描仪上还可以使用其他专门的运动校正。（图17）展示了一种这样的技术在纠正由于流体界面运动而引起的伪影方面的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109201834942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109201834942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3.&lt;strong&gt;心脏门控&lt;/strong&gt;：：心脏的快速运动会导致心脏图像中出现严重的伪影，并导致伪影能够模仿相关结构（例如解剖的主动脉）中的疾病。 为了克服这些困难，已经开发了通过使用在心动过少时仅来自心动周期的一小部分的数据来产生图像的技术。 这是通过将心电门控技术与图像重建的专用方法相结合来实现的（4）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;三incomplete-projections不完整的投影&#34;&gt;三、Incomplete Projections（不完整的投影）&lt;/h3&gt;
&lt;p&gt;        如果患者的任何部分位于扫描视野之外，则计算机将具有与该部分有关的不完整信息，并且可能会产生条纹或阴影伪影。
        这在（图18）中进行了说明，该图显示了患者手臂朝下进行扫描而不是抬起来不妨碍扫描。 由于手臂不在扫描场中，因此它们不会出现在图像中，但是在扫描过程中它们在某些视图中的存在已导致整个图像出现如此严重的伪影，从而大大降低了其实用性。 密集物体（例如，位于扫描场外部的包含造影剂的静脉内试管）可能会产生类似的效果。 检测器阵列侧面的参考通道阻塞也可能会干扰数据归一化并导致条纹伪影。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201109202436124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201109202436124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        为了避免由于投影不完全而导致的伪影，必须将患者放置在适当的位置，以使任何部分都不会位于扫描区域之外。 专为放射治疗计划设计的扫描仪具有比标准扫描仪更大的孔径和更大的视野，并且在患者定位方面具有更大的通用性。 它们还允许对不适合标准扫描仪视野的超大型患者进行扫描。
        某些制造商会监控参考数据通道是否存在不一致之处，并避免使用看起来可疑的参考数据。 作为替代方案，可以将CT系统设计为在管侧配备参考检测器，或者在机架内部配备射线路径，以消除对参考数据的可能干扰。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;扫描仪伪影&#34;&gt;扫描仪伪影&lt;/h2&gt;
&lt;h3 id=&#34;一ring-artifacts环状伪影&#34;&gt;一、Ring Artifacts（环状伪影）&lt;/h3&gt;
&lt;h4 id=&#34;i环装伪影原因&#34;&gt;I.环装伪影原因&lt;/h4&gt;
&lt;p&gt;        如果有一个侦测器在第三代扫描器（旋转的x射线管和侦测部件）上的校准器之外，那么侦测在会在每一个角度上得到一个错误的读取，从而形成一个环状的伪影（图19）。具有固态检测器的扫描仪（其中所有检测器都是独立的实体）在原理上比带有气体检测器的扫描仪更容易产生环状伪影，在气体检测仪中，检测器阵列由单个氙气填充且由电极细分的腔室组成 。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110113242909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110113242909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        当宽床位使用的时候，在一个统一的体模或者空气中可以看见的环状伪影（图20）可能在临床上并不可见。即使它们是可见的，也很少会与疾病混淆。 但是，它们可能会损害图像的诊断质量，尤其是当中央探测器受到影响时，图像的中心会出现黑色污点，这尤其可能发生。

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/2020111011405935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/2020111011405935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;ii环状伪影解决方案&#34;&gt;II.环状伪影解决方案&lt;/h4&gt;
&lt;p&gt;        图像中存在圆形伪影表明检测器增益需要重新校准或可能需要维修服务。 选择正确的扫描视野可以通过使用更适合患者解剖结构的校准数据来减少伪影。所有现代扫描仪均使用固态检测器，但通过表征和校正检测器变化的软件可以减少其产生环状伪像的可能性。&lt;/p&gt;
&lt;h3 id=&#34;二helical-and-multisection-ct-artifacts螺旋多段状伪影&#34;&gt;二、Helical and Multisection CT Artifacts（螺旋、多段状伪影）&lt;/h3&gt;
&lt;h4 id=&#34;i轴向平面中的螺旋伪影单节扫描&#34;&gt;I.轴向平面中的螺旋伪影：单节扫描&lt;/h4&gt;
&lt;p&gt;        通常，在螺旋扫描中会看到与连续扫描相同的伪影。但是，由于螺旋插值和重建过程，在螺旋扫描中可能会出现其他伪影。 当解剖结构在z方向上快速变化时（例如，在头骨的顶部），就会出现伪影，并且对于较大的间距，伪影会更严重。
        如果对沿扫描仪z轴放置的圆锥形幻像执行螺旋扫描，则结果轴向图像应显示为圆形。实际上，由于螺旋插值算法中使用的加权函数，其形状会失真（图21） 。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110115322121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110115322121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;        对于某些投影角度，图像受扫描平面前面的圆锥体较宽部分的贡献影响更大； 对于其他投影角度，主要来自圆锥体较窄部分的扫描平面后面的贡献。 因此，伪影的取向根据在图像平面的中心处的放射管的位置而变化。 在临床图像中，例如（图22）中所示的一系列肝脏图像，螺旋伪影很容易被误解为疾病。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110115513962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110115513962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        为了使螺旋伪影降到最低，必须采取步骤以减少沿z轴变化的影响。 这意味着，如果可能的话，使用低间距，180°而不是360°的螺旋内插器，以及较薄的采集部分而不是较厚的采集部分。 有时，仍然优选使用轴向成像而不是螺旋成像以避免螺旋伪像（例如，在脑部扫描中）。&lt;/p&gt;
&lt;h4 id=&#34;ii多段扫描中的螺旋伪影&#34;&gt;II.多段扫描中的螺旋伪影&lt;/h4&gt;
&lt;p&gt;        螺旋内插过程导致多部分扫描仪上的轴向图像变形比单部分扫描仪上更为复杂。形成这种典型风车外观伪影（图23）的原因如下：在每次旋转过程中，几行检测器与重建平面相交。随着螺旋螺距的增加，与图像平面旋转相交的检测器行数增加，风车伪影中的“叶片”数也增加。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110140128927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110140128927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        多段扫描仪通常使用Z滤波器螺旋内插器来代替单段扫描器上通常使用的两点内插器。 z滤波器插值器的好处之一是，它们降低了风车伪影的严重性，尤其是当图像重构宽度大于检测器采集宽度时。通过使用相对于检测器采集宽度的非整数间距值（例如在某些扫描仪上的间距为3.5或4.5），也可以稍微减少伪影。这是因为针对非整数间距优化了z轴采样密度。&lt;/p&gt;
&lt;h4 id=&#34;iii锥束效应&#34;&gt;III.锥束效应&lt;/h4&gt;
&lt;p&gt;        随着每转获取的切片数量增加，需要更宽的准直度，并且X射线束变成锥形而不是扇形（图24）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110141011701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110141011701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        （图25）展示了沿z轴的x射线束和检测器的放大图。 当试管和检测器绕患者旋转时（在垂直于图的平面中），每个检测器收集的数据对应于两个锥体之间的体积，而不是理想的平面。 这会导致伪像类似于由离轴对象周围的部分体积引起的伪像。 与内部探测器行相比，外部探测器行的伪影更为明显（图26），其中所收集的数据更接近于一个平面。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110141128446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110141128446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;



&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110141148685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110141148685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        随着探测器行数的增加，锥束效应变得更糟。 因此，与四段扫描仪相比，16段扫描仪应更可能受到伪影的影响。 然而，制造商已经通过采用各种形式的锥形束重建代替了四截面扫描仪上使用的标准重建技术来解决该问题。 图27所示的幻像研究证明了一种这样的技术的有效性。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110141411200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110141411200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;iv多平面和三维重塑&#34;&gt;IV.多平面和三维重塑&lt;/h4&gt;
&lt;p&gt;        自从引入螺旋扫描以来，在多平面和三维重建中已取得了重大进步，并且在更大程度上实现了多部分扫描。 扫描所需体积的速度更快，这意味着大大降低了患者运动的影响，并且使用更窄的采集部分和重叠的重建部分可以使重新格式化图像的边缘清晰度更高。&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoral阶梯状伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;阶梯状伪影&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        当使用宽准直和不重叠的重构间隔时，阶梯伪影会出现在多平面和三维重新格式化图像中结构的边缘周围。 螺旋扫描对它们的影响较小，这允许重建重叠的部分，而不会给患者带来额外的剂量（如果获得重叠的轴向扫描，则不会产生额外的剂量）（图28）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110142150377.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110142150377.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

        从今天的多截面扫描仪获得的薄截面数据中，可以在多平面和三维格式的图像中消除阶梯状伪影（图29）。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110142227105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110142227105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h5 id=&#34;font-colorcoral斑马伪影font&#34;&gt;&lt;font color=Coral&gt;&lt;strong&gt;斑马伪影&lt;/strong&gt;&lt;/font&gt;&lt;/h5&gt;
&lt;p&gt;        由于螺旋插值过程沿z轴产生一定程度的噪声不均匀性，因此在螺旋数据的多平面和三维重新格式化图像中可能会出现模糊条纹。 这种“斑马”效应（图30）在远离旋转轴的地方变得更加明显，因为离轴的噪声不均匀性更差。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20201110142659242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20201110142659242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;        伪影来自多种来源，会在不同程度上降低CT图像的质量。 现代扫描仪中包含的设计功能可以最大程度地减少某些伪影，并且某些特征可以通过软件进行部分纠正。 但是，在许多情况下，仔细的患者定位和最佳的扫描参数选择是避免图像伪影的最重要因素。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: HRNet用于视觉识别的深度高分辨率表示学习</title>
      <link>https://Joevaen.github.io/showcase/paper/paper7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper7/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;HRNet用于视觉识别的深度高分辨率表示学习&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#低分辨率表示学习&#34;&gt;低分辨率表示学习&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#高分辨率表示恢复&#34;&gt;高分辨率表示恢复&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#高分辨率表示保持&#34;&gt;高分辨率表示保持&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#多尺度混合&#34;&gt;多尺度混合&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#我们的方法&#34;&gt;我们的方法&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#31-并行多分辨率卷积&#34;&gt;3.1 并行多分辨率卷积&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#32--重复的多分辨率融合&#34;&gt;3.2  重复的多分辨率融合&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.学习该算法的目的：在u2net上进行针道的尝试之后，发现分割的算法无法解决针道问题，能呈现一定的分割效果，但因为针在体内的位置不确定，性状、像素值也并不像之前设想的那么具有可识别度，故希望利用从feature map上回归点的特征点的方法解决这个棘手的问题；&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=blue&gt;蓝色表示对原来的理解做的一些修改或补充&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示本文的重要关键字&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=purple&gt;紫色表示后续更新的内容&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三.CVPR2019 的 HRNet 在我之前的工作中具有十分重要的作用，在长期的图像分割任务中，并没有太多时间思考这个模型及类似点回归模型在医学图像中的应用。从这篇博客开始，我将会持续探讨，此类点回归模型在医学图像中介入体识别中的作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;一摘要&#34;&gt;一、摘要&lt;/h1&gt;
&lt;p&gt;深度卷积网络在许多机器视觉领域已经取得了SOTA级别的效果，比如图像分类、目标检测、语义分割、人体姿态识别等等。原因就是与手工制作的特征相比，深度学习具有更强大的提取特征的能力。
最近的大多数分类网络，比如AlexNet、VGGNet、GoogleNet、ResNet等等，都遵从着LeNet-5的设计原则，这个原则就如 （&lt;strong&gt;图一&lt;/strong&gt;） 所描述的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(a) 从高分辨率到低分辨率逐渐减小特征图的尺寸，最终从低分辨率的特征图中得到分类的结果；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图一：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210412094000326.png&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20210412094000326&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20210412094000326&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20210412094000326&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210412094000326.png&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;高分辨率表达主要用于一些对位置敏感的任务，比如语义分割、人体姿态识别和目标检测。先前的SOTA方法主要采用的是高分辨率恢复的方法，将低分辨率图中的分类结果提升为高分辨率，如&lt;strong&gt;图一&lt;/strong&gt;的(b)中描述的，比如Hourglass、SegNet、DeconvNet、U-Net、SimpleBaseline和编解码模式。另外，膨胀卷积用于移除一些下采样层，从而产生一些中级像素的特征图。
我们提出了一个新的网络结构，名为 High-ResolutionNet (&lt;strong&gt;HRNet&lt;/strong&gt;)，能够在整个过程中保持高分辨率的特征图。我们从一个高分辨率的卷积流程开始，一个个地把由高到低的卷积流加入进去，然后平行连接多个流。最终的网络包含了几个（论文中是4个）&lt;strong&gt;图二&lt;/strong&gt;所表示出的stage，第n个stage包含了对应与n像素级的n个流。我们通过在并行流之间交换信息来进行重复的多分辨率融合。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图二：&lt;/strong&gt;


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210412113232752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210412113232752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HRNet的高分辨率表达不仅仅在语义上具有很好的性能，在空间上也具备一定的精准度。这主要来自两个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(i) 我们的方法不仅包含了从低像素恢复的高分辨率信息，也包含了原始的高分辨率信息，因此，这样学习到的信息会使得空间上的判别更精确；&lt;/li&gt;
&lt;li&gt;(ii) 当前大多数的融合方案，聚合了通过对低分辨率信息进行上采样获得的高分辨率和低分辨率，从而实现低级和高级表示。 相反，我们在低分辨率表示的帮助下重复多分辨率融合以增强高分辨率表示，反之亦然。 结果，我们的方法在语义上是强大的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们提出了两个HRNet版本，&lt;strong&gt;HRNetV1&lt;/strong&gt;只输出从高分辨率卷积流中计算出的高分辨率表达，然后将其应用到姿态评估的heatmap框架。我们以经验的方式展示了COCO关键点检测数据集上优越的姿态估计性能。
&lt;strong&gt;HRNetV2&lt;/strong&gt;则将所有高到低像素流的表达进行了合并。通过从组合的高分辨率表示估计分割图，将其应用于语义分割。所提出的方法在PASCAL-Context、Cityscapes和LIP实现了SOTA结果，同时它的模型尺寸与之前的SOTA的模型尺寸差不多同时具有更低的计算复杂度。我们发现V2和V1在COCO数据集上的表现基本相同，同时发现了V2在语义分割上的先进性。
此外，我们从&lt;strong&gt;HRNetV2&lt;/strong&gt;的高分辨率输出构建了一个多层表示，称为&lt;strong&gt;HRNetV2p&lt;/strong&gt;，并将其应用于最新的检测框架，包括Faster R-CNN，Cascade R-CNN，FCOS和CenterNet，以及最新的联合检测和实例分割框架，包括Mask R-CNN，Cascade Mask R-CNN和Hybrid Task Cascade。结果表明，我们的方法改进了检测性能，特别是对小物体的动态改进。&lt;/p&gt;
&lt;h1 id=&#34;二相关工作&#34;&gt;二、相关工作&lt;/h1&gt;
&lt;p&gt;我们从三个方面回顾了主要用于人体姿势估计，语义分割和对象检测的紧密相关的表示学习技术：低分辨率表示学习，高分辨率表示恢复和高分辨率表示保持。 此外，我们还提到了与多尺度融合相关的一些作品。&lt;/p&gt;
&lt;h2 id=&#34;低分辨率表示学习&#34;&gt;低分辨率表示学习&lt;/h2&gt;
&lt;p&gt;全卷积网络方法，通过删除分类网络中的全连接层来计算低分辨率表示，并估计其粗略分割图。 通过组合从中间低级别中分辨率表示估计的精细分割得分图或对过程进行迭代，可以改善估计的分割图。 类似的技术也已应用于边缘检测，例如整体边缘检测。
&lt;strong&gt;&lt;font color=red&gt;The  fully  convolutional  network  is  extended,  by  re-placing  a  few  (typically  two)  strided  convolutions  and the  associated  convolutions  with  dilated  convolutions,  tothe  dilation  version,  leading  to  medium-resolution  repre-sentations&lt;/font&gt;&lt;/strong&gt;。通过特征金字塔进一步扩展为多尺度上下文表示，用于在多个尺度上分割对象。&lt;/p&gt;
&lt;h2 id=&#34;高分辨率表示恢复&#34;&gt;高分辨率表示恢复&lt;/h2&gt;
&lt;p&gt;上采样的操作主要用于逐渐把低分辨率的表示恢复成高分辨率信息，可以看做是下采样的对称版本（比如VGGNet），通过一些跳级链接来对池化层进行一些变换（比如SegNet和DeconvNet），或者复制特征图（比如UNet、Hourglass、编解码）。一种UNet的扩展——全像素残差网络，介绍了一种额外的全像素流，这种流通过在全图上拾取信息，代替了之前的跳级链接，下采样和上采样的每一个子网络单元都从全像素流上收到和发出信息。
这种非对称的上采样过程也被广泛研究，RefineNet改善了上采样信息表达和相同像素级别上、由下采样复制而来的信息表达。其他的工作包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.在backbone中使用可能带有扩张卷积的轻量级上采样方法；&lt;/li&gt;
&lt;li&gt;2.轻量级下采样和重量级上采样组成的复合网络；&lt;/li&gt;
&lt;li&gt;3.利用更多或者更复杂的卷积单元改进跳级链接，通过低像素的跳级链接向高像素的跳级链接发送信息或者交换这两者的信息；&lt;/li&gt;
&lt;li&gt;4.研究上采样过程的细节；&lt;/li&gt;
&lt;li&gt;5.组合多尺度金字塔的表达；&lt;/li&gt;
&lt;li&gt;6.用密集链接来堆叠多个DeconvNets/UNet/Hourglass。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;高分辨率表示保持&#34;&gt;高分辨率表示保持&lt;/h2&gt;
&lt;p&gt;我们的工作与之前的一些注重高像素表达的工作密切相关。比如 convolutional neural fabrics、interlinked  CNNs、GridNet和多尺度DenseNet。
convolutional neural fabrics和interlinked  CNNs这两个早期的工作缺乏对何时启动低分辨率并行流以及如何和在何处交换并行流信息的精心设计，并且不使用批量归一化和残差连接，因此表现并不令人满意。GridNet就像是多个U-Net的组合，包括两个对称信息交换阶段：第一阶段仅将信息从高分辨率传递给低分辨率，第二阶段仅将信息从低分辨率传递给高分辨率。 这限制了其分割质量。 多尺度DenseNet无法学习强大的高分辨率表示，因为没有从低分辨率表示中接收到任何信息。&lt;/p&gt;
&lt;h2 id=&#34;多尺度混合&#34;&gt;多尺度混合&lt;/h2&gt;
&lt;p&gt;多尺度混合被广泛的研究。比较直接的一种方式是把不同像素级别的图像丢入多个网络，同时聚合输出图像的信息。Hourglass、UNet和SegNet通过跳级链接混合了下采样和上采样过程中同一像素水平的特征信息。PSPNet和DeepLabV2混合了金字塔池化模式和atrous空间池化的信息。我们的多尺度池化模式包含了以上两种模式。但是不同在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1) 我们的混合输出是四个像素表达而不只是一个；&lt;/li&gt;
&lt;li&gt;(2) 我们的混合模式被深度混合激励同时重复多次。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;我们的方法&#34;&gt;我们的方法&lt;/h2&gt;
&lt;p&gt;我们的网络并行链接高像素到低像素的卷积流。它包括整个过程中的高像素表示和通过从多个像素级别中混合的对位置信息及其敏感的可靠的高像素表示。
这篇论文对我们之前的论文进行了充分的扩展和补充，我们另外添加了一些未发表文章的材料，以及应用到目标检测和实例分割框架中的结果。
与之前相比，技术的新颖之处在一下三个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1) 与之前的HRNetV1相比，我们提出了HRNetV2和HRNetV2p，探索了四个像素级别的表示；&lt;/li&gt;
&lt;li&gt;(2) 在多像素级别混合和通常的卷积之间创建了联系，这为探索HRNetV2和HRNetV2p在四个像素级别上的表示提供了支持；&lt;/li&gt;
&lt;li&gt;(3) 我们显示了HRNetV2和HRNetV2p相对于HRNetV1的优越性，并介绍了HRNetV2和HRNetV2p在广泛的视觉问题中的应用，包括语义分割和目标检测。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;三hrnet&#34;&gt;三、HRNet&lt;/h1&gt;
&lt;p&gt;我们将图像输入到一个枝干中，该枝干由两个步幅为2的3×3卷积组成，将分辨率降低到1/4，然后以相同的分辨率输出表示的主体（1/4）。主体如 &lt;strong&gt;图二&lt;/strong&gt; 所示，下面进行了详细说明，它由几个组件组成：并行多分辨率卷积，重复的多分辨率融合和如 &lt;strong&gt;图四&lt;/strong&gt; 所示的表示头。&lt;/p&gt;
&lt;h2 id=&#34;31-并行多分辨率卷积&#34;&gt;3.1 并行多分辨率卷积&lt;/h2&gt;
&lt;p&gt;我们从高分辨率卷积流作为第一步开始，逐步将高至低分辨率流逐个添加，形成新的阶段，然后并行连接多分辨率流。 结果，下一级并行流的分辨率包括前一级的分辨率，以及下一级的分辨率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图二&lt;/strong&gt;

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210412163023281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210412163023281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;图二&lt;/strong&gt; 中展示了这个阶段的示意图，包含了四个并行流，逻辑如下图所示：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210412163100650.png&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;20210412163100650&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-20210412163100650&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-20210412163100650&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210412163100650.png&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

$N_{sr}$表示一个子流，$s$表示第$s$个stage，$r$表示属于的像素级别索引。第一个流的像素级别索引是$r$ = 1，第$r$个的分辨率是第一个流的分辨率的$\frac{1}{2^{r-1}}$。&lt;/p&gt;
&lt;h2 id=&#34;32--重复的多分辨率融合&#34;&gt;3.2  重复的多分辨率融合&lt;/h2&gt;
&lt;p&gt;这个混合模块的目的是交换多种分辨率表示的信息，它重复很多次（比如每四个残差单元重复一次）。
让我们看下&lt;strong&gt;图三&lt;/strong&gt;中这个混合三个像素级别的例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图三&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20210412164537490.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20210412164537490.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Showcase: 对多个单分类数据集中训练，实现单个多分类的分割</title>
      <link>https://Joevaen.github.io/showcase/paper/paper8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Joevaen.github.io/showcase/paper/paper8/</guid>
      <description>
        
        
        










&lt;section id=&#34;td-cover-block-0&#34; class=&#34;row td-cover-block td-cover-block--height-sm js-td-cover td-overlay td-overlay--dark -bg-primary&#34;&gt;
  &lt;div class=&#34;container td-overlay__inner&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;col-12&#34;&gt;
        &lt;div class=&#34;text-center&#34;&gt;
          
          
          &lt;div class=&#34;pt-3 lead&#34;&gt;
            
                &lt;div class=&#34;text-left&#34;&gt;
  &lt;h1 class=&#34;display-1 mb-5&#34;&gt;对多个单分类数据集中训练，实现单个多分类的分割&lt;/h1&gt;&lt;/div&gt;

            
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
&lt;/section&gt;

&lt;div class=&#34;container l-container--padded&#34;&gt;
&lt;div class=&#34;row&#34;&gt;




  
    &lt;div class=&#34;d-lg-none col-12&#34;&gt;
      &lt;div class=&#34;td-toc td-toc--inline&#34;&gt;
  
      
        &lt;a id=&#34;td-content__toc-link&#34; class=&#34;collapsed&#34; href=&#34;#td-content__toc&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-page-toc&#34; aria-expanded=&#34;false&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
          &lt;span class=&#34;lead&#34;&gt;Contents&lt;i class=&#34;fas fa-chevron-right ml-2&#34;&gt;&lt;/i&gt;&lt;/span&gt;
        &lt;/a&gt;
        &lt;div id=&#34;td-content__toc&#34; class=&#34;collapse&#34;&gt;
          &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1介绍&#34;&gt;1.介绍&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2相关工作&#34;&gt;2.相关工作&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3方法&#34;&gt;3.方法&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#假设条件&#34;&gt;假设条件：&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#目标&#34;&gt;目标：&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#原理图&#34;&gt;原理图：&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#31-基础模型&#34;&gt;3.1 基础模型&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-conditioning条件限制&#34;&gt;3.2 Conditioning（条件限制）&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-应用与问题&#34;&gt;3.3 应用与问题&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-实验&#34;&gt;4. 实验&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-font-colorredablation-experimentsfont&#34;&gt;4.1 &lt;strong&gt;&lt;font color=red&gt;Ablation experiments&lt;/font&gt;&lt;/strong&gt;&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#411-主要内容&#34;&gt;4.1.1 主要内容&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#412-不同类别之间空间连接信息的重要性&#34;&gt;4.1.2 不同类别之间空间连接信息的重要性&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#413-自然图像的适用性&#34;&gt;4.1.3 自然图像的适用性&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-讨论&#34;&gt;5 讨论&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
        &lt;button id=&#34;td-content__toc-link-expanded&#34; href=&#34;#td-content__toc&#34; class=&#34;btn btn-small ml-1 my-2 py-0 px-3&#34; data-toggle=&#34;collapse&#34; aria-controls=&#34;td-docs-toc&#34; aria-expanded=&#34;true&#34; aria-label=&#34;Toggle toc navigation&#34;&gt;
        &lt;/button&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;

&lt;/div&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;div class=&#34;col-12 col-lg-8&#34;&gt;
&lt;h1 id=&#34;讲在前面&#34;&gt;讲在前面&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;一.论文地址在&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/Dmitriev_Learning_Multi-Class_Segmentations_From_Single-Class_Datasets_CVPR_2019_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;i class=&#34;fas fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一.&lt;strong&gt;&lt;font color=red&gt;首先要非常感谢张同学提供的这么一篇论文以及相当重要的理解，为了进一步的理解和学习这篇论文，我决定对其进行深层的挖掘：&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;二.我设计了几种字体颜色用于更加醒目地表现关键的思想和主题：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=red&gt;红色表示本文的重要关键信息&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=green&gt;绿色表示此处需要参考的论文其他部分&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=orange&gt;橙色表示尚未理解透彻的一些概念&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;del&gt;我会用删除线将自己曾经不到位的理解进行删除&lt;/del&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;三.&lt;strong&gt;&lt;font color=red&gt;一些关键信息总结&lt;/font&gt;&lt;/strong&gt;（对于理解整篇论文都相当有必要，按照文中意思进行的理解）：&lt;/li&gt;
&lt;li&gt;四.&lt;strong&gt;&lt;font color=red&gt;目的&lt;/font&gt;&lt;/strong&gt;：我现在面临模型线性推理的耗时问题，因为一个器官对应一个模型，我想进行多器官分割的时候就会面对时间成本提高的问题，同时我的不同器官的标签暂时还存在于不同的数据源上，且以现在的能力和资源无法解决&lt;font color=red&gt;&lt;strong&gt;将多个单器官模型融合为一个多器官模型从而实现多分类&lt;/strong&gt;&lt;/font&gt;的问题。只能从训练的起点来寻找解决问题的方案。&lt;/li&gt;
&lt;li&gt;五.&lt;font color=red&gt;&lt;strong&gt;意义&lt;/strong&gt;&lt;/font&gt;：
&lt;ul&gt;
&lt;li&gt;1.腹部多器官分割模型性能的提升；&lt;/li&gt;
&lt;li&gt;2.解决某器官的数据集标注耗时问题（胰腺）；&lt;/li&gt;
&lt;li&gt;3.对GAN在医学领域的使用进行一个初步的探索。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;六.&lt;font color=red&gt;&lt;strong&gt;思考&lt;/strong&gt;&lt;/font&gt;：
&lt;ul&gt;
&lt;li&gt;创建一个与某层输入形状大小完全一致的张量会使得张量形状变得更大，会不会降低推理的速度，这个有点要不得哦，如果真是如此，那么这个算法最大的意义在于能够减少算力，在最短时间内出尽量好的效果，但对于一个本就有着长远打算且又具备较为可靠的研发基础的开发项目来说，似乎并没有太大的意义；&lt;/li&gt;
&lt;li&gt;现在只能通过在推理之前传入带有对应值的张量（因为每个器官的标签都置为1），以推理对应的器官，既然模型参数包含了三个信息，如何实现一次全推理；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;        在自然图像与视频领域，多类别分割最近越来越具备重大意义，这样的成就主要依赖于庞大的多分类的公共数据集。但是，类似于医学图像这种比较特殊的领域，想要制作巨大带有标签的医学数据是十分损耗人力的，甚至有时相当难以实现，但是这些领域有很多的但标签数据集可供使用。由于现在的研究都普遍关注单分类的实现，我们提出一个统一的高性能框架，这个框架可以通过把多个单标签的数据集当做一整个大的数据集，从而实现对单分类中各个器官的多分类。我们论证了多种合并条件信息的方式，并进行广泛的评估，最终这个框架在医学图像的分割任务上展现出了相当惊人的表现——比当前最好的解决方案还要高出2.7%。与当前很多单分类分割的解决方案不同的是，单分类分割十分精细的去使用单个标签的数据集，而我们应用的来自于多个数据源。而且经过验证，我们的框架在自然图像上仍然有效，同时我们将进一步评估该框架的其他可能性。&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容&lt;/h1&gt;
&lt;h2 id=&#34;1介绍&#34;&gt;1.介绍&lt;/h2&gt;
&lt;p&gt;        公共数据的不断庞大催生了自然图像分割的进步，而医学分割图像的数据集来源是十分稀缺的。尤其在临床研究领域，医学图像的分割相当的重要。在传统的临床实践中，诊断阶段的分割经常被忽略。但是人为的分析或者衡量医学图像，却会具有很大的不确定性，这可以取决于很多元素，比如组织的结构、图像的质量和临床医生的经验。同时，在各种各样的医学系统中，包括CAD、外科手术和诊疗计划等，分割又是不可或缺的元素。再者，早期癌症的诊断也经常需要图像分割的帮助。
        MRI和CT的图像分割已经取得了长足的进步，这些图像展现出各种各样的对象，比如一张图像中展现出一整个腹部，里面包含有很多的器官和组织。但是，为这套CT建立一个专业的标签是一个耗时费力的工作，因此多标签的数据标签就会很难生成。现在很多算法针对多类别的分类任务都已经得到了评估，而这些算法依赖于一些公共数据集，但公共的有些数据集因为资金短缺而无法继续使用。其他的就是私人的数据集，但这些多标签数据集往往都有数目限制，而且可能各自来自于不同的组织，这些数据集的产生应用了同样的图像方案或者图像策略，那么运用这些数据集的这些算法，由于是在相同的数据集上进行应用的，就会对这些数据的参数十分敏感。另一方面，制作单标签数据集更快速简单，而且经常很多是竞赛数据，而且这些数据因为来源不同所以会展现出不同的性质，比如癌病种的不同、图像方案的不同、重构算法的不同。
        然而，如果简单的将多个单标签的数据集组合在一起训练的话，网络会因为数据集中的正样本或者负样本进行不统一的学习（比如数据集A的标签中带有背景0和organ1，数据集B的标签中带有背景0和organ2，数据集C中的标签中带有背景0和organ3，那么1\2\3在有些数据中是正样本，但在有些数据中却是负样本）。在传统的算法中，单分类数据集是被高度定制用于进行单目标分割的。我们在这篇论文中设计的是一种可以让这些不同源的数据集不进行重叠地卷积网络。我们的算法允许模型隐秘的保留所有类别的模型参数，这使得模型同时能够学习到这些不同布标之间的空间关系从而提升其泛化能力。
        据我们所知，我们这项工作是第一次通过给卷积网络加上条件约束来实现在多个不同的单标签数据源上，不重叠的进行多分类模型的训练。我们工作的贡献有以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（1）通过给语义分割的卷积网络添加条件约束，来实现目的；&lt;/li&gt;
&lt;li&gt;（2）这个框架现在可以使得在多个单标签数据源上训练的多个模型成为一个多分类分割的模型，与单标签模型训练相比，大幅地减少了训练的复杂度和需要训练的总参数；&lt;/li&gt;
&lt;li&gt;（3）在显著减少计算损耗的基础上，提升了肝脏、脾脏、胰腺公共数据集上分割的SOTA指标（2.7%）。
        而且，我们评估了它在自然场景中的有效性，同时我们会在未来验证它的更多可能性。
        &lt;strong&gt;图一&lt;/strong&gt;：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825071615464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825071615464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

                                                                                        &lt;strong&gt;（图一）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2相关工作&#34;&gt;2.相关工作&lt;/h2&gt;
&lt;p&gt;        收集大批而且精确的标签具有相当大的难度，现在也有很多算法是通过弱标签的方式来实现和我们同样的目的。现在的弱监督学习是基于图像标签、点、边界框的，但是他们的中心思想基本一直，我们的方法却与其有很大的不同。他们仍然认为如果一组预定义的目标类存在于图像中，则每个对象的注释都可用。 对于CT图像，每个切片都需要为切片上存在的每个目标器官（无论是种子，边界框还是标签）设置一组注释。 但是，单类数据集没有附带此类注释，仅提供了一个特定类的详细信息。
        解剖结构分割，尤其是腹部器官的分割被认为是一个难题，因为这些器官在尺寸、位置和形状上都展现了高度的可变性。当前有很多卷积网络都可以进行不错的腹部多器官分割，这些方法很多都是针对特定器官的分割，而且这些算法往往都是通过多阶段实现。通常都是每个单器官模型各自推理完之后，再最终融合在一起得到最后的分割结果。但是，如果你想要都达到SOTA级别的表现，那这每个模型都必须要独立推理，可见对于算力和时间是相当大的消耗。而且，这些模型的训练是无视这些不同器官的空间联系信息的，这就使得单一模型的显示会出现过度的拟合。另外，这些模型往往都要求很多的前后处理，这让整个推理更加复杂而且特定化。
        现在也有一些研究是在研究腹部多器官分割的，其中大多数利用概率图谱和统计形状模型。这些方法要求所有的训练Volume都必须是配准好的。这些方法的前处理会耗费昂贵的算力，而且，因为不同病人的腹部器官的位置、尺寸、形状等都会不同，有些甚至差距很大。最近，一些基于卷积的同时多分类分割方法逐渐出现，但是这些方法都是在不公开的数据集上进行评估和使用的，而且，所使用的多类数据集是由单个机构获取的，表现出相同的图像质量并且没有慢性异常。与此不同的是，我们对这些数据集进行平衡，然后提出一种特别的方法，这种方法给卷积网络施加条件限制（Conditioning），从而生成一种具备高度概括能力的多类别分割模型。
        Conditioning这种方法在图像合成领域已经被广泛使用，在特定的属性（例如类别和标签）限制的下的图像生成已经有很多的研究成果。Ma等人提出了一个基于任意姿势的人体图像生成框架；Zhu等人对图-&amp;gt;图翻译的潜在结果的分布进行了建模；Reed等人设计了给定想要的图像内容和图像中的位置从而生成图像的方法。但是，医学领域内条件卷积网络的使用还没有开发，并没有人进行这方面的探索。我们在这里提出这种方法并讨论其可能的应用方向。&lt;/p&gt;
&lt;h2 id=&#34;3方法&#34;&gt;3.方法&lt;/h2&gt;
&lt;p&gt;        接下来进行方法的阐述，下面的假设拓宽了初始化的条件，同时使得问题的描述更加通用和具有挑战性：&lt;/p&gt;
&lt;h3 id=&#34;假设条件&#34;&gt;假设条件：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1.现在我们有D1、D2、D3、D4四个来源不同的数据集，代表四个器官，每个里面含有多个训练对（一个case及一个对应的label是一对）；&lt;/li&gt;
&lt;li&gt;2.四个数据集两两互斥（任意两个数据集中没有同一个一模一样的训练对）；&lt;/li&gt;
&lt;li&gt;3.不同数据集中所包含的类别标签可以是多个也可以是单个。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;目标&#34;&gt;目标：&lt;/h3&gt;
&lt;p&gt;        输入一个case，实现多个标签的预测分割。&lt;/p&gt;
&lt;h3 id=&#34;原理图&#34;&gt;原理图：&lt;/h3&gt;
&lt;p&gt;

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200824190545822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;1&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200824190545822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;1&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

                                                                                        &lt;strong&gt;（图二）&lt;/strong&gt;
        上图是一个训练过程中的 Conditioning 原理图：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;总共的数据集有 $k$ 个不同的源，即有 $k$ 种数据集，Conditioning 可以单独在编码器上进行，或者单独在解码器上进行，或者编解码上同时进行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;31-基础模型&#34;&gt;3.1 基础模型&lt;/h3&gt;
&lt;p&gt;        基础网络模型是一个添加了skip-connection的3DUNet网络，同时使用了dense块来提升网络的信息收集能力，具体来说，我们加入了一个与dense有关的复合函数$F_l$：
$$
x_l = F_l([x_0, x_1, x_2, &amp;hellip; , x_{l-1}])
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（1）$x_l$是第$l$层的输出，表示第$l$层的输出是由前面几层的输出决定的；&lt;/li&gt;
&lt;li&gt;（2）$[]$是对前面几层进行的concate操作；&lt;/li&gt;
&lt;li&gt;（3）该实验中的$F_l$被定义为$α = 0.3$的LRelu，且卷积核大小为$3 × 3 × 3$；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        该模型的编码器部分包括一个卷积层，然后是六个dense块，依次通过$2×2×2$ 的maxpooling层连接。每个dense块中特征通道的数量与其深度成正比。而上采样则用了转置卷积，与下采样结构对称，最后的输出层为sigmoid。附录上有具体的细节。&lt;/p&gt;
&lt;h3 id=&#34;32-conditioning条件限制&#34;&gt;3.2 Conditioning（条件限制）&lt;/h3&gt;
&lt;p&gt;        不像传统的图像分割算法进行单个器官的分割，我们的方法可以学习不同数据集标签之间的联系，并且只利用一个模型来实现$c_m$个类别分割。为了给模型注入这种能力，我们利用一个需要分割的标签类别$c_m$来Conditioning卷积网络。这种方式已经在GAN中得到广泛的使用，就我们所知，至今为止还没有人在医学分割领域进行这项工作。
        我们的目标是保持网络结构最基本的简单有效的样子，从而避免一些不必要的开销和负面影响。为了实现这个目标，我们决定将这个条件信息作为一个一个网络块，添加到卷积块之后和非线性层（激活层）之前。因为有些Conditioned GAN建议让网络自己学习这个条件信息，所以我们为这个分割任务设计了一个可计算且有效的方法。我们尤其建议使用下面这个函数：
$$
φ(c_m,  H_j, W_j, D_j) =  \textit{\textbf{O}}^{H_j ×W_j×D_j} \odot hash(c_m)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（1）$\odot$是矩阵对应元素相乘，即点乘；&lt;/li&gt;
&lt;li&gt;（2）$\textit{\textbf{O}}^{H_j ×W_j×D_j}$是一个元素值全为 &lt;strong&gt;1&lt;/strong&gt; 的且尺寸为 $H_j ×W_j×D_j$的张量；&lt;/li&gt;
&lt;li&gt;（3）$hash（·）$是预定义查找表的哈希函数。&lt;/li&gt;
&lt;li&gt;也就是说，$φ(c_m,  H_j, W_j, D_j)$ 创建了一个尺寸为${H_j ×W_j×D_j}$的张量，并且这个张量
所有的值都是$hash(c_m)$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;        因此，对第 $l^{th}$ 层形状为 ${H_j ×W_j×D_j}$ 的输入 $x_l$ 进行 Conditioning 的操作就被定义为：
$$
x_l = [x_{l-1}, φ(c_m,  H_j, W_j, D_j)]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x_{l-1}$ 是上一层的输出；&lt;/li&gt;
&lt;li&gt;非常要注意的是，所提出的 Conditioning 并不取决于类的可能属性，例如位置，形状等。这样做是为了提高所提出框架的通用性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-应用与问题&#34;&gt;3.3 应用与问题&lt;/h3&gt;
&lt;p&gt;        在训练阶段，网络会从不同的数据集中进行随机选择进行训练，同时根据输入的数据集类别 $c_m$ 来进行约束。
        在推理阶段，网络会依次根据限制条件 $c_m$ 来为输入的case进行分割。
        使用预定义查找表的这种方法保持了框架的简单性和紧缩性，而无需训练其他变量，但是它也具有一些实际的好处。 特别是，在添加新的目标细分类$c_{m+1}$的情况下，该框架将只需要向查找表添加一个新条目并进行简单的微调，这与如果我们学习了条件函数所需要的更昂贵的重新训练成本不同。
        但是，就会很自然的出现下一个问题：给定一个深度卷积网络，究竟在哪里进行Conditioning是最好的呢？哪一层的Conditioning是最有效果的呢？我们假设这个网络结构的形状类似于UNet，那么编码器进行Conditioning应该是可以提高效果的，因为下采样的时候不断再收集细节信息，如果在这些特征图上使用Conditioning来添加条件限制，那么机会把这两种信息对解码器进行很好的映射。而且，我们希望通过直接获取每层的Conditioning以使得优化变得更简单。在Section4.1我们测试了自己的假设并且报告了各种Conditioning设置的表现。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-实验&#34;&gt;4. 实验&lt;/h2&gt;
&lt;p&gt;        在这一部分中，我们对框架进行了拓展的分析，同时应用不同的损失函数和Conditioning方法进行了实验，并将结果与专门进行单标签分类和多标签分类的一些方法结果进行对比。结果表明，我们的条件化框架优于生物医学图像的当前最先进的单分类方法。 此外，我们证明了该方法在城市场景分割中的适用性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;① &lt;strong&gt;数据集&lt;/strong&gt;：为了评估框架并测试我们的假设，我们使用三个不同的腹部数据集（CT），20个肝数据（Sliver07）、82个胰腺（NIH）和74个肝脏和脾脏（自己的）。因此，在我们的实验中，$c_m \in{C}={{}肝脏、胰腺、脾脏}$。最后这个包含两个标签的数据的每类标签被单独进行了保存。图一和图六中是这些器官表现直观看起来的样子。接下来用一个传统的策略，每一种数据集按照4:1的比例随机分为训练集和测试集。每种数据集中Volume的形状是$512×512×Z_0$，$Z_0$是层数。每个数据集都是在不同的机构使用不同的扫描仪和协议收集的，所以这些spacing都是多样的，此外还展示了多种病理学，例如肝肿瘤和脾肿瘤。 数据集中的这种多样性使我们能够在充满挑战的环境中测试提出的方法。
        我们尽可能少的对这些数据进行预处理：每一种数据集按照同样的可能性去采样，&lt;strong&gt;&lt;font color=orange&gt;同时提取大小为256×256×32的子卷并将其标准化以创建输入图像&lt;/font&gt;&lt;/strong&gt;。所有的训练集都经过了一些小的增强，比如旋转、放大和平移。&lt;/li&gt;
&lt;li&gt;② &lt;strong&gt;训练&lt;/strong&gt;：该框架是在所有单分类数据集上进行训练的，依据下面的损失函数进行的优化：
&lt;ul&gt;
&lt;li&gt;$\mathcal L(\textbf{Y}，\hat\textbf{Y})=\alpha_1\beta_1\mathcal L_1(\textbf{Y}^{c_1}，\hat{\textbf{Y}^{c_1}})+&amp;hellip;+\alpha_n\beta_k\mathcal L_k(\textbf{Y}^{c_m}，\hat{\textbf{Y}^{c_m}})$        （4）&lt;/li&gt;
&lt;li&gt;（1）$\mathcal L_i(\textbf{Y}^{c_i}，\hat{\textbf{Y}^{c_i}})$是对于数据集$\mathcal D_i$来说单类别分割的损失函数；&lt;/li&gt;
&lt;li&gt;（2）$\alpha_i$用来指定每个类别$c_i$的损失对总损失的影响程度；&lt;/li&gt;
&lt;li&gt;（3）$\beta_i$的值为0或者1，如果为0，则说明$c_i$这个类别在将训练batch中没有；如果是1，则说明$c_i$这个类别在将训练batch中有。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;③ &lt;strong&gt;推理&lt;/strong&gt;：在推理的时候，可以手动的指定你想要的类别$c_i$，但是，为了简化推理期间框架的使用，我们建议通过迭代遍历查找表的方式，对所有case自动化指定目标类别。另外，对于腹部器官分割来说，可以做一些预设置，比如肝脏和胆囊在临床应用中经常被用来一起做分析。&lt;/li&gt;
&lt;li&gt;④ &lt;strong&gt;改进&lt;/strong&gt;：我们提出的设计是在TensorFlow的Keras库中进行的，利用Adam优化器，且初始学习率为0.00005。$\beta_1=0.9$,$\beta_2=0.999$,进行 $batchsize=2$ 的 $25K$ 次的迭代。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;41-font-colorredablation-experimentsfont&#34;&gt;4.1 &lt;strong&gt;&lt;font color=red&gt;Ablation experiments&lt;/font&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;411-主要内容&#34;&gt;4.1.1 主要内容&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;1&amp;gt;&lt;/strong&gt; 在阐述论文内容之前，笔者先理解一下&lt;font color=red&gt;&lt;strong&gt;Ablation experiments&lt;/strong&gt;&lt;/font&gt;，简单来说就是可以用控制变量的方式来评估各个模型的性能：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825084619525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;3&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825084619525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;3&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;2&amp;gt;&lt;/strong&gt; 预测的结果是通过0.5的阈值来进行二值化的处理的，为了测量预测值和实际标签之间的相似度，我们使用了Dice相似度系数（DSC）这个算法，定义如下：
$$
DSC(\textbf{Y}，\hat\textbf{Y})=\frac{2\sum{{\textbf{Y}}\odot{\hat\textbf{Y}}}}{\sum \textbf{Y}+ \sum \hat\textbf{Y}}
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;3&amp;gt;&lt;/strong&gt; 我们将分割的结果与一些SOTA级别的分割算法进行了对比，这些算法往往都是专门对单类别分割进行设计的。我们专门和Zhou的算法进行对比，他的算法基于卷积网络，利用两个阶段，实现从粗糙到精细的胰腺分割。在NIH上的分割dice为0.824。我们也与Yang的卷积分割算法进行对比，他的算法在1000CT上对肝进行分割，得出的dice为0.95 。最后，我们将算法和Roth的两阶段由粗到细的多器官分割算法比较，它的算法在多类别数据上的表现是0.954、 0.928、 0.822（肝、脾、胰腺）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;4&amp;gt;&lt;/strong&gt; 在所有的实验中，我们让$\alpha_i=1$，然后使用dice-loss：
$$
\mathcal L_i(\textbf{Y}^{c_i}，\hat{\textbf{Y}^{c_i}})=1-DSC(\textbf{Y}，\hat\textbf{Y})
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;5&amp;gt;&lt;/strong&gt; 我们用BCEloss进行测试，性能较差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;6&amp;gt;&lt;/strong&gt; ：


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825114907191.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825114907191.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;

                                                                                        &lt;strong&gt;（图三）&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;x轴为训练的迭代次数；&lt;/li&gt;
&lt;li&gt;y轴为dice，即精度值；&lt;/li&gt;
&lt;li&gt;有点灰绿色的线是训练精度（dice）；&lt;/li&gt;
&lt;li&gt;橙色的线是验证精度（dice）；&lt;/li&gt;
&lt;li&gt;红色直线是SOTA水平的dice线。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;7&amp;gt;&lt;/strong&gt; 分别对上图五个实验做个解释
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;indivs&lt;/strong&gt;：原始网络训练三个单标签模型；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;no cond&lt;/strong&gt;：&lt;font color=orange&gt;暂时认为：在训练单标签模型这个网络的基础上，把输入的训练集设计成三个通道，每个通道对应一个类别的数据集，而不是在一个通道内简单的相加在一起（训练一个单标签是一个通道的数据集）。显然，这样训练会更占显存（这点符合论文描述），但是这样简单的加通道我还不知道意味着什么。&lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;cond-2nd&lt;/strong&gt;：&lt;font color=orange&gt;暂时认为：是给输入的Volume加入一个通道，这个通道存放一个全为（-1，0，1）的与Volume形状相同的一个张量，以此来使得卷积的同时，这个条件信息也在融合，同时会根据设计好的查找表来决定训练哪个类别的数据。&lt;/font&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;cond-enc&lt;/strong&gt;：下采样加入Conditioning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;cond-dec&lt;/strong&gt;：上采样加入Conditioning：出色的分割效果和能力，主要源于两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;① 生成的这个模型具备高度的隐式参数共享能力，也就是说，模型共用了很多单个模型的参数；&lt;/li&gt;
&lt;li&gt;② 解码器可以利用条件信息，从而来恢复要分类的那些目标的空间信息和边界信息。&lt;/li&gt;
&lt;li&gt;③ 分割效果：

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825172929610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825172929610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;附加实验&lt;/strong&gt; ：在编码器和解码器都进行Conditioning、对解码器的部分层进行Conditioning，结果都没上面的实验效果好。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;412-不同类别之间空间连接信息的重要性&#34;&gt;4.1.2 不同类别之间空间连接信息的重要性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;1&amp;gt;&lt;/strong&gt; 这是一张破坏的ct图，其中脾脏的70%都被器官间的组织或脂肪的强度值代替；

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825170728770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825170728770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
	                                                                                        &lt;strong&gt;（图四）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;2&amp;gt;&lt;/strong&gt; 下面是各个实验的分割dice，以及一些优秀算法的dice：

&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825171049456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825171049456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
                                                                                        &lt;strong&gt;（表一）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;lt;3&amp;gt;&lt;/strong&gt; 为了检验我们的假设并探索模型之间的空间相关性对模型性能的重要性，我们评估了损坏图像的Conditioning模型。 对于上图的CT图像，我们用脂肪间体素强度值来随机替换70%的器官的体素，以达到破坏CT的目的。 脾脏图像不完整的一个例子如图4所示。有趣的是，脾脏和胰腺的这些单独的损坏实际上对肝脏分割的准确性没有影响，仅在2％的范围内降低。 然而，当其他器官受损时，脾脏和胰脏的分割都会受到显着影响，与基线相比平均降低了15.3％。 我们相信这支持我们的假设，即模型在推理过程中学习并利用目标类之间的空间相关性，而剥夺这些相关性会降低性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;413-自然图像的适用性&#34;&gt;4.1.3 自然图像的适用性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;笔者暂时不关心现实场景部分。


&lt;figure class=&#34;text-center&#34;&gt;
  &lt;img class=&#34;modal-trigger&#34; src=&#34;https://img-blog.csdnimg.cn/20200825171959838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34; id=&#34;watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; data-toggle=&#34;modal&#34; data-target=&#34;#modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;/&gt;

  &lt;div class=&#34;modal&#34; id=&#34;modal-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34;&gt;
    &lt;div class=&#34;modal-dialog modal-lg modal-dialog-centered&#34;&gt;
      &lt;div class=&#34;modal-body&#34;&gt;
        &lt;img src=&#34;https://img-blog.csdnimg.cn/20200825171959838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjA2MTYzNg==,size_16,color_FFFFFF,t_70#pic_center&#34; alt=&#34;在这里插入图片描述&#34;/&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-讨论&#34;&gt;5 讨论&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt;1&amp;gt; 在解码器上添加Conditioning效果最好；&lt;/li&gt;
&lt;li&gt;&amp;lt;2&amp;gt; 该框架可以扩充到病理学领域（活检等）和实例分割领域；&lt;/li&gt;
&lt;li&gt;&amp;lt;3&amp;gt; 未来将会先对MRI进行一定的实验。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
